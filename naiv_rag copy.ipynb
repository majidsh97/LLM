{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://motius.breezy.hr/p/0b622aa1163e01-join-our-tech-community-as-working-student-m-f-d/apply?utm_source=pt-linkedin&utm_medium=job-posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/cuda/__init__.py:749: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n",
      "No ROCm runtime is found, using ROCM_HOME='/usr'\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr'\n",
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dd14d811e34541b585ee8ec3e9ff6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import  AutoModel,AutoTokenizer,AutoModelForMaskedLM , Trainer,TrainingArguments,\\\n",
    "BitsAndBytesConfig,pipeline,default_data_collator,DataCollatorWithPadding,DataCollatorForLanguageModeling\n",
    "from transformers.utils import move_cache\n",
    "from chat_template_utils import get_json_schema\n",
    "from llama_cpp import Llama\n",
    "from utils import *\n",
    "from peft import *\n",
    "import datasets\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader,Dataset\n",
    "from hqq.engine.hf import HQQModelForCausalLM\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from huggingface_hub import snapshot_download\n",
    "#import deepspeed\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from var_dump import var_dump\n",
    "from bs4 import BeautifulSoup,PageElement,Comment\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cache_dir='/var/tmp/.cache/' #'/proj/ciptmp/ix05ogym/.cache/'\n",
    "output_dir = cache_dir+'outputs/'\n",
    "\n",
    "move_cache(cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "privacy                   63\n",
      "search                    43\n",
      "email                     38\n",
      "cv                        37\n",
      "submit                    28\n",
      "first name                25\n",
      "phone number              25\n",
      "cover letter              24\n",
      "linkedin                  23\n",
      "last name                 21\n",
      "find us                   15\n",
      "cancel                    12\n",
      "address                   11\n",
      "salary                    10\n",
      "available from            10\n",
      "github                     9\n",
      "question                   8\n",
      "transcript                 8\n",
      "recommendation             5\n",
      "login                      5\n",
      "birth                      5\n",
      "password                   4\n",
      "german language level      4\n",
      "xing                       4\n",
      "next                       4\n",
      "website                    3\n",
      "company                    3\n",
      "house number               3\n",
      "zip                        3\n",
      "picture                    3\n",
      "cookie                     3\n",
      "city                       3\n",
      "register                   3\n",
      "eligible                   2\n",
      "username                   2\n",
      "residentcountry            2\n",
      "work hours                 2\n",
      "visa                       2\n",
      "workherebefore             2\n",
      "sex                        2\n",
      "fake                       1\n",
      "googledrive                1\n",
      "dropbox                    1\n",
      "workduration               1\n",
      "citizen country            1\n",
      "resident country           1\n",
      "twitter                    1\n",
      "willing to relocate        1\n",
      "universityenrollment       1\n",
      "english language level     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_excel('train_forms.xlsx')[['input_text','labels']]\n",
    "train_dataset.drop_duplicates(['input_text']).reset_index(drop=True)\n",
    "c = train_dataset['labels']=='other'\n",
    "train_dataset.loc[c,'labels']=pd.NA\n",
    "c = train_dataset['labels']=='birthdate'\n",
    "train_dataset.loc[c,'labels']='birth'\n",
    "\n",
    "train_dataset['labels'].unique()\n",
    "\n",
    "#c = train_dataset['labels']=='privacy'\n",
    "#train_dataset.loc[c,:]\n",
    "\n",
    "lll=[]\n",
    "person = {\"first name\":\"majid\",\"last name\":\"sharghi foroushani\",\"pronoun\":\"he\",\"birth\":\"10/08/1997\",\"age\":\"27\",\"sex\":\"male\",\"skill\":\"NLP,LLM\",\"country\":\"Germany\",\"address\":\"Philip-9\",\"city\":\"Erlangen\",\"phone number\":\"+497773154\",\"available from\":\"6/24/2024\",\"salary\":\"10000\",\"German language level\":\"A1\",\"English language level\":\"C1\",\"visa\":\"do not need visa\",\"email\":\"sharghi.majid@gmail.com\",\"password\":\"123456\",\"find us\":\"Google\",\"xing\":\"www.xing.com\",\"job\":\"I am stduent\",\"university\":\"FAU\",\"major\":\"AI\",\"privacy\":\"privacy\",\"search\":\"search\",\"submit\":\"submit\",\"cookie\":\"cookie\",\"cover letter\":\"cover letter\",\"linkedin\":\"www.linkedin.com\",\"github\":\"www.github.com\",\"login\":\"login\",\"register\":\"register\",\"cv\":\"/pah/to/cv.pdf\",\"twitter\":\"www.twitter.com\"}\n",
    "for k,v in person.items():\n",
    "    c =  train_dataset['labels']==k\n",
    "    #train_dataset.loc[c,'labels']=k\n",
    "    pass\n",
    "    \n",
    "print(train_dataset['labels'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cv', 'first name', 'last name', 'email', 'phone number',\n",
       "       'available from', 'github', 'privacy', 'submit', 'search',\n",
       "       'country', 'sex', 'zip', 'cover letter', 'linkedin', 'visa',\n",
       "       'xing', 'newsletter'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = pd.read_excel('forms.xlsx')\n",
    "c = test_dataset['label'].notna()\n",
    "test_dataset = test_dataset.loc[c,:].reset_index(drop=True)\n",
    "test_dataset['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = test_dataset['label']=='guthub'\n",
    "test_dataset.loc[c,'label'] = 'github'\n",
    "test_dataset = test_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>element</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Personal information\\n CV or resume\\n Browse C...</td>\n",
       "      <td>&lt;input accept=\"application/pdf,.pdf\" name=\"cv\"...</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name *\\n</td>\n",
       "      <td>&lt;input name=\"first_name\" placeholder=\"First\" r...</td>\n",
       "      <td>first name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This field contains invalid characters\\n</td>\n",
       "      <td>&lt;input name=\"last_name\" placeholder=\"Last\" req...</td>\n",
       "      <td>last name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This field contains invalid characters\\n Email...</td>\n",
       "      <td>&lt;input name=\"email\" placeholder=\"yourmail@doma...</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phone\\n</td>\n",
       "      <td>&lt;input name=\"phone\" placeholder=\"+49 176 123 4...</td>\n",
       "      <td>phone number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cover letter\\n upload your cover letter\\n</td>\n",
       "      <td>&lt;input accept=\"application/msword, application...</td>\n",
       "      <td>cover letter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>github\\n</td>\n",
       "      <td>&lt;input name=\"custom_attribute_356304\" placehol...</td>\n",
       "      <td>github</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ihre e-mail-adresse\\n</td>\n",
       "      <td>&lt;button aria-label=\"subscribe for newsletter\" ...</td>\n",
       "      <td>newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>(!)\\n this field is required\\n</td>\n",
       "      <td>&lt;button id=\"uploaddropboxresume\" type=\"submit\"...</td>\n",
       "      <td>submit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>this field is required\\n from device\\n *\\n</td>\n",
       "      <td>&lt;input accept=\".pdf,.doc,.docx,.txt\" aria-requ...</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                query  \\\n",
       "0   Personal information\\n CV or resume\\n Browse C...   \n",
       "1                                           Name *\\n    \n",
       "2           This field contains invalid characters\\n    \n",
       "3   This field contains invalid characters\\n Email...   \n",
       "4                                            Phone\\n    \n",
       "..                                                ...   \n",
       "95         cover letter\\n upload your cover letter\\n    \n",
       "96                                          github\\n    \n",
       "97                             ihre e-mail-adresse\\n    \n",
       "98                    (!)\\n this field is required\\n    \n",
       "99        this field is required\\n from device\\n *\\n    \n",
       "\n",
       "                                              element         label  \n",
       "0   <input accept=\"application/pdf,.pdf\" name=\"cv\"...            cv  \n",
       "1   <input name=\"first_name\" placeholder=\"First\" r...    first name  \n",
       "2   <input name=\"last_name\" placeholder=\"Last\" req...     last name  \n",
       "3   <input name=\"email\" placeholder=\"yourmail@doma...         email  \n",
       "4   <input name=\"phone\" placeholder=\"+49 176 123 4...  phone number  \n",
       "..                                                ...           ...  \n",
       "95  <input accept=\"application/msword, application...  cover letter  \n",
       "96  <input name=\"custom_attribute_356304\" placehol...        github  \n",
       "97  <button aria-label=\"subscribe for newsletter\" ...    newsletter  \n",
       "98  <button id=\"uploaddropboxresume\" type=\"submit\"...        submit  \n",
       "99  <input accept=\".pdf,.doc,.docx,.txt\" aria-requ...            cv  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers  import SentenceTransformer\n",
    "#from transformers import AutoModel\n",
    "\n",
    "embdeding_tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2',cache_dir=cache_dir)\n",
    "\n",
    "#embeding_model= AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2',cache_dir=cache_dir)#.to('cuda')\n",
    "embeding_model= SentenceTransformer('sentence-transformers/all-MiniLM-L12-v2',cache_folder=cache_dir)#.to('cuda')\n",
    "\n",
    "\n",
    "embeding_model.eval()\n",
    "embeding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>element</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>keywords</td>\n",
       "      <td>&lt;input autocomplete=\"off\" autofocus=\"\" id=\"aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Email Address</td>\n",
       "      <td>&lt;input id=\"fieldEmail\" name=\"cm-ukutgu-ukutgu\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Please tick to confirm that you consent to us ...</td>\n",
       "      <td>&lt;a href=\"/privacy-policy\" target=\"_blank\" titl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>which includes details on how you can withdraw...</td>\n",
       "      <td>&lt;input name=\"gdpr_verification\" required=\"\" ty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subscribe</td>\n",
       "      <td>&lt;button type=\"submit\"&gt;Subscribe&lt;/button&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>Please identify your race Please selectAmerica...</td>\n",
       "      <td>&lt;select aria-required=\"false\" id=\"job_applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>Race &amp; Ethnicity Definitions</td>\n",
       "      <td>&lt;a href=\"https://boards.cdn.greenhouse.io/docs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>Veteran Status Please selectI am not a protect...</td>\n",
       "      <td>&lt;select aria-required=\"false\" id=\"job_applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Completing this form is voluntary, and we hope...</td>\n",
       "      <td>&lt;a href=\"https://www.dol.gov/ofccp\" target=\"_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>Disability Status Please selectYes, I have a d...</td>\n",
       "      <td>&lt;select aria-required=\"false\" id=\"job_applicat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1591 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  query  \\\n",
       "0                                              keywords   \n",
       "1                                         Email Address   \n",
       "2     Please tick to confirm that you consent to us ...   \n",
       "3     which includes details on how you can withdraw...   \n",
       "4                                             Subscribe   \n",
       "...                                                 ...   \n",
       "1586  Please identify your race Please selectAmerica...   \n",
       "1587                       Race & Ethnicity Definitions   \n",
       "1588  Veteran Status Please selectI am not a protect...   \n",
       "1589  Completing this form is voluntary, and we hope...   \n",
       "1590  Disability Status Please selectYes, I have a d...   \n",
       "\n",
       "                                                element  \n",
       "0     <input autocomplete=\"off\" autofocus=\"\" id=\"aut...  \n",
       "1     <input id=\"fieldEmail\" name=\"cm-ukutgu-ukutgu\"...  \n",
       "2     <a href=\"/privacy-policy\" target=\"_blank\" titl...  \n",
       "3     <input name=\"gdpr_verification\" required=\"\" ty...  \n",
       "4              <button type=\"submit\">Subscribe</button>  \n",
       "...                                                 ...  \n",
       "1586  <select aria-required=\"false\" id=\"job_applicat...  \n",
       "1587  <a href=\"https://boards.cdn.greenhouse.io/docs...  \n",
       "1588  <select aria-required=\"false\" id=\"job_applicat...  \n",
       "1589  <a href=\"https://www.dol.gov/ofccp\" target=\"_b...  \n",
       "1590  <select aria-required=\"false\" id=\"job_applicat...  \n",
       "\n",
       "[1591 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('query_element_3.xlsx')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 147,456 || all params: 33,507,456 || trainable%: 0.4401\n"
     ]
    }
   ],
   "source": [
    "embeding_model = get_peft_model(embeding_model,LoraConfig(target_modules=['query','value']))\n",
    "embeding_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#c = train_dataset['labels']=='relocate'\n",
    "#train_dataset.loc[c,'labels'] = 'willing to relocate'\n",
    "#train_dataset[c]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.to_excel('train_forms.xlsx',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.trainer import SentenceTransformerTrainer,SentenceTransformerTrainingArguments\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'element', 'label'],\n",
       "    num_rows: 1591\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[:,'label']=1\n",
    "train_dataset = datasets.Dataset.from_pandas(data)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PeftModel' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenoisingAutoEncoderLoss \u001b[38;5;28;01mas\u001b[39;00m myloss\n\u001b[1;32m      2\u001b[0m trainer  \u001b[38;5;241m=\u001b[39m  SentenceTransformerTrainer(model\u001b[38;5;241m=\u001b[39membeding_model,\n\u001b[1;32m      3\u001b[0m                            train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[1;32m      4\u001b[0m                            tokenizer\u001b[38;5;241m=\u001b[39membdeding_tokenizer,\n\u001b[0;32m----> 5\u001b[0m                            loss\u001b[38;5;241m=\u001b[39m\u001b[43mmyloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeding_model\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      6\u001b[0m                            args\u001b[38;5;241m=\u001b[39mSentenceTransformerTrainingArguments(\n\u001b[1;32m      7\u001b[0m                                output_dir\u001b[38;5;241m=\u001b[39moutput_dir,\n\u001b[1;32m      8\u001b[0m                                num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m      9\u001b[0m                                per_device_train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m\n\u001b[1;32m     10\u001b[0m                            )\n\u001b[1;32m     11\u001b[0m                            \n\u001b[1;32m     12\u001b[0m                            )\n\u001b[1;32m     15\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/sentence_transformers/losses/DenoisingAutoEncoderLoss.py:77\u001b[0m, in \u001b[0;36mDenoisingAutoEncoderLoss.__init__\u001b[0;34m(self, model, decoder_name_or_path, tie_encoder_decoder)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m model  \u001b[38;5;66;03m# This will be the final model used during the inference time.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer_encoder \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtokenizer\n\u001b[0;32m---> 77\u001b[0m encoder_name_or_path \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mauto_model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_name_or_path\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder_name_or_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m     80\u001b[0m         tie_encoder_decoder\n\u001b[1;32m     81\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust indicate the decoder_name_or_path argument when tie_encoder_decoder=False!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'PeftModel' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.losses import DenoisingAutoEncoderLoss as myloss\n",
    "trainer  =  SentenceTransformerTrainer(model=embeding_model,\n",
    "                           train_dataset=train_dataset,\n",
    "                           tokenizer=embdeding_tokenizer,\n",
    "                           loss=myloss(embeding_model,),\n",
    "                           args=SentenceTransformerTrainingArguments(\n",
    "                               output_dir=output_dir,\n",
    "                               num_train_epochs=2,\n",
    "                               per_device_train_batch_size=16\n",
    "                           )\n",
    "                           \n",
    "                           )\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51, 384])\n",
      "acc: 0.67\n"
     ]
    }
   ],
   "source": [
    "def compute_metric():\n",
    "    embeding_model.eval()\n",
    "    acc=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        l=embeding_model.encode(LABEL_INDEX_TO_KEY)\n",
    "        l = torch.tensor(l)\n",
    "        print(l.shape)\n",
    "        \n",
    "        for i,x in test_dataset.iterrows():\n",
    "            #te = embdeding_tokenizer([x['element']],max_length=512,truncation=True,return_tensors='pt')['input_ids']\n",
    "            \n",
    "            o= embeding_model.encode( x['element'])\n",
    "            o = torch.tensor(o)\n",
    "            sim = torch.cosine_similarity(l,o)\n",
    "            #print(sim.shape)\n",
    "            #sim = torch.mean(sim,1)\n",
    "            if LABEL_INDEX_TO_KEY[sim.argmax()]==x['label']:\n",
    "                acc+=1\n",
    "                pass\n",
    "            #print(LABEL_INDEX_TO_KEY[sim.argmax()],x['label'])\n",
    "            \n",
    "           \n",
    "             \n",
    "    \n",
    "    acc/=len(test_dataset)\n",
    "    print(\"acc:\",acc)\n",
    "    \n",
    "    \n",
    "    \n",
    "compute_metric()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No ROCm runtime is found, using ROCM_HOME='/usr'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-11 13:35:14,136] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Warning: The default cache directory for DeepSpeed Triton autotune, /home/cip/ce/ix05ogym/.triton/autotune, appears to be on an NFS system. While this is generally acceptable, if you experience slowdowns or hanging when DeepSpeed exits, it is recommended to set the TRITON_CACHE_DIR environment variable to a non-NFS path.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel,AutoTokenizer , Trainer,TrainingArguments,BitsAndBytesConfig\n",
    "from peft import get_peft_model,LoraConfig\n",
    "import datasets\n",
    "import torchmetrics\n",
    "import torch\n",
    "from hqq.engine.hf import HQQModelForCausalLM\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from huggingface_hub import snapshot_download\n",
    "import deepspeed\n",
    "import os\n",
    "cache_dir='/proj/ciptmp/ix05ogym/.cache/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demo': 'cptbbef',\n",
       " 'turn': 4,\n",
       " 'action': 'click(uid=None)',\n",
       " 'action_history': 'say(speaker=\"instructor\", utterance=\"Hello\") say(speaker=\"navigator\", utterance=\"Hi\")</s><s>[INST] say(speaker=\"instructor\", utterance=\"Open momondo.in and login with google using the below details: \\\\n\\\\t\\\\n\\\\tId: webtasks.navigator@gmail.com \\\\n\\\\tPassword: KEG24qweUHij%^\") load(url=\"https://www.momondo.in/\")</s><s>[INST]',\n",
       " 'utterances': 'N o   i n s t r u c t o r   u t t e r a n c e ;',\n",
       " 'candidates': \"(uid = 9f2c37b3-a223-4f07) [[tag]] body [[xpath]] /html/body [[text]]   [[bbox]] x=0 y=0 width=1519.2 height=2919.5 [[attributes]] id='c-ehw' data-webtasks-id='9f2c37b3-a223-4f07' class='keel-mom kl kl-override FlightsSearchBrandsMomon...st wide a11y-focus-outlines wide-fd en_IN horizon' [[children]]\",\n",
       " 'clean_html': '(html(head prefix=\"og: http://ogp.me/ns# fb: http://ogp.me/ns/fb#\" ) (body class=\"keel-mom kl kl-override FlightsSearchBrandsMomondo react react-st wide a11y-focus-outlines wide-fd en_IN horizon\" data-webtasks-id=\"9f2c37b3-a223-4f07\" ))',\n",
       " 'viewport': '714h x 1536w'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.load_dataset('McGill-NLP/WebLINX',split=['train[:100]'],cache_dir=cache_dir)[0]\n",
    "train_dataset[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:00<00:00, 151967.54it/s]\n",
      "100%|██████████| 130/130 [00:00<00:00, 50557.21it/s]\n",
      "100%|██████████| 225/225 [00:00<00:00, 20331.75it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"PrunaAI/McGill-NLP-Llama-3-8B-Web-HQQ-4bit-smashed\"\n",
    "#config = BitsAndBytesConfig(\n",
    "    #load_in_4bit=True,\n",
    "\n",
    "    #load_in_8bit=True,\n",
    "    \n",
    "    #bnb_4bit_quant_type=\"nf4\",\n",
    "    #bnb_4bit_use_double_quant=True,\n",
    "    #bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    #)\n",
    "\n",
    "\"\"\"\n",
    "model = AutoModel.from_pretrained(model_name,\n",
    "                          #quantization_config=GPTQConfig(bits=4, disable_exllama=False),\n",
    "                          #load_in_8bit=True,\n",
    "                          cache_dir=cache_dir)\n",
    "\n",
    "\n",
    "print(model)\n",
    "\"\"\"\n",
    "#https://huggingface.co/docs/transformers/main/en/quantization/hqq\n",
    "try:\n",
    " model_hqq = HQQModelForCausalLM.from_quantized(model_name, device_map='auto',cache_dir=cache_dir)#.to(torch.bfloat16) #.half()\n",
    "except: \n",
    " model_hqq = AutoHQQHFModel.from_quantized(model_name,cache_dir=cache_dir)\n",
    " \n",
    " \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"McGill-NLP/Llama-3-8B-Web\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.eval()\n",
    "#input_ids = tokenizer(\"create an html apply button?\", return_tensors='pt').to('cuda')[\"input_ids\"]\n",
    "#outputs = model.generate(input_ids, max_new_tokens=216)\n",
    "#tokenizer.decode(outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(128256, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaSdpaAttention(\n",
      "          (q_proj): HQQLinear(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): HQQLinear(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): HQQLinear(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): HQQLinear(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): HQQLinear(in_features=4096, out_features=14336, bias=False)\n",
      "          (up_proj): HQQLinear(in_features=4096, out_features=14336, bias=False)\n",
      "          (down_proj): HQQLinear(in_features=14336, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_hqq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 2322.43it/s]\n"
     ]
    }
   ],
   "source": [
    "snapshot_download(\"McGill-NLP/WebLINX\", repo_type=\"dataset\", allow_patterns=\"templates/*\",cache_dir=cache_dir)\n",
    "valid = datasets.load_dataset(\"McGill-NLP/WebLINX\", split=\"validation[:5]\",cache_dir=cache_dir)\n",
    "template = \"\"\"<s>[INST] <<SYS>>\n",
    "{clean_html}\n",
    "You will find above the HTML elements that are available for the current webpage.\n",
    "You are an AI assistant with a deep understanding of HTML \n",
    "and you must predict actions based on a user request, which will be executed. \n",
    "Use one of the following, replacing [] with an appropriate value: change(value=[str], uid=[str]) ; click(uid=[str]) ; load(url=[str]) ; say(speaker=\"navigator\", utterance=[str]) ; scroll(x=[int], y=[int]) ; \n",
    "submit(uid=[str]) ; text_input(text=[str], uid=[str]) ;\n",
    "The user's first and last 4 utterances are:\n",
    "{utterances} ;\n",
    "Viewport size: {viewport}\n",
    "Only the last 5 turns are provided.\n",
    "Here are the top candidates for this turn:\n",
    "{candidates}\n",
    "\n",
    "<</SYS>>[/INST]\n",
    "{action_history}\n",
    "Please select the best action using the correct format, do not provide any other information or explanation.\n",
    "[/INST]\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>[INST] <<SYS>>\n",
      "(html(body(div class=\"container\"(div class=\"row\"(div class=\"col hdr-r justify-...flex align-items-center\"(div class=\"hdr-categories-container\"(a class=\"rc-link\" onclick=\"if (!window.__cfRLUn... false; toggleFlyout()\" data-webtasks-id=\"76978...85e-4cf1\"(span class=\"text\" data-webtasks-id=\"6c7fe1...640-4dce\"EXPLORE)(i class=\"fa ency-down\" data-webtasks-id=\"e7b787...5ae-48a5\"))(div class=\"rc-flyout\"))))) (div (div class=\"dialog-off-canvas-main-canvas\"(div class=\"homepage\"(div style=\"background-image: url('/sites...01_3.png');\" class=\"ency-loaded\"(div class=\"ency-loaded mask-hero\")(h4 data-webtasks-id=\"1ea51e...fcd-4e30\"The World’s #1 Online Encyclopedia)(div class=\"clear-both hero\"(div class=\"ency-hero-search\"(form action=\"https://www.encyclopedia.com/gsearch\" method=\"get\" data-webtasks-id=\"c7fbc11c...49-4ab2\"(div class=\"js-form-item form-...-keys form-no-label\" data-webtasks-id=\"8d8afc8...7-477a\" (span class=\"field-preffix\" (input class=\"button js-form-submit form-submit\" type=\"submit\" value=\"\" ) (input title=\"\" class=\"searchbox form-search form-input\" placeholder=\"What do you want to learn today?\" type=\"search\" name=\"q\" value=\"\" size=\"15\" maxlength=\"128\" data-webtasks-id=\"67e2a5...d-41a0\" spellcheck=\"false\" (span class=\"field-suffix\" (i class=\"fa ency-close\")))(div class=\"form-actions js-form-wrapper form-wrapper\" (input class=\"button js-form-submit form-submit\" type=\"submit\" value=\"Search\" data-webtasks-id=\"fedfb512-...9e-42b3\")))(div class=\"clear-both hero footer-copy\"(a href=\"/about\" data-webtasks-id=\"bf33a0...67-44f0\"Read more) about our content and why so many people love it.))))))(div class=\"adthrive-ad adth...cls adthrive-sticky\" style=\"min-height: 90px;\" closable=\"true\"(div style=\"border: 0pt none;\")(span class=\"adthrive-close\" data-webtasks-id=\"0ffc6f0...8a-4c2a\"×))))\n",
      "You will find above the HTML elements that are available for the current webpage.\n",
      "You are an AI assistant with a deep understanding of HTML \n",
      "and you must predict actions based on a user request, which will be executed. \n",
      "Use one of the following, replacing [] with an appropriate value: change(value=[str], uid=[str]) ; click(uid=[str]) ; load(url=[str]) ; say(speaker=\"navigator\", utterance=[str]) ; scroll(x=[int], y=[int]) ; \n",
      "submit(uid=[str]) ; text_input(text=[str], uid=[str]) ;\n",
      "The user's first and last 4 utterances are:\n",
      "[00:05] Hello ; ;\n",
      "Viewport size: 746h x 1536w\n",
      "Only the last 5 turns are provided.\n",
      "Here are the top candidates for this turn:\n",
      "(uid = 67e2a5fb-8b1d-41a0) [[tag]] input [[xpath]] /html/body/div[2...form/div[1]/input [[bbox]] x=419.6 y=461.0 width=477.6 height=89.6 [[attributes]] title='' value='' name='...What do you want to learn today?' \n",
      "(uid = fedfb512-949e-42b3) [[tag]] input [[xpath]] /html/body/div[2...form/div[2]/input [[bbox]] x=915.6 y=461.0 width=185.6 height=89.6 [[attributes]] type='submit' value='Search...-form-submit form-submit' \n",
      "(uid = c7fbc11c-0949-4ab2) [[tag]] form [[xpath]] /html/body/div[2...2]/div[3]/form [[bbox]] x=419.6 y=461.0 width=680 height=88 [[attributes]] method='get' data-web...clopedia.com/gsearch' [[children]] div div \n",
      "(uid = 6c7fe1f1-f640-4dce) [[tag]] span [[xpath]] /html/body/header/div...div[2]/a/span [[text]] EXPLORE [[bbox]] x=1240.5 y=28.6 width=54.1 height=30 [[attributes]] class='text' data-webtasks...-main-menu-menu' \n",
      "(uid = 0ffc6f0e-808a-4c2a) [[tag]] span [[xpath]] /html/body/div[5]/span [[text]] × [[bbox]] x=1485.9 y=665.6 width=23.3 height=21.6 [[attributes]] class='adthrive-close...8a-4c2a' \n",
      "(uid = 8d8afc84-5b97-477a) [[tag]] div [[xpath]] /html/body/div[...3]/form/div[1] [[text]]   [[bbox]] x=419.6 y=461.0 width=476 height=88 [[attributes]] data-webtasks-id='8...keys form-no-label' [[children]] span input \n",
      "(uid = 1ea51e98-3fcd-4e30) [[tag]] h4 [[xpath]] /html/body/div[...div/div[1]/h4 [[text]] The World’s #1 Online Encyclopedia [[bbox]] x=33 y=163 width=1453.2 height=43.2 [[attributes]] data-webtasks-id='1...cd-4e30' \n",
      "(uid = 769785af-485e-4cf1) [[tag]] a [[xpath]] /html/body/header/div...2]/div[2]/a [[bbox]] x=1240.5 y=28.6 width=74.1 height=30 [[attributes]] id='rcLink' class='... false; toggleFlyout()' [[children]] span i \n",
      "(uid = e7b7879f-45ae-48a5) [[tag]] i [[xpath]] /html/body/header/div...div[2]/a/i [[bbox]] x=1294.6 y=33.6 width=20 height=20 [[attributes]] class='fa ency-down...5ae-48a5' \n",
      "(uid = bf33a062-fb67-44f0) [[tag]] a [[xpath]] /html/body/div[2...div[4]/p/a [[text]] Read more [[bbox]] x=567.0 y=641.0 width=69.3 height=16 [[attributes]] href='/about' data-...67-44f0'\n",
      "\n",
      "<</SYS>>[/INST]\n",
      "say(speaker=\"navigator\", utterance=\"Hi\")</s><s>[INST] say(speaker=\"instructor\", utterance=\"Open Encyclopedia website.\") say(speaker=\"navigator\", utterance=\"Yes, sure\") load(url=\"https://www.encyclopedia.com/\")</s><s>[INST] say(speaker=\"instructor\", utterance=\"Search for biotechnology\")\n",
      "Please select the best action using the correct format, do not provide any other information or explanation.\n",
      "[/INST]\n"
     ]
    }
   ],
   "source": [
    "state = template.format(**valid[0])\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-11 13:37:19,495] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown\n",
      "[2024-06-11 13:37:19,500] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/cip/ce/ix05ogym/.cache/torch_extensions/py311_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module cpu_adam, skipping build step...\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "/home/cip/ce/ix05ogym/.cache/torch_extensions/py311_cu118/cpu_adam/cpu_adam.so: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 89\u001b[0m\n\u001b[1;32m     83\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/usr/bin/g++\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Move the optimizer instance to the GPU\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m#optimizer = optimizer.to(\"cuda\")\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m model, optimizer, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdeepspeed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_hqq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_hqq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#optimizer=deepspeed.ops.adam.DeepSpeedCPUAdam,\u001b[39;49;00m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_config\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/__init__.py:181\u001b[0m, in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, distributed_port, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    169\u001b[0m         engine \u001b[38;5;241m=\u001b[39m DeepSpeedHybridEngine(args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m    170\u001b[0m                                        model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    171\u001b[0m                                        optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m                                        config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    179\u001b[0m                                        config_class\u001b[38;5;241m=\u001b[39mconfig_class)\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 181\u001b[0m         engine \u001b[38;5;241m=\u001b[39m \u001b[43mDeepSpeedEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtraining_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mdist_init_required\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdist_init_required\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_class\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m mpu \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmpu must be None with pipeline parallelism\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/runtime/engine.py:307\u001b[0m, in \u001b[0;36mDeepSpeedEngine.__init__\u001b[0;34m(self, args, model, optimizer, model_parameters, training_data, lr_scheduler, mpu, dist_init_required, collate_fn, config, config_class, dont_change_device)\u001b[0m\n\u001b[1;32m    304\u001b[0m     model_parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_parameters)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_optimizer:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_lr_scheduler(lr_scheduler)\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_progress(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/runtime/engine.py:1232\u001b[0m, in \u001b[0;36mDeepSpeedEngine._configure_optimizer\u001b[0;34m(self, client_optimizer, model_parameters)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_moe_layers:\n\u001b[1;32m   1231\u001b[0m         model_parameters \u001b[38;5;241m=\u001b[39m configure_moe_param_groups(model_parameters)\n\u001b[0;32m-> 1232\u001b[0m     basic_optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_configure_basic_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1233\u001b[0m     log_dist(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing DeepSpeed Optimizer param name \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_name()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as basic optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, ranks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/runtime/engine.py:1303\u001b[0m, in \u001b[0;36mDeepSpeedEngine._configure_basic_optimizer\u001b[0;34m(self, model_parameters)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_use_cpu_optimizer():\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepSpeedCPUAdam\n\u001b[0;32m-> 1303\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mDeepSpeedCPUAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m                                 \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptimizer_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43madamw_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffective_adam_w_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeepspeed\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FusedAdam\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/ops/adam/cpu_adam.py:94\u001b[0m, in \u001b[0;36mDeepSpeedCPUAdam.__init__\u001b[0;34m(self, model_params, lr, bias_correction, betas, eps, weight_decay, amsgrad, adamw_mode, fp32_optimizer_states)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madam_w_mode \u001b[38;5;241m=\u001b[39m adamw_mode\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp32_optimizer_states \u001b[38;5;241m=\u001b[39m fp32_optimizer_states\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_opt_adam \u001b[38;5;241m=\u001b[39m \u001b[43mCPUAdamBuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds_opt_adam\u001b[38;5;241m.\u001b[39mcreate_adam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt_id, lr, betas[\u001b[38;5;241m0\u001b[39m], betas[\u001b[38;5;241m1\u001b[39m], eps, weight_decay, adamw_mode,\n\u001b[1;32m     97\u001b[0m                              should_log_le(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:480\u001b[0m, in \u001b[0;36mOpBuilder.load\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op_module\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/deepspeed/ops/op_builder/builder.py:524\u001b[0m, in \u001b[0;36mOpBuilder.jit_load\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_rocm_pytorch():\n\u001b[1;32m    522\u001b[0m     cxx_args\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-D__HIP_PLATFORM_AMD__=1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 524\u001b[0m op_module \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip_empty_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip_empty_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcxx_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnvcc_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrip_empty_entries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    532\u001b[0m build_duration \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_build\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1309\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(name,\n\u001b[1;32m   1218\u001b[0m          sources: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m   1219\u001b[0m          extra_cflags\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1227\u001b[0m          is_standalone\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1228\u001b[0m          keep_intermediates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03m    Load a PyTorch C++ extension just-in-time (JIT).\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;124;03m        ...     verbose=True)\u001b[39;00m\n\u001b[1;32m   1308\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1309\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jit_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43msources\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_cuda_cflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_ldflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_include_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_get_build_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_cuda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_standalone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_intermediates\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/utils/cpp_extension.py:1745\u001b[0m, in \u001b[0;36m_jit_compile\u001b[0;34m(name, sources, extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths, build_directory, verbose, with_cuda, is_python_module, is_standalone, keep_intermediates)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_standalone:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _get_exec_path(name, build_directory)\n\u001b[0;32m-> 1745\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_import_module_from_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuild_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_python_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/utils/cpp_extension.py:2143\u001b[0m, in \u001b[0;36m_import_module_from_library\u001b[0;34m(module_name, path, is_python_module)\u001b[0m\n\u001b[1;32m   2141\u001b[0m spec \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mspec_from_file_location(module_name, filepath)\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2143\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule_from_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2144\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(spec\u001b[38;5;241m.\u001b[39mloader, importlib\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mLoader)\n\u001b[1;32m   2145\u001b[0m spec\u001b[38;5;241m.\u001b[39mloader\u001b[38;5;241m.\u001b[39mexec_module(module)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:573\u001b[0m, in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1233\u001b[0m, in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: /home/cip/ce/ix05ogym/.cache/torch_extensions/py311_cu118/cpu_adam/cpu_adam.so: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  \"train_batch_size\": 8,\n",
    "  \"gradient_accumulation_steps\": 1,\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"Adam\",\n",
    "    \"params\": {\n",
    "      \"lr\": 0.00015\n",
    "    }\n",
    "  },\n",
    "  \"fp16\": {\n",
    "    \"enabled\": true\n",
    "  },\n",
    "  \"zero_optimization\": true\n",
    "}\n",
    "\"\"\"\n",
    "#os.environ['DS_SKIP_CUDA_CHECK'] = '1'\n",
    "\n",
    "\"\"\"\n",
    "  \"optimizer\": {\n",
    "      \"type\": \"AdamW\",\n",
    "      \"params\": {\n",
    "        \"lr\": 2e-5,\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"bias_correction\": True\n",
    "      }\n",
    "    },\n",
    "\n",
    "\"\"\"\n",
    "ds_config = {\n",
    "    \"train_batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "      \"optimizer\": {\n",
    "      \"type\": \"AdamW\",\n",
    "      \"params\": {\n",
    "        \"lr\": 2e-5,\n",
    "        \"weight_decay\": 0.0,\n",
    "        \"bias_correction\": True\n",
    "      }\n",
    "    },\n",
    "  \n",
    "   \"\"\" \"quantize_training\": {\n",
    "      \"enabled\": True,\n",
    "      \"quantize_verbose\": True,\n",
    "      \"quantizer_kernel\": True,\n",
    "      \"quantize-algo\": {\n",
    "        \"q_type\": \"symmetric\"\n",
    "      },\n",
    "      \"quantize_bits\": {\n",
    "        \"start_bits\": 4,\n",
    "        \"target_bits\": 2\n",
    "      },\n",
    "      \"quantize_schedule\": {\n",
    "        \"quantize_period\": 400,\n",
    "        \"schedule_offset\": 0\n",
    "      },\n",
    "      #\"quantize_groups\": 8,\n",
    "    },\"\"\"\n",
    "  \n",
    "    \n",
    "    \"bf16\": {\n",
    "        \"enabled\": True,\n",
    "        #\"initial_scale_power\": 16,\n",
    "\n",
    "    },\n",
    "    \"zero_optimization\": {\n",
    "        \"stage\": 3,\n",
    "        \"offload_param\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "        \"offload_optimizer\": {\n",
    "            \"device\": \"cpu\",\n",
    "            \"pin_memory\": True\n",
    "        },\n",
    "    },\n",
    "    \"activation_checkpointing\": {\n",
    "        \"partition_activations\": True,\n",
    "        \"cpu_checkpointing\": True\n",
    "    },\n",
    "}\n",
    "os.environ[\"PATH\"] = '/usr/bin/g++'\n",
    "os.environ[\"DEFAULT_TORCH_EXTENSION_PATH \"] = '/proj/ciptmp/ix05ogym/tmp'\n",
    "# Move the optimizer instance to the GPU\n",
    "#optimizer = optimizer.to(\"cuda\")\n",
    "\n",
    "\n",
    "model, optimizer, _, _ = deepspeed.initialize(\n",
    "    model=model_hqq,\n",
    "    model_parameters=model_hqq.parameters(),\n",
    "    #optimizer=deepspeed.ops.adam.DeepSpeedCPUAdam,\n",
    "    config=ds_config\n",
    "    ,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_state = tokenizer(state,return_tensors='pt',truncation=True,max_length=2048).to('cuda')#.to(torch.bfloat16)\n",
    "print(tokenized_state)\n",
    "#model = model.eval()\n",
    "with torch.cuda.amp.autocast():#torch.no_grad():\n",
    "    o=model(**tokenized_state)\n",
    "    #del tokenized_state\n",
    "    #torch.cuda.empty_cache()\n",
    "    \n",
    "o\n",
    "#print(\"Action:\", out['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y =o.logits.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = y.argmax(2)\n",
    "print(m.shape)\n",
    "pp=tokenizer.decode(m[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

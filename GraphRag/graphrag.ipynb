{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphrag\n",
    "#https://medium.com/@ysaurabh059/graphrag-local-setup-via-vllm-and-ollama-a-detailed-integration-guide-5d85f18f7fec\n",
    "#https://medium.com/percena/inside-graphrag-analyzing-microsofts-innovative-framework-for-knowledge-graph-processing1-6f84deec5499\n",
    "\n",
    "#python -m graphrag.index --init --root ./ragtest\n",
    "#python -m graphrag.index --root ./ragtest\n",
    "\n",
    "#litellm --host 127.0.0.1 --port 8080 --config /home/cip/ce/ix05ogym/Majid/LLM/litellm/config.yaml\n",
    "#visual\n",
    "#https://noworneverev.github.io/graphrag-visualizer/\n",
    "#https://docs.llamaindex.ai/en/stable/examples/low_level/evaluation/\n",
    "#https://platform.openai.com/docs/guides/rate-limits/error-mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"anything\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.generator import TestsetGenerator,RunConfig\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.integrations.llama_index import evaluate \n",
    "# generator with openai models\n",
    "model_name = \"gpt-4o\"\n",
    "base_url = \"http://localhost:8080/\"\n",
    "max_tokens = 1024*8\n",
    "generator_llm = ChatOpenAI(model=model_name, base_url=base_url,max_tokens=max_tokens)\n",
    "critic_llm = ChatOpenAI(model=model_name, base_url=base_url,max_tokens=max_tokens)\n",
    "embeddings = OpenAIEmbeddings(model='text', base_url=base_url)\n",
    "runconfig = RunConfig(max_workers=1,max_retries=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex,Document,Settings\n",
    "from llama_index.core import VectorStoreIndex,Document,Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "unit_text_path = '/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/ragtest/output/create_base_text_units.parquet'\n",
    "\n",
    "texts = pd.read_parquet(unit_text_path)\n",
    "\n",
    "texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response=\"The provided text is a passage from Charles Dickens's *A Christmas Carol*. It describes Scrooge's interactions with his nephew and other business associates. \\n\", source_nodes=[NodeWithScore(node=TextNode(id_='ebc403dd3df39bacc3443ef4afb7edfd', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\nprecious time to me, I know. Lead on, Spirit!\\'\\n\\nThe Phantom moved away as it had come towards him. Scrooge followed in\\nthe shadow of its dress, which bore him up, he thought, and carried him\\nalong.\\n\\nThey scarcely seemed to enter the City; for the City rather seemed to\\nspring up about them, and encompass them of its own act. But there they\\nwere in the heart of it; on \\'Change, amongst the merchants, who hurried\\nup and down, and chinked the money in their pockets, and conversed in\\ngroups, and looked at their watches, and trifled thoughtfully with their\\ngreat gold seals, and so forth, as Scrooge had seen them often.\\n\\nThe Spirit stopped beside one little knot of business men. Observing\\nthat the hand was pointed to them, Scrooge advanced to listen to their\\ntalk.\\n\\n\\'No,\\' said a great fat man with a monstrous chin, \\'I don\\'t know much\\nabout it either way. I only know he\\'s dead.\\'\\n\\n\\'When did he die?\\' inquired another.\\n\\n\\'Last night, I believe.\\'\\n\\n\\'Why, what was the matter with him?\\' asked a third, taking a vast\\nquantity of snuff out of a very large snuff-box. \\'I thought he\\'d never\\ndie.\\'\\n\\n\\'God knows,\\' said the first, with a yawn.\\n\\n\\'What has he done with his money?\\' asked a red-faced gentleman with a\\npendulous excrescence on the end of his nose, that shook like the gills\\nof a turkey-cock.\\n\\n\\'I haven\\'t heard,\\' said the man with the large chin, yawning again.\\n\\'Left it to his company, perhaps. He hasn\\'t left it to _me_. That\\'s all\\nI know.\\'\\n\\nThis pleasantry was received with a general laugh.\\n\\n\\'It\\'s likely to be a very cheap funeral,\\' said the same speaker; \\'for,\\nupon my life, I don\\'t know of anybody to go to it. Suppose we make up a\\nparty, and volunteer?\\'\\n\\n\\'I don\\'t mind going if a lunch is provided,\\' observed the gentleman with\\nthe excrescence on his nose. \\'But I must be fed if I make one.\\'\\n\\nAnother laugh.\\n\\n[Illustration:\\n\\n  _\"How are you?\" said one.\\n   \"How are you?\" returned the other.\\n   \"Well!\" said the first. \"Old Scratch has got his own at last, hey?\"_\\n\\n]\\n\\n\\'Well, I am the most disinterested among you, after all,\\' said the first\\nspeaker, \\'for I never wear black gloves, and I never eat lunch. But I\\'ll\\noffer to go if anybody else will. When I come to think of it, I\\'m not\\nat all sure that I wasn\\'t his most particular friend; for we used to\\nstop and speak whenever we met. Bye, bye!\\'\\n\\nSpeakers and listeners strolled away, and mixed with other groups.\\nScrooge knew the men, and looked towards the Spirit for an explanation.\\n\\nThe phantom glided on into a street. Its finger pointed to two persons\\nmeeting. Scrooge listened again, thinking that the explanation might lie\\nhere.\\n\\nHe knew these men, also, perfectly. They were men of business: very\\nwealthy, and of great importance. He had made a point always of standing\\nwell in their esteem in a business point of view, that is; strictly in a\\nbusiness point of view.\\n\\n\\'How are you?\\' said one.\\n\\n\\'How are you?\\' returned the other.\\n\\n\\'Well!\\' said the first, \\'old Scratch has got his own at last, hey?\\'\\n\\n\\'So I am told,\\' returned the second. \\'Cold, isn\\'t it?\\'\\n\\n\\'Seasonable for Christmas-time. You are not a skater, I suppose?\\'\\n\\n\\'No, no. Something else to think of. Good-morning!\\'\\n\\nNot another word. That was their meeting, their conversation, and their\\nparting.\\n\\nScrooge was at first inclined to be surprised that the Spirit should\\nattach importance to conversations apparently so trivial; but feeling\\nassured that they must have some hidden purpose, he set himself to\\nconsider what it was likely to be. They could scarcely be supposed to\\nhave any bearing on the death of Jacob, his old partner, for that was\\nPast, and this Ghost\\'s province was the Future. Nor could he think of\\nany one immediately connected with himself to whom he could apply them.\\nBut nothing doubting that, to whomsoever they applied, they had some\\nlatent moral for his own improvement, he resolved to treasure up every\\nword he heard, and everything he saw; and especially to observe the\\nshadow of himself when it appeared. For he had an expectation that the\\nconduct of his future self would give him the clue he missed, and would\\nrender the solution of these riddles easy.\\n\\nHe looked about in that very place for his own image, but another man\\nstood in his accustomed corner; and though the clock pointed to his\\nusual time of day for being there, he saw no likeness of himself among\\nthe multitudes that poured in through the Porch. It gave him little\\nsurprise, however; for he had been revolving in his mind a change of\\nlife, and thought and hoped he saw his new-born resolutions carried out\\nin this.\\n\\nQuiet and dark, beside him stood the Phantom, with its outstretched\\nhand. When he roused himself from his thoughtful quest, he fancied,\\nfrom the turn of the hand, and its situation in reference to himself,\\nthat the Unseen Eyes were looking at him keenly. It made him shudder,\\nand feel very cold.\\n\\nThey left the busy scene, and went into an obscure part of the town,\\nwhere Scro', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.2923593701747352), NodeWithScore(node=TextNode(id_='080d8e696ff38c653ca90fa086415e74', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='\\'Bah!\\' again; and followed it up with \\'Humbug!\\'\\n\\n\\'Don\\'t be cross, uncle!\\' said the nephew.\\n\\n\\'What else can I be,\\' returned the uncle, \\'when I live in such a world\\nof fools as this? Merry Christmas! Out upon merry Christmas! What\\'s\\nChristmas-time to you but a time for paying bills without money; a time\\nfor finding yourself a year older, and not an hour richer; a time for\\nbalancing your books, and having every item in \\'em through a round dozen\\nof months presented dead against you? If I could work my will,\\' said\\nScrooge indignantly, \\'every idiot who goes about with \"Merry Christmas\"\\non his lips should be boiled with his own pudding, and buried with a\\nstake of holly through his heart. He should!\\'\\n\\n\\'Uncle!\\' pleaded the nephew.\\n\\n\\'Nephew!\\' returned the uncle sternly, \\'keep Christmas in your own way,\\nand let me keep it in mine.\\'\\n\\n\\'Keep it!\\' repeated Scrooge\\'s nephew. \\'But you don\\'t keep it.\\'\\n\\n\\'Let me leave it alone, then,\\' said Scrooge. \\'Much good may it do you!\\nMuch good it has ever done you!\\'\\n\\n\\'There are many things from which I might have derived good, by which I\\nhave not profited, I dare say,\\' returned the nephew; \\'Christmas among\\nthe rest. But I am sure I have always thought of Christmas-time, when\\nit has come round--apart from the veneration due to its sacred name and\\norigin, if anything belonging to it can be apart from that--as a good\\ntime; a kind, forgiving, charitable, pleasant time; the only time I know\\nof, in the long calendar of the year, when men and women seem by one\\nconsent to open their shut-up hearts freely, and to think of people\\nbelow them as if they really were fellow-passengers to the grave, and\\nnot another race of creatures bound on other journeys. And therefore,\\nuncle, though it has never put a scrap of gold or silver in my pocket, I\\nbelieve that it _has_ done me good and _will_ do me good; and I say, God\\nbless it!\\'\\n\\nThe clerk in the tank involuntarily applauded. Becoming immediately\\nsensible of the impropriety, he poked the fire, and extinguished the\\nlast frail spark for ever.\\n\\n\\'Let me hear another sound from _you_,\\' said Scrooge, \\'and you\\'ll keep\\nyour Christmas by losing your situation! You\\'re quite a powerful\\nspeaker, sir,\\' he added, turning to his nephew. \\'I wonder you don\\'t go\\ninto Parliament.\\'\\n\\n\\'Don\\'t be angry, uncle. Come! Dine with us to-morrow.\\'\\n\\nScrooge said that he would see him----Yes, indeed he did. He went the\\nwhole length of the expression, and said that he would see him in that\\nextremity first.\\n\\n\\'But why?\\' cried Scrooge\\'s nephew. \\'Why?\\'\\n\\n\\'Why did you get married?\\' said Scrooge.\\n\\n\\'Because I fell in love.\\'\\n\\n\\'Because you fell in love!\\' growled Scrooge, as if that were the only\\none thing in the world more ridiculous than a merry Christmas. \\'Good\\nafternoon!\\'\\n\\n\\'Nay, uncle, but you never came to see me before that happened. Why give\\nit as a reason for not coming now?\\'\\n\\n\\'Good afternoon,\\' said Scrooge.\\n\\n\\'I want nothing from you; I ask nothing of you; why cannot we be\\nfriends?\\'\\n\\n\\'Good afternoon!\\' said Scrooge.\\n\\n\\'I am sorry, with all my heart, to find you so resolute. We have never\\nhad any quarrel to which I have been a party. But I have made the trial\\nin homage to Christmas, and I\\'ll keep my Christmas humour to the last.\\nSo A Merry Christmas, uncle!\\'\\n\\n\\'Good afternoon,\\' said Scrooge.\\n\\n\\'And A Happy New Year!\\'\\n\\n\\'Good afternoon!\\' said Scrooge.\\n\\nHis nephew left the room without an angry word, notwithstanding. He\\nstopped at the outer door to bestow the greetings of the season on the\\nclerk, who, cold as he was, was warmer than Scrooge; for he returned\\nthem cordially.\\n\\n\\'There\\'s another fellow,\\' muttered Scrooge, who overheard him: \\'my\\nclerk, with fifteen shillings a week, and a wife and family, talking\\nabout a merry Christmas. I\\'ll retire to Bedlam.\\'\\n\\nThis lunatic, in letting Scrooge\\'s nephew out, had let two other people\\nin. They were portly gentlemen, pleasant to behold, and now stood, with\\ntheir hats off, in Scrooge\\'s office. They had books and papers in their\\nhands, and bowed to him.\\n\\n\\'Scrooge and Marley\\'s, I believe,\\' said one of the gentlemen, referring\\nto his list. \\'Have I the pleasure of addressing Mr. Scrooge, or Mr.\\nMarley?\\'\\n\\n\\'Mr. Marley has been dead these seven years,\\' Scrooge replied. \\'He died\\nseven years ago, this very night.\\'\\n\\n\\'We have no doubt his liberality is well represented by his surviving\\npartner,\\' said the gentleman, presenting his credentials.\\n\\n[Illustration: THEY WERE PORTLY GENTLEMEN, PLEASANT TO BEHOLD]\\n\\nIt certainly was; for they had been two kindred spirits. At the ominous\\nword \\'liberality\\' Scrooge frowned, and shook his head, and handed the\\ncredentials back.\\n\\n\\'At this festive season of the year, Mr. Scro', mimetype='text/plain', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.2889239410776775)], metadata={'ebc403dd3df39bacc3443ef4afb7edfd': {}, '080d8e696ff38c653ca90fa086415e74': {}})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Settings.embed_model = embeddings #OpenAIEmbedding(model='text',api_base=base_url,max_retries=1)\n",
    "Settings.llm=OpenAI(model=model_name,api_base=base_url,max_tokens=max_tokens,max_retries=1)\n",
    "Settings.chunk_size=1200\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# create collection\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store( vector_store )\n",
    "retriever = index.as_retriever()\n",
    "rag_pipline = index.as_query_engine(similarity_top_k=2)\n",
    "\n",
    "rag_pipline.query(\"hello\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = texts['chunk'].tolist()\n",
    "e = embeddings.embed_documents(d)\n",
    "chroma_collection.add(ids=texts['id'].tolist(),documents=d,embeddings=e)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = chroma_collection.get(include=['documents','embeddings'])\n",
    "docs = data['documents']\n",
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\"\"\"docs_llama = []\n",
    "for i,x in texts.iterrows():\n",
    "    c = x['chunk']\n",
    "    docs_llama.append(Document(text=c))\n",
    "    docs_llama[-1].metadata['source']=x['id']\n",
    "    \n",
    "docs_llama \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from llama_index.core.llms import ChatMessage\n",
    "\n",
    "response = Settings.llm.chat([ChatMessage(role=\"user\", content=\"Hello\")])\n",
    "print(response)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "docs_llama = list(map(lambda x:Document(text=x ),docs))\n",
    "docs_llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.prompts.default_prompts import DEFAULT_TEXT_QA_PROMPT,DEFAULT_QUERY_PROMPT,DEFAULT_QUESTION_GENERATION_PROMPT\n",
    "DEFAULT_TEXT_QA_PROMPT\n",
    "DEFAULT_QUESTION_GENERATION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.llama_dataset.generator import RagDatasetGenerator\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "dataset_generator = RagDatasetGenerator.from_documents(\n",
    "    documents=docs_llama[:20],\n",
    "    num_questions_per_chunk=1,\n",
    "    #text_question_template=DEFAULT_QUESTION_GENERATION_PROMPT,\n",
    "    #question_gen_query=DEFAULT_TEXT_QA_PROMPT,\n",
    "    show_progress=True,\n",
    "    workers=1\n",
    "    \n",
    ")\n",
    "\n",
    "len(dataset_generator.nodes) # 1314\n",
    "\n",
    "rag_dataset =  dataset_generator.generate_dataset_from_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference_answer</th>\n",
       "      <th>reference_answer_by</th>\n",
       "      <th>query_by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>**Question:**  What is the ISBN of the book \"A...</td>\n",
       "      <td>[﻿The Project Gutenberg eBook of A Christmas C...</td>\n",
       "      <td>The ISBN of the book \"A Christmas Carol\" as pu...</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>**Question:**  How does the narrator establish...</td>\n",
       "      <td>[and thither in\\n    restless haste and moanin...</td>\n",
       "      <td>The narrator establishes the certainty of Marl...</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>## Quiz Question:</td>\n",
       "      <td>[-fisted hand at the grindstone, Scrooge! a\\ns...</td>\n",
       "      <td>Please provide the quiz question so I can answ...</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>## Quiz Question:</td>\n",
       "      <td>['Bah!' again; and followed it up with 'Humbug...</td>\n",
       "      <td>Please provide the quiz question so I can answ...</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>**Question:**  What is Scrooge's attitude towa...</td>\n",
       "      <td>[have no doubt his liberality is well represen...</td>\n",
       "      <td>Empty Response</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "      <td>ai (gpt-4o)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  **Question:**  What is the ISBN of the book \"A...   \n",
       "1  **Question:**  How does the narrator establish...   \n",
       "2                                  ## Quiz Question:   \n",
       "3                                  ## Quiz Question:   \n",
       "4  **Question:**  What is Scrooge's attitude towa...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [﻿The Project Gutenberg eBook of A Christmas C...   \n",
       "1  [and thither in\\n    restless haste and moanin...   \n",
       "2  [-fisted hand at the grindstone, Scrooge! a\\ns...   \n",
       "3  ['Bah!' again; and followed it up with 'Humbug...   \n",
       "4  [have no doubt his liberality is well represen...   \n",
       "\n",
       "                                    reference_answer reference_answer_by  \\\n",
       "0  The ISBN of the book \"A Christmas Carol\" as pu...         ai (gpt-4o)   \n",
       "1  The narrator establishes the certainty of Marl...         ai (gpt-4o)   \n",
       "2  Please provide the quiz question so I can answ...         ai (gpt-4o)   \n",
       "3  Please provide the quiz question so I can answ...         ai (gpt-4o)   \n",
       "4                                     Empty Response         ai (gpt-4o)   \n",
       "\n",
       "      query_by  \n",
       "0  ai (gpt-4o)  \n",
       "1  ai (gpt-4o)  \n",
       "2  ai (gpt-4o)  \n",
       "3  ai (gpt-4o)  \n",
       "4  ai (gpt-4o)  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = rag_dataset.to_pandas()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query_id': None,\n",
       "  'query': '**Question:**  What is the ISBN of the book \"A Christmas Carol\" as published by J.B. Lippincott Company?',\n",
       "  'gt_answer': 'The ISBN of the book \"A Christmas Carol\" as published by J.B. Lippincott Company is **0-397-00033-2**. \\n',\n",
       "  'response': 'The ISBN of the book is 0-397-00033-2. \\n',\n",
       "  'retrieved_context': [{'text': '\\ufeffThe Project Gutenberg eBook of A Christmas Carol\\n    \\nThis ebook is for the use of anyone anywhere in the United States and\\nmost other parts of the world at no cost and with almost no restrictions\\nwhatsoever. You may copy it, give it away or re-use it under the terms\\nof the Project Gutenberg License included with this ebook or online\\nat www.gutenberg.org. If you are not located in the United States,\\nyou will have to check the laws of the country where you are located\\nbefore using this eBook.\\n\\nTitle: A Christmas Carol\\n\\nAuthor: Charles Dickens\\n\\nIllustrator: Arthur Rackham\\n\\nRelease date: December 24, 2007 [eBook #24022]\\n\\nLanguage: English\\n\\nOriginal publication: Philadelphia and New York: J. B. Lippincott Company,, 1915\\n\\nCredits: Produced by Suzanne Shell, Janet Blenkinship and the Online\\n        Distributed Proofreading Team at http://www.pgdp.net\\n\\n\\n*** START OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL ***\\n\\n\\n\\n\\nProduced by Suzanne Shell, Janet Blenkinship and the Online\\nDistributed Proofreading Team at http://www.pgdp.net\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  A CHRISTMAS CAROL\\n\\n  [Illustration: _\"How now?\" said Scrooge, caustic and cold as ever.\\n  \"What do you want with me?\"_]\\n\\n\\n  A CHRISTMAS CAROL\\n\\n  [Illustration]\\n\\n  BY\\n\\n  CHARLES DICKENS\\n\\n  [Illustration]\\n\\n  ILLUSTRATED BY ARTHUR RACKHAM\\n\\n  [Illustration]\\n\\n  J. B. LIPPINCOTT COMPANY PHILADELPHIA AND NEW YORK\\n\\n  FIRST PUBLISHED 1915\\n\\n  REPRINTED 1923, 1927, 1932, 1933, 1934, 1935, 1947, 1948, 1952, 1958,\\n  1962, 1964, 1966, 1967, 1969, 1971, 1972, 1973\\n\\n  ISBN: 0-397-00033-2\\n\\n  PRINTED IN GREAT BRITAIN\\n\\n\\n\\n\\n  PREFACE\\n\\n  I have endeavoured in this Ghostly little book to raise the Ghost of an\\n  Idea which shall not put my readers out of humour with themselves, with\\n  each other, with the season, or with me. May it haunt their house\\n  pleasantly, and no one wish to lay it.\\n\\n  Their faithful Friend and Servant,\\n\\n  C. D.\\n\\n  _December, 1843._\\n\\n\\n\\n\\n  CHARACTERS\\n\\n  Bob Cratchit, clerk to Ebenezer Scrooge.\\n  Peter Cratchit, a son of the preceding.\\n  Tim Cratchit (\"Tiny Tim\"), a cripple, youngest son of Bob Cratchit.\\n  Mr. Fezziwig, a kind-hearted, jovial old merchant.\\n  Fred, Scrooge\\'s nephew.\\n  Ghost of Christmas Past, a phantom showing things past.\\n  Ghost of Christmas Present, a spirit of a kind, generous,\\n    and hearty nature.\\n  Ghost of Christmas Yet to Come, an apparition showing the shadows\\n    of things which yet may happen.\\n  Ghost of Jacob Marley, a spectre of Scrooge\\'s former partner in business.\\n  Joe, a marine-store dealer and receiver of stolen goods.\\n  Ebenezer Scrooge, a grasping, covetous old man, the surviving partner\\n    of the firm of Scrooge and Marley.\\n  Mr. Topper, a bachelor.\\n  Dick Wilkins, a fellow apprentice of Scrooge\\'s.\\n\\n  Belle, a comely matron, an old sweetheart of Scrooge\\'s.\\n  Caroline, wife of one of Scrooge\\'s debtors.\\n  Mrs. Cratchit, wife of Bob Cratchit.\\n  Belinda and Martha Cratchit, daughters of the preceding.\\n\\n  Mrs. Dilber, a laundress.\\n  Fan, the sister of Scrooge.\\n  Mrs. Fezziwig, the worthy partner of Mr. Fezziwig.\\n\\n\\n\\n\\n  CONTENTS\\n\\n  STAVE ONE--MARLEY\\'S GHOST                                             3\\n  STAVE TWO--THE FIRST OF THE THREE SPIRITS                            37\\n  STAVE THREE--THE SECOND OF THE THREE SPIRITS                         69\\n  STAVE FOUR--THE LAST OF THE SPIRITS                                 111\\n  STAVE FIVE--THE END OF IT                                           137\\n\\n\\n  LIST OF ILLUSTRATIONS\\n\\n  _IN COLOUR_\\n\\n\\n  \"How now?\" said Scrooge, caustic\\n    and cold as ever. \"What do you\\n    want with me?\"                                           _Frontispiece_\\n\\n  Bob Cratchit went down a slide on\\n    Cornhill, at the end of a lane of\\n    boys, twenty times, in honour of\\n    its being Christmas Eve                                           16\\n\\n  Nobody under the bed; nobody in\\n    the closet; nobody in his dressing-gown,\\n    which was hanging up\\n    in a suspicious attitude against\\n    the wall                                                          20\\n\\n  The air was filled with phantoms,\\n   wandering hither and thither in\\n    restless haste and moaning as\\n    they went                                                         32\\n\\n  Then old Fezziwig stood out to\\n    dance with Mrs. Fezziwig                                          54\\n\\n  A flushed and boisterous group                                      62\\n\\n  Laden with Christmas toys and\\n    presents                                                          64\\n\\n  The way he went after that plump\\n    sister in the lace tucker!                                       100\\n\\n  \"How are you?\" said one.\\n',\n",
       "    'doc_id': 'd6583840046247f428a9f02738842a7c'},\n",
       "   {'text': '. \\'A merrier Christmas,\\nBob, my good fellow, than I have given you for many a year! I\\'ll raise\\nyour salary, and endeavour to assist your struggling family, and we will\\ndiscuss your affairs this very afternoon, over a Christmas bowl of\\nsmoking bishop, Bob! Make up the fires and buy another coal-scuttle\\nbefore you dot another i, Bob Cratchit!\\'\\n\\n[Illustration: _\"Now, I\\'ll tell you what, my friend,\" said Scrooge. \"I\\nam not going to stand this sort of thing any longer.\"_]\\n\\nScrooge was better than his word. He did it all, and infinitely more;\\nand to Tiny Tim, who did NOT die, he was a second father. He became as\\ngood a friend, as good a master, and as good a man as the good old\\nCity knew, or any other good old city, town, or borough in the good old\\nworld. Some people laughed to see the alteration in him, but he let them\\nlaugh, and little heeded them; for he was wise enough to know that\\nnothing ever happened on this globe, for good, at which some people did\\nnot have their fill of laughter in the outset; and knowing that such as\\nthese would be blind anyway, he thought it quite as well that they\\nshould wrinkle up their eyes in grins as have the malady in less\\nattractive forms. His own heart laughed, and that was quite enough for\\nhim.\\n\\nHe had no further intercourse with Spirits, but lived upon the\\nTotal-Abstinence Principle ever afterwards; and it was always said of\\nhim that he knew how to keep Christmas well, if any man alive possessed\\nthe knowledge. May that be truly said of us, and all of us! And so, as\\nTiny Tim observed, God bless Us, Every One!\\n\\n[Illustration]\\n\\n+---------------------------------------------------------------+\\n|Transcriber\\'s note: The Contents were added by the transcriber.|\\n+---------------------------------------------------------------+\\n\\n\\n\\n\\n\\n\\n\\n*** END OF THE PROJECT GUTENBERG EBOOK A CHRISTMAS CAROL ***\\n\\n\\n    \\n\\nUpdated editions will replace the previous one—the old editions will\\nbe renamed.\\n\\nCreating the works from print editions not protected by U.S. copyright\\nlaw means that no one owns a United States copyright in these works,\\nso the Foundation (and you!) can copy and distribute it in the United\\nStates without permission and without paying copyright\\nroyalties. Special rules, set forth in the General Terms of Use part\\nof this license, apply to copying and distributing Project\\nGutenberg™ electronic works to protect the PROJECT GUTENBERG™\\nconcept and trademark. Project Gutenberg is a registered trademark,\\nand may not be used if you charge for an eBook, except by following\\nthe terms of the trademark license, including paying royalties for use\\nof the Project Gutenberg trademark. If you do not charge anything for\\ncopies of this eBook, complying with the trademark license is very\\neasy. You may use this eBook for nearly any purpose such as creation\\nof derivative works, reports, performances and research. Project\\nGutenberg eBooks may be modified and printed and given away—you may\\ndo practically ANYTHING in the United States with eBooks not protected\\nby U.S. copyright law. Redistribution is subject to the trademark\\nlicense, especially commercial redistribution.\\n\\n\\nSTART: FULL LICENSE\\n\\nTHE FULL PROJECT GUTENBERG LICENSE\\n\\nPLEASE READ THIS BEFORE YOU DISTRIBUTE OR USE THIS WORK\\n\\nTo protect the Project Gutenberg™ mission of promoting the free\\ndistribution of electronic works, by using or distributing this work\\n(or any other work associated in any way with the phrase “Project\\nGutenberg”), you agree to comply with all the terms of the Full\\nProject Gutenberg™ License available with this file or online at\\nwww.gutenberg.org/license.\\n\\nSection 1. General Terms of Use and Redistributing Project Gutenberg™\\nelectronic works\\n\\n1.A. By reading or using any part of this Project Gutenberg™\\nelectronic work, you indicate that you have read, understand, agree to\\nand accept all the terms of this license and intellectual property\\n(trademark/copyright) agreement. If you do not agree to abide by all\\nthe terms of this agreement, you must cease using and return or\\ndestroy all copies of Project Gutenberg™ electronic works in your\\npossession. If you paid a fee for obtaining a copy of or access to a\\nProject Gutenberg™ electronic work and you do not agree to be bound\\nby the terms of this agreement, you may obtain a refund from the person\\nor entity to whom you paid the fee as set forth in paragraph 1.E.8.\\n\\n1.B. “Project Gutenberg” is a registered trademark. It may only be\\nused on or associated in any way with an electronic work by people who\\nagree to be bound by the terms of this agreement. There are a few\\nthings that you can do with most Project Gutenberg™ electronic works\\neven without complying with the full terms of this agreement. See\\nparagraph 1.C below. There are a lot of things you can do with Project\\nGutenberg™ electronic works if you follow the terms of this\\nagreement and help preserve free future access to Project Gutenberg™\\nelectronic works. See paragraph 1.E below.\\n\\n1.C. The Project Gutenberg Literary Archive Foundation (“the\\nFoundation” or PGLAF), owns a compilation copyright in the collection\\nof Project Gutenberg™ electronic works. Nearly all the individual\\nworks in the collection are in the public domain in the United\\nStates. If an individual work is unprotected by copyright law in the\\nUnited States and you are located in the United States, we do not\\nclaim a right to prevent you from copying, distributing, performing,\\ndisplaying or creating derivative works based',\n",
       "    'doc_id': '2b5ecb7fba1301d1f3d307e194a6c435'}]}]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragchecker.integrations.llama_index import response_to_rag_results\n",
    "\n",
    "\n",
    "rag_result_list = []\n",
    "for i,x in df.iterrows():\n",
    "    response_object = rag_pipline.query(x['query'])\n",
    "    rag_result = response_to_rag_results(\n",
    "    query=x['query'],\n",
    "    gt_answer=x['reference_answer'],\n",
    "    response_object=response_object,\n",
    "    )\n",
    "    rag_result_list.append(rag_result)\n",
    "    break\n",
    "\n",
    "rag_result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGResults(\n",
      "  1 RAG results,\n",
      "  Metrics:\n",
      "  {\n",
      "    \"overall_metrics\": {},\n",
      "    \"retriever_metrics\": {},\n",
      "    \"generator_metrics\": {}\n",
      "  }\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/dataclasses_json/core.py:201: RuntimeWarning: 'NoneType' object value of non-optional type query_id detected when decoding RAGResult.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "rag_results = RAGResults.from_dict({\"results\": [rag_result_list[0]]})\n",
    "print(rag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-03 11:11:18.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mragchecker.evaluator\u001b[0m:\u001b[36mextract_claims\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1mExtracting claims for gt_answer of 2 RAG results.\u001b[0m\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "litellm.RateLimitError: RateLimitError: OpenAIException - Error code: 429 - {'error': {'message': 'litellm.RateLimitError: litellm.RateLimitError: VertexAIException - {\\n  \"error\": {\\n    \"code\": 429,\\n    \"message\": \"Resource has been exhausted (e.g. check quota).\",\\n    \"status\": \"RESOURCE_EXHAUSTED\"\\n  }\\n}\\n\\nReceived Model Group=gpt-4o\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}} [sleep 10 seconds]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:14<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/refchecker/utils.py:156\u001b[0m, in \u001b[0;36mget_model_batch_response\u001b[0;34m(prompts, model, temperature, n_choices, max_new_tokens, api_base, sagemaker_client, sagemaker_params, sagemaker_get_response_func, custom_llm_api_func, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\u001b[38;5;28misinstance\u001b[39m(r, ModelResponse) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m responses])\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_choices \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 26\u001b[0m\n\u001b[1;32m     13\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m RAGChecker(\n\u001b[1;32m     14\u001b[0m     extractor_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[1;32m     15\u001b[0m     checker_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# evaluate results with selected metrics or certain groups, e.g., retriever_metrics, generator_metrics, all_metrics\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(rag_results)\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/ragchecker/evaluator.py:228\u001b[0m, in \u001b[0;36mRAGChecker.evaluate\u001b[0;34m(self, results, metrics, save_path)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# compute the required intermediate results\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m requirement \u001b[38;5;129;01min\u001b[39;00m requirements:\n\u001b[0;32m--> 228\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_claims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequirement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/ragchecker/evaluator.py:158\u001b[0m, in \u001b[0;36mRAGChecker.check_claims\u001b[0;34m(self, results, check_type)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_claims\u001b[39m(\u001b[38;5;28mself\u001b[39m, results: RAGResults, check_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer2response\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    Check the claims extracted from the response and ground truth answer.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;124;03m        or 'retrieved2response'. Default: 'answer2response'.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mmatch\u001b[39;00m check_type:\n\u001b[1;32m    144\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer2response\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    145\u001b[0m             results \u001b[38;5;241m=\u001b[39m [ret \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39manswer2response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    146\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_claims(results, extract_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    147\u001b[0m             claims \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mresponse_claims \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    148\u001b[0m             references \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mgt_answer \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    149\u001b[0m             merge_psg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse2answer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    151\u001b[0m             results \u001b[38;5;241m=\u001b[39m [ret \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mresponse2answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    152\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_claims(results, extract_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt_answer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    153\u001b[0m             claims \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mgt_answer_claims \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    154\u001b[0m             references \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mresponse \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    155\u001b[0m             merge_psg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieved2answer\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    157\u001b[0m             results \u001b[38;5;241m=\u001b[39m [ret \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mretrieved2answer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m--> 158\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_claims\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgt_answer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m             claims \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mgt_answer_claims \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    160\u001b[0m             references \u001b[38;5;241m=\u001b[39m [[doc\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mretrieved_context] \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    161\u001b[0m             merge_psg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieved2response\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    163\u001b[0m             results \u001b[38;5;241m=\u001b[39m [ret \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;28;01mif\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mretrieved2response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_claims(results, extract_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    165\u001b[0m             claims \u001b[38;5;241m=\u001b[39m [ret\u001b[38;5;241m.\u001b[39mresponse_claims \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    166\u001b[0m             references \u001b[38;5;241m=\u001b[39m [[doc\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mretrieved_context] \u001b[38;5;28;01mfor\u001b[39;00m ret \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    167\u001b[0m             merge_psg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[38;5;28;01mcase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01m_\u001b[39;00m:\n\u001b[1;32m    169\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid check_type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheck_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/ragchecker/evaluator.py:114\u001b[0m, in \u001b[0;36mRAGChecker.extract_claims\u001b[0;34m(self, results, extract_type)\u001b[0m\n\u001b[1;32m    111\u001b[0m questions \u001b[38;5;241m=\u001b[39m [result\u001b[38;5;241m.\u001b[39mquery \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results]\n\u001b[1;32m    113\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting claims for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m RAG results.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m extraction_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_responses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_questions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquestions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextractor_max_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m claims \u001b[38;5;241m=\u001b[39m [[c\u001b[38;5;241m.\u001b[39mcontent \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m res\u001b[38;5;241m.\u001b[39mclaims] \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m extraction_results]\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/refchecker/extractor/extractor_base.py:26\u001b[0m, in \u001b[0;36mExtractorBase.extract\u001b[0;34m(self, batch_responses, batch_questions, max_new_tokens, sagemaker_client, sagemaker_params, sagemaker_get_response_func, custom_llm_api_func, **kwargs)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract\u001b[39m(\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     16\u001b[0m     batch_responses, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     24\u001b[0m ):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclaim_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtriplet\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 26\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_claim_triplets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_responses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_responses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_questions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_questions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m            \u001b[49m\u001b[43msagemaker_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclaim_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsentence\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     37\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract_subsentence_claims(\n\u001b[1;32m     38\u001b[0m             batch_responses\u001b[38;5;241m=\u001b[39mbatch_responses,\n\u001b[1;32m     39\u001b[0m             batch_questions\u001b[38;5;241m=\u001b[39mbatch_questions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     46\u001b[0m         )\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/refchecker/extractor/llm_extractor.py:146\u001b[0m, in \u001b[0;36mLLMExtractor.extract_claim_triplets\u001b[0;34m(self, batch_responses, batch_questions, max_new_tokens, sagemaker_client, sagemaker_params, sagemaker_get_response_func, custom_llm_api_func, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(prompt_list), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)):\n\u001b[1;32m    144\u001b[0m     batch_prompts \u001b[38;5;241m=\u001b[39m prompt_list[_i:_i\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[0;32m--> 146\u001b[0m     llm_responses \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_batch_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_choices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_base\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_base\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43msagemaker_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msagemaker_get_response_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_llm_api_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m llm_responses \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(llm_responses):\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m llm_responses:\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/refchecker/utils.py:178\u001b[0m, in \u001b[0;36mget_model_batch_response\u001b[0;34m(prompts, model, temperature, n_choices, max_new_tokens, api_base, sagemaker_client, sagemaker_params, sagemaker_get_response_func, custom_llm_api_func, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexception\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [sleep 10 seconds]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ragchecker import RAGResults, RAGChecker\n",
    "from ragchecker.metrics import all_metrics\n",
    "\n",
    "\n",
    "\n",
    "# Create RAGResults object\n",
    "\n",
    "# initialize ragresults from json/dict\n",
    "\n",
    "with open(\"checking_inputs.json\") as fp:\n",
    "    rag_results = RAGResults.from_json(fp.read())\n",
    "# set-up the evaluator\n",
    "evaluator = RAGChecker(\n",
    "    extractor_name=model_name,\n",
    "    checker_name=model_name,\n",
    "    batch_size_extractor=1,\n",
    "    batch_size_checker=1,\n",
    "    #custom_llm_api_func=generator_llm.invoke,\n",
    "    checker_api_base=base_url,\n",
    "    extractor_api_base=base_url,\n",
    "    \n",
    "    \n",
    ")\n",
    "\n",
    "# evaluate results with selected metrics or certain groups, e.g., retriever_metrics, generator_metrics, all_metrics\n",
    "evaluator.evaluate(rag_results, all_metrics)\n",
    "print(rag_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "docs = []\n",
    "for i,x in texts.iterrows():\n",
    "    c = x['chunk']\n",
    "    docs.append(Document(c))\n",
    "    docs[-1].metadata['source']=x['id']\n",
    "    \n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings,\n",
    "    run_config=runconfig,\n",
    "    chunk_size=1200,\n",
    ")\n",
    "\n",
    "\n",
    "# generate testset\n",
    "message = [{\"role\":\"user\",\"content\":\"what is 2+2?\"}]\n",
    "#res = generator_llm.invoke(message)\n",
    "#res.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import numpy as np\n",
    "x = embeddings([\"hello world!\"])\n",
    "y = np.array(x)\n",
    "y.shape\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25}\n",
    "testset = generator.generate_with_langchain_docs(docs[:5], test_size=10,run_config=runconfig,is_async=True,with_debugging_logs=True,raise_exceptions=False)\n",
    "testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = testset.to_pandas()\n",
    "display(pt)\n",
    "for i,x in pt.iterrows():\n",
    "    print(\"Q: \",x['question'])\n",
    "    print(\"GT: \",x['ground_truth'])\n",
    "    print(\"C: \",x['contexts'])\n",
    "    print('----------------------------')\n",
    "    \n",
    "pt.to_parquet('questions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pt.drop(index=4).reset_index(drop=True)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dd = pd.read_parquet('/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/questions.parquet')\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.evaluation import EvaluationDataset\n",
    "\n",
    "ed = EvaluationDataset.from_orm(dd.to_dict('list'))\n",
    "\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "result = evaluate(\n",
    "    ed,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        #faithfulness,\n",
    "        #answer_relevancy,\n",
    "        #context_recall,\n",
    "    ],\n",
    "\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load graph from .graphml file\n",
    "G = nx.read_graphml('./ragtest/output/embedded_graph.0.graphml')\n",
    "\n",
    "# Draw the graph\n",
    "nx.draw(G, with_labels=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "entity = pd.read_parquet('/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/ragtest/output/create_base_extracted_entities.parquet')\n",
    "unit = pd.read_parquet('/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/ragtest/output/create_base_text_units.parquet')\n",
    "sum = pd.read_parquet('/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/ragtest/output/create_summarized_entities.parquet')\n",
    "entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = \"\"\"The Eiffel Tower is located in Paris. It was designed by Gustave Eiffel in 1887 and is one of the most visited landmarks in the world.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphrag import model,index,llm\n",
    "import graphrag.index\n",
    "import graphrag.llm\n",
    "import graphrag.model\n",
    "\n",
    "graphrag.model.entity.Entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Set your Gemini API Key\n",
    "api_key = \"AIzaSyDcsi9U5RgrnT3BG34Q0SMbbIvBc5kyFG0\"\n",
    "\n",
    "# Define the API URL\n",
    "url = \"http://localhost:8000/v1/chat/completions\"\n",
    "\n",
    "# Define the headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_key}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Define the data payload\n",
    "data = {\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, Who are you?\"}],\n",
    "    \"temperature\": 0.7\n",
    "}\n",
    "\n",
    "# Make the request\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "\n",
    "# Print the response from the server\n",
    "print(response.status_code)\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

21:14:35,733 graphrag.index.cli INFO Logging enabled at /home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph/output/indexing-engine.log
21:14:35,734 graphrag.index.cli INFO Starting pipeline run for: 20241018-211435, dryrun=False
21:14:35,734 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "gpt-4o",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "http://localhost:8080/",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 350000,
        "requests_per_minute": 50,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 5
    },
    "async_mode": "asyncio",
    "root_dir": "/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph",
    "reporting": {
        "type": "file",
        "base_dir": "/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph/output",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "/home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph/output",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "csv",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.csv$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": true,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:8080/",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 350000,
            "requests_per_minute": 10,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 5
        },
        "async_mode": "asyncio",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": true,
        "raw_entities": true,
        "top_level_nodes": true
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:8080/",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 350000,
            "requests_per_minute": 50,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 5
        },
        "async_mode": "asyncio",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "THINGS"
        ],
        "max_gleanings": 2,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:8080/",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 350000,
            "requests_per_minute": 50,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 5
        },
        "async_mode": "asyncio",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:8080/",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 350000,
            "requests_per_minute": 50,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 5
        },
        "async_mode": "asyncio",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "gpt-4o",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:8080/",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 350000,
            "requests_per_minute": 50,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 5
        },
        "async_mode": "asyncio",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": true
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": [
        ""
    ]
}
21:14:35,737 graphrag.index.create_pipeline_config INFO skipping workflows 
21:14:35,737 graphrag.index.run.run INFO Running pipeline
21:14:35,737 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at /home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph/output
21:14:35,739 graphrag.index.input.load_input INFO loading input from root_dir=input
21:14:35,739 graphrag.index.input.load_input INFO using file storage for input
21:14:35,741 graphrag.index.input.csv INFO Loading csv files from input
21:14:35,741 graphrag.index.storage.file_pipeline_storage INFO search /home/cip/ce/ix05ogym/Majid/LLM/GraphRag/elec_graph/input for files matching .*\.csv$
21:14:35,744 graphrag.index.input.csv INFO Found 1 csv files, loading 1
21:14:35,744 graphrag.index.input.csv INFO Total number of unfiltered csv rows: 26
21:14:35,744 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'create_final_relationships', 'create_final_text_units', 'create_final_community_reports', 'create_final_documents']
21:14:35,745 graphrag.index.run.run INFO Final # of rows loaded: 26
21:14:35,852 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
21:14:35,855 datashaper.workflow.workflow INFO executing verb create_base_text_units
21:14:38,246 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
21:14:38,423 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_base_text_units']
21:14:38,423 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
21:14:38,445 datashaper.workflow.workflow INFO executing verb create_base_entity_graph
21:14:38,466 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:8080
21:14:38,508 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for gpt-4o: TPM=350000, RPM=50
21:14:38,508 graphrag.index.llm.load_llm INFO create concurrency limiter for gpt-4o: 25
21:14:42,67 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:42,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.5560935759858694. input_tokens=2467, output_tokens=0
21:14:42,675 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:42,676 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.1643427350209095. input_tokens=2484, output_tokens=909
21:14:48,644 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:48,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.567783694976242. input_tokens=28, output_tokens=1751
21:14:49,242 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:49,244 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5888403459975962. input_tokens=30, output_tokens=1
21:14:52,672 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:52,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.4219222709944006. input_tokens=28, output_tokens=776
21:14:53,138 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:53,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 14.61664355697576. input_tokens=2327, output_tokens=4307
21:14:54,461 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:54,466 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 15.943679735006299. input_tokens=2489, output_tokens=4241
21:14:54,642 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:54,649 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 16.127089132991387. input_tokens=2523, output_tokens=4547
21:14:54,649 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:54,650 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.9593706439773086. input_tokens=2253, output_tokens=357
21:14:54,874 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:54,878 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 12.195319509017281. input_tokens=28, output_tokens=3556
21:14:55,624 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:55,626 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.7379808760015294. input_tokens=30, output_tokens=1
21:14:56,508 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:56,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 1.843950574984774. input_tokens=28, output_tokens=330
21:14:57,3 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:57,5 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 1.3712372849986423. input_tokens=28, output_tokens=155
21:14:57,9 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:57,11 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.4941933850059286. input_tokens=30, output_tokens=1
21:14:59,271 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:14:59,276 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.12867026499589. input_tokens=28, output_tokens=1612
21:15:00,12 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:00,14 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.7301542189961765. input_tokens=30, output_tokens=1
21:15:00,905 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:00,909 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.877575735998107. input_tokens=28, output_tokens=1070
21:15:01,662 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:01,664 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 0.7385047670104541. input_tokens=1699, output_tokens=58
21:15:02,768 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:02,770 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 1.1004824099945836. input_tokens=28, output_tokens=174
21:15:02,781 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:02,785 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.7565683699795045. input_tokens=2287, output_tokens=1850
21:15:03,250 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:03,251 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.4426123040029779. input_tokens=30, output_tokens=1
21:15:03,794 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:03,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 9.322217379987705. input_tokens=28, output_tokens=2591
21:15:04,138 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:04,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 0.8829143820039462. input_tokens=28, output_tokens=133
21:15:04,265 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:04,267 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 4.243572055012919. input_tokens=28, output_tokens=1096
21:15:04,604 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:04,606 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.8005929329956416. input_tokens=30, output_tokens=1
21:15:05,315 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:05,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.0260431520000566. input_tokens=1816, output_tokens=125
21:15:05,631 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:05,636 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 10.977176538028289. input_tokens=28, output_tokens=3017
21:15:05,871 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:05,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.0739886229857802. input_tokens=28, output_tokens=694
21:15:06,487 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:06,489 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.608597117010504. input_tokens=30, output_tokens=1
21:15:06,574 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:06,575 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.9311253729974851. input_tokens=30, output_tokens=1
21:15:07,67 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:07,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 1.746421226998791. input_tokens=28, output_tokens=341
21:15:07,443 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:07,446 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.8310755919956136. input_tokens=28, output_tokens=557
21:15:07,593 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:07,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.425841361982748. input_tokens=2893, output_tokens=892
21:15:09,813 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:15:09,815 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.3114876160107087. input_tokens=28, output_tokens=904
21:15:09,895 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:09,896 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:10,473 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:10,473 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:10,955 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:10,955 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:11,640 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:11,640 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:11,657 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:11,657 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:11,658 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:11,659 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:11,987 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:11,988 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:12,688 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:12,688 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:12,929 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:12,930 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:13,605 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:13,606 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:13,868 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:13,869 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:14,519 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:14,520 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:15,427 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:15,428 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:16,639 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:16,640 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:17,844 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:17,845 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:18,720 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:18,721 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:20,53 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:20,54 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:21,254 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:21,254 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:22,334 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:22,335 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:23,544 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:23,545 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:27,303 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:27,304 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:28,795 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:28,796 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:29,633 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:29,634 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:31,132 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:31,133 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:32,287 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:32,287 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:37,337 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:37,338 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:38,824 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:38,825 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:40,545 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:40,545 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:41,159 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:41,160 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:42,313 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:42,314 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:47,372 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:47,373 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:48,858 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:48,859 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:50,574 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:50,575 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:51,186 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:51,187 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:52,342 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:52,343 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:57,401 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:57,402 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:15:58,888 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:15:58,889 graphrag.llm.base.rate_limiting_llm WARNING extract-loopcheck-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:16:00,611 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:16:00,612 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-1 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:16:01,212 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:16:01,213 graphrag.llm.base.rate_limiting_llm WARNING Process failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:16:02,365 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:16:02,366 graphrag.llm.base.rate_limiting_llm WARNING extract-continuation-0 failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:16:09,872 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:09,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 8 retries took 0.9822948579967488. input_tokens=30, output_tokens=1
21:16:10,743 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:10,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 8 retries took 3.3363457950181328. input_tokens=2102, output_tokens=624
21:16:10,940 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:10,942 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 1.0612740019860212. input_tokens=28, output_tokens=150
21:16:13,199 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:13,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.4482074760016985. input_tokens=28, output_tokens=526
21:16:13,686 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:13,688 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 8 retries took 1.3171740789839532. input_tokens=28, output_tokens=214
21:16:13,768 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:13,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5606252170109656. input_tokens=30, output_tokens=1
21:16:14,108 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:14,111 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 8 retries took 2.895308639999712. input_tokens=2894, output_tokens=435
21:16:14,259 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:14,261 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.299469025019789. input_tokens=2321, output_tokens=628
21:16:14,263 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:14,264 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.568870365008479. input_tokens=30, output_tokens=1
21:16:15,808 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:17,12 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.037253945018165. input_tokens=28, output_tokens=427
21:16:17,49 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:17,100 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:18,187 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:18,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.070273437013384. input_tokens=28, output_tokens=749
21:16:20,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 8 retries took 6.434682654013159. input_tokens=28, output_tokens=1480
21:16:21,797 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.832976141013205. input_tokens=28, output_tokens=665
21:16:23,148 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:23,543 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:23,545 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5445732350053731. input_tokens=30, output_tokens=1
21:16:25,178 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:26,428 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:27,675 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:28,376 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 7.671320744993864. input_tokens=28, output_tokens=2268
21:16:29,580 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 0.4320631640148349. input_tokens=1709, output_tokens=6
21:16:30,783 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.4734133929887321. input_tokens=30, output_tokens=1
21:16:31,589 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:31,985 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 8.287096965010278. input_tokens=2205, output_tokens=2045
21:16:37,408 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:38,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 4.425458816986065. input_tokens=28, output_tokens=983
21:16:38,732 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:39,224 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.0144582529901527. input_tokens=28, output_tokens=472
21:16:39,232 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:41,635 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 5.545813982986147. input_tokens=2322, output_tokens=1213
21:16:41,960 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:43,433 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:43,884 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:43,886 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 1.0479954729962628. input_tokens=30, output_tokens=1
21:16:45,89 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.630407179996837. input_tokens=28, output_tokens=755
21:16:47,499 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.148293335019844. input_tokens=28, output_tokens=1126
21:16:49,920 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.008060876018135. input_tokens=2300, output_tokens=659
21:16:50,789 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:51,723 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:54,264 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:54,743 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.499833226000192. input_tokens=28, output_tokens=943
21:16:55,842 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:55,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.6027608400036115. input_tokens=30, output_tokens=1
21:16:57,147 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.9408979240106419. input_tokens=2438, output_tokens=433
21:16:58,904 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:16:59,559 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.3115274459996726. input_tokens=28, output_tokens=347
21:17:03,831 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:03,975 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:04,231 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:04,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5560303770180326. input_tokens=30, output_tokens=1
21:17:05,596 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 15.13078875100473. input_tokens=28, output_tokens=4546
21:17:06,439 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:06,799 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.21479941700818. input_tokens=28, output_tokens=674
21:17:08,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 1.047916796989739. input_tokens=30, output_tokens=1
21:17:12,74 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:12,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.462160900002345. input_tokens=28, output_tokens=1050
21:17:13,884 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:13,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 4.681795898010023. input_tokens=28, output_tokens=974
21:17:14,205 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:16,299 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.6619976829970255. input_tokens=2120, output_tokens=379
21:17:17,964 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:21,127 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.5846632290049456. input_tokens=28, output_tokens=431
21:17:22,331 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.46482813500915654. input_tokens=30, output_tokens=1
21:17:22,875 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:23,190 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:24,665 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:24,668 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 1.1337979460076895. input_tokens=2178, output_tokens=196
21:17:26,547 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:27,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 4.166227712004911. input_tokens=2188, output_tokens=945
21:17:27,903 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:28,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.272866048006108. input_tokens=28, output_tokens=660
21:17:30,692 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 11.458669788989937. input_tokens=2541, output_tokens=2708
21:17:31,91 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:34,136 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:34,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.0350250330229755. input_tokens=28, output_tokens=511
21:17:34,820 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:36,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 1.6092677410051692. input_tokens=28, output_tokens=350
21:17:37,926 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 1.0344477570033632. input_tokens=30, output_tokens=1
21:17:39,210 graphrag.callbacks.file_workflow_callbacks INFO Error Invoking LLM details={'input': '\n-Goal-\nGiven a text document that is potentially relevant to this activity and identify all entities from the text and all relationships among the identified entities.\n \n-Steps-\n1. Identify all entities. For each identified entity, extract the following information:\n- entity_name: Name of the entity, capitalized\n- entity_type: Which class the entity belogns to? The class has to be an specific term\n- entity_description: Comprehensive description of the entity\'s attributes and activities\nFormat each entity as ("entity"<|><entity_name><|><entity_type><|><entity_description>)\n \n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\nFor each pair of related entities, extract the following information:\n- source_entity: name of the source entity, as identified in step 1\n- target_entity: name of the target entity, as identified in step 1\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\n Format each relationship as ("relationship"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\n \n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\n \n4. When finished, output <|COMPLETE|>\n \n######################\n-Examples-\n######################\nExample 1:\nText:\nThe Verdantis\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\n######################\nOutput:\n("entity"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\n##\n("entity"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\n##\n("entity"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\'s money supply)\n##\n("relationship"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\n<|COMPLETE|>\n\n######################\nExample 2:\nText:\nTechGlobal\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\'s debut on the public markets isn\'t indicative of how other newly listed companies may perform.\n\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\n######################\nOutput:\n("entity"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\n##\n("entity"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\n##\n("relationship"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\n<|COMPLETE|>\n\n######################\nExample 3:\nText:\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\n\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\n\nThe exchange initiated in Firuzabad\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\n\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\'s capital, Cashion.\n\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\n######################\nOutput:\n("entity"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\n##\n("entity"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\n##\n("entity"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\n##\n##\n("entity"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\n##\n("entity"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\n##\n("entity"<|>CASHION<|>GEO<|>Capital city in Aurelia)\n##\n("entity"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\'s Alhamia Prison)\n##\n("entity"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\n##\n("entity"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\n##\n("entity"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\n##\n("relationship"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\n##\n("relationship"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\n##\n("relationship"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\n##\n("relationship"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\n<|COMPLETE|>\n######################\n-Real Data-\n######################\nText:\nby\n\n186 SC SOLDERING PROCESSES\n\n186 SC SOLDERING PROCESSES Photo 8.6 Hot gas/air soldering machine, used typically in rework or individual component placement (Planer Industrial) @ soldering irons  conventional soldering irons with specially shaped tips. Comparison of soldering processes All SC soldering processes are compared in Appendix 4, along with CS soldering processes.\n\nPreface   Electronics assembly is about components that are soldered onto a printed   circuit board.  Soldering, as a principle  in electronics assembly, is straight-   forward  and simple m  two  metal surfaces (component termination  and a   connecting pad on printed circuit board track) are joined by metallic bonds   created by molten solder between them. Solder joints are supported by the   solder when  it solidifies,  and the solder allows electrical  contact between   metals in the joints.  Surface mounted components are changing, they are   becoming  smaller  and  lighter and  in the case of ICs due to the  increased   demands of functionality,  they also  have a greater number of  leads. This   dimensional  and  weight  change  is  driven  by  the  increase in  demand  of   portable  products.  Table  I  shows the  growth  in  unit  terms for  portable   products over the coming years.   The other sectors illustrated  harsh environment,  low cost/high value and   high  performance  cut across the traditional  market  boundaries and focus   more on the products technology requirement (Figure I).   Increasingly,  a number of companies are adopting one particular pack-   aging strategy m  that of small form-factor  components  ideal  for  portable   products.  These are  increasingly  being  used in  larger electronic  systems   such as exchanges, base stations etc  as a company  wishes to  adopt one   packaging strategy and hence assembly strategy for all types of products that   they manufacture.  This has obvious benefits with  regards to stock holding   Table  1 Total equipment quantities by global technology roadmap sectors 1997-2007   1997   2 0 0 2    2 0 0 7    x  lO 6   %   x  l O  6   %   x  lO 6   1710   4480   57.2   Portables   45.1   7480   %   !   63.3   High performance   460   12.2   840   10.7   990   8.4   Harsh environment   275   7.3   670   8.6   1190   10.0   Low cost, high volume   1340   35.4   1840   23.5   2160   18.3   Total   3785   1 0 0 . 0   7830   1 0 0 . 0    1 1 8 2 0   100.0\n######################\nOutput:'}
21:17:41,419 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:41,547 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.927732952986844. input_tokens=28, output_tokens=648
21:17:41,600 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:44,456 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:45,645 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:46,382 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 1.0821976559818722. input_tokens=30, output_tokens=1
21:17:47,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 6.087540189997526. input_tokens=28, output_tokens=1397
21:17:48,788 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 1.7085557949903887. input_tokens=28, output_tokens=313
21:17:49,991 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.47395688298274763. input_tokens=30, output_tokens=1
21:17:50,568 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:53,152 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:54,100 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:56,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 1 retries took 6.605005726974923. input_tokens=2360, output_tokens=1740
21:17:57,234 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.7508451139729004. input_tokens=30, output_tokens=1
21:17:57,540 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:58,306 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:17:58,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 3.486059554008534. input_tokens=2640, output_tokens=872
21:17:59,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.908221609017346. input_tokens=28, output_tokens=849
21:18:04,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 3.9297903970000334. input_tokens=28, output_tokens=906
21:18:05,319 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:05,795 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:07,621 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:07,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.606800148001639. input_tokens=28, output_tokens=1201
21:18:08,843 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:09,162 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 2.663541241985513. input_tokens=28, output_tokens=495
21:18:10,364 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 5.699408934015082. input_tokens=28, output_tokens=1306
21:18:12,146 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:12,336 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:12,776 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.093717209994793. input_tokens=2408, output_tokens=522
21:18:14,486 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:17,308 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:17,602 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5805186610086821. input_tokens=30, output_tokens=1
21:18:18,805 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 6.794348976021865. input_tokens=2080, output_tokens=2265
21:18:20,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5098701840033755. input_tokens=30, output_tokens=1
21:18:21,21 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:21,211 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 2.1218122970021795. input_tokens=2041, output_tokens=444
21:18:24,543 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:26,672 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:27,248 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.628436045022681. input_tokens=28, output_tokens=1156
21:18:27,641 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:28,452 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.131265912001254. input_tokens=28, output_tokens=444
21:18:29,203 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:29,655 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 1.8432785689947195. input_tokens=28, output_tokens=409
21:18:31,352 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:32,67 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 4.0206008440000005. input_tokens=28, output_tokens=748
21:18:34,476 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 3.164985576993786. input_tokens=28, output_tokens=724
21:18:36,336 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:36,888 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.4960184230003506. input_tokens=30, output_tokens=1
21:18:38,594 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:39,300 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.6591725279868115. input_tokens=30, output_tokens=1
21:18:40,640 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:41,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.5056017710012384. input_tokens=30, output_tokens=1
21:18:44,127 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 7.372186085995054. input_tokens=2451, output_tokens=1518
21:18:44,573 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:47,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 4.071730711002601. input_tokens=28, output_tokens=1000
21:18:48,70 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:49,275 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 2.7434772300184704. input_tokens=28, output_tokens=490
21:18:52,355 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:52,360 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 5.817442307015881. input_tokens=28, output_tokens=1201
21:18:53,29 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:53,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-loopcheck-0" with 0 retries took 0.6644660909951199. input_tokens=30, output_tokens=1
21:18:56,427 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:18:56,432 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 13.511618951975834. input_tokens=28, output_tokens=4320
21:19:01,360 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:01,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-1" with 0 retries took 7.121263878972968. input_tokens=28, output_tokens=1548
21:19:02,71 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:02,73 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6680725810001604. input_tokens=170, output_tokens=31
21:19:02,472 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:02,655 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:03,689 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:04,488 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:05,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0721887870167848. input_tokens=600, output_tokens=162
21:19:05,756 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:06,892 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.213714904995868. input_tokens=500, output_tokens=269
21:19:08,94 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2509423659939785. input_tokens=170, output_tokens=48
21:19:09,297 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 2.28734881800483. input_tokens=1962, output_tokens=350
21:19:11,578 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:11,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0773576489882544. input_tokens=278, output_tokens=133
21:19:12,782 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2753632229869254. input_tokens=419, output_tokens=195
21:19:14,723 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:15,749 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:16,908 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:18,171 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:19,478 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:20,25 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7384614130132832. input_tokens=257, output_tokens=94
21:19:21,227 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5570275290228892. input_tokens=153, output_tokens=18
21:19:22,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5079902550205588. input_tokens=162, output_tokens=37
21:19:23,632 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5628528390079737. input_tokens=176, output_tokens=39
21:19:24,836 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6627336539968383. input_tokens=166, output_tokens=54
21:19:27,33 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:27,809 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:29,337 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:29,339 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8853862209944054. input_tokens=600, output_tokens=0
21:19:30,221 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:31,577 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:32,75 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9966633330041077. input_tokens=153, output_tokens=17
21:19:33,277 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.565146809007274. input_tokens=167, output_tokens=37
21:19:35,110 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:35,687 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5622094430145808. input_tokens=173, output_tokens=33
21:19:36,891 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7116067729948554. input_tokens=284, output_tokens=113
21:19:38,626 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:40,193 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:40,508 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6333580979844555. input_tokens=160, output_tokens=35
21:19:42,195 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:43,411 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:44,124 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5347759409924038. input_tokens=155, output_tokens=30
21:19:45,808 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:46,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8942784130049404. input_tokens=507, output_tokens=163
21:19:47,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4866867199889384. input_tokens=163, output_tokens=41
21:19:48,940 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4957569800026249. input_tokens=159, output_tokens=38
21:19:50,937 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:51,351 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4833801760105416. input_tokens=159, output_tokens=33
21:19:53,958 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:54,981 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:55,621 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:56,797 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:19:57,385 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7964206160104368. input_tokens=163, output_tokens=49
21:19:58,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2201371709816158. input_tokens=165, output_tokens=62
21:19:59,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.405724057025509. input_tokens=158, output_tokens=37
21:20:00,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6536625089938752. input_tokens=191, output_tokens=53
21:20:02,195 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6213487439963501. input_tokens=165, output_tokens=36
21:20:04,148 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:05,208 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:06,587 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:07,656 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:08,868 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:09,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7510368679941166. input_tokens=162, output_tokens=34
21:20:10,638 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.603105857007904. input_tokens=165, output_tokens=38
21:20:11,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7750579930143431. input_tokens=161, output_tokens=81
21:20:13,43 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6370787360065151. input_tokens=161, output_tokens=37
21:20:14,246 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6413296080136206. input_tokens=268, output_tokens=88
21:20:16,463 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:16,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0174627119849902. input_tokens=164, output_tokens=24
21:20:18,125 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:19,387 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:20,567 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:21,915 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:23,7 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:23,709 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.45847479900112376. input_tokens=171, output_tokens=24
21:20:24,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5117342860030476. input_tokens=154, output_tokens=29
21:20:26,113 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4828692589944694. input_tokens=162, output_tokens=16
21:20:27,317 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6231732440064661. input_tokens=165, output_tokens=39
21:20:28,519 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.506766068021534. input_tokens=157, output_tokens=16
21:20:30,265 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:31,504 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:32,745 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:33,966 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:35,63 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:35,762 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5452276129799429. input_tokens=145, output_tokens=20
21:20:36,964 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5759198500018101. input_tokens=185, output_tokens=48
21:20:38,167 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6089816750027239. input_tokens=181, output_tokens=58
21:20:39,370 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6212068949826062. input_tokens=162, output_tokens=48
21:20:40,573 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5111275230010506. input_tokens=157, output_tokens=24
21:20:42,436 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:43,510 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:44,918 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:45,992 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:47,106 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:47,816 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6615282200218644. input_tokens=147, output_tokens=18
21:20:49,18 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5282877369900234. input_tokens=159, output_tokens=25
21:20:50,220 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7278467620199081. input_tokens=144, output_tokens=22
21:20:51,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5944694819918368. input_tokens=214, output_tokens=73
21:20:52,625 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5002150939835701. input_tokens=141, output_tokens=22
21:20:55,426 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:56,149 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:56,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1143994869780727. input_tokens=162, output_tokens=26
21:20:57,993 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:20:59,246 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:00,258 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:00,976 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5999291779880878. input_tokens=300, output_tokens=124
21:21:02,863 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:03,385 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6417423559760209. input_tokens=144, output_tokens=34
21:21:04,587 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6879993079928681. input_tokens=287, output_tokens=89
21:21:05,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.49053728400031105. input_tokens=150, output_tokens=33
21:21:07,764 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:08,200 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6871291490097065. input_tokens=193, output_tokens=72
21:21:09,849 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:11,212 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:12,284 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:13,21 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7744742989889346. input_tokens=196, output_tokens=79
21:21:15,430 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.44943395198788494. input_tokens=146, output_tokens=15
21:21:15,518 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:16,633 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6027580270019826. input_tokens=200, output_tokens=67
21:21:17,836 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.466970395995304. input_tokens=147, output_tokens=27
21:21:19,754 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:20,865 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:21,453 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.2975157200125977. input_tokens=453, output_tokens=249
21:21:23,391 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:24,605 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:25,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7185065560042858. input_tokens=199, output_tokens=64
21:21:27,261 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:27,263 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9902293129998725. input_tokens=462, output_tokens=166
21:21:28,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.621077427000273. input_tokens=190, output_tokens=56
21:21:29,666 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.738040138996439. input_tokens=220, output_tokens=89
21:21:30,868 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7450946760072839. input_tokens=195, output_tokens=90
21:21:32,494 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:33,806 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:35,108 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:37,191 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:37,833 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:38,106 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4244340249861125. input_tokens=135, output_tokens=14
21:21:39,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5292894279991742. input_tokens=150, output_tokens=26
21:21:40,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6232764989836141. input_tokens=198, output_tokens=76
21:21:41,712 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.5027503730088938. input_tokens=892, output_tokens=371
21:21:42,915 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.936817907000659. input_tokens=569, output_tokens=174
21:21:45,436 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:46,473 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:46,475 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1475402069918346. input_tokens=199, output_tokens=72
21:21:48,838 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:48,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1621318649849854. input_tokens=372, output_tokens=199
21:21:51,216 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:51,219 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.174813407997135. input_tokens=470, output_tokens=247
21:21:53,214 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:53,631 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.3195130489766598. input_tokens=477, output_tokens=112
21:21:55,921 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:55,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.088614337000763. input_tokens=184, output_tokens=51
21:21:57,812 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:59,91 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:21:59,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7946025359851774. input_tokens=430, output_tokens=117
21:22:01,298 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:02,717 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:03,156 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6892364590021316. input_tokens=190, output_tokens=68
21:22:05,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.760887765994994. input_tokens=169, output_tokens=74
21:22:06,312 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:06,768 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.559444510989124. input_tokens=182, output_tokens=58
21:22:07,970 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7701796019973699. input_tokens=225, output_tokens=90
21:22:09,712 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:11,32 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:11,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9551180860144086. input_tokens=703, output_tokens=453
21:22:13,325 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:14,581 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:15,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5413314340112265. input_tokens=154, output_tokens=31
21:22:16,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6528830089955591. input_tokens=211, output_tokens=80
21:22:18,134 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:18,817 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5369859430065844. input_tokens=173, output_tokens=38
21:22:20,19 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5850385049998295. input_tokens=169, output_tokens=44
21:22:21,769 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:22,896 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:23,637 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5272018469986506. input_tokens=160, output_tokens=35
21:22:25,520 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:26,531 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:27,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.54870633999235. input_tokens=171, output_tokens=45
21:22:28,457 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4686346869857516. input_tokens=167, output_tokens=30
21:22:30,156 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:30,867 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.682079619000433. input_tokens=222, output_tokens=81
21:22:32,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48621083100442775. input_tokens=198, output_tokens=36
21:22:33,877 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:33,879 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6076185830170289. input_tokens=152, output_tokens=0
21:22:34,960 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:35,687 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.49963441700674593. input_tokens=198, output_tokens=52
21:22:37,376 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:38,580 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:39,972 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:40,508 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4828025019960478. input_tokens=137, output_tokens=23
21:22:42,186 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:42,920 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4886716369946953. input_tokens=205, output_tokens=45
21:22:44,122 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48882493100245483. input_tokens=159, output_tokens=24
21:22:45,324 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6735255769744981. input_tokens=240, output_tokens=78
21:22:46,994 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:47,735 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.47590539199882187. input_tokens=155, output_tokens=25
21:22:49,375 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:50,591 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:51,912 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:53,0 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:22:53,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4687022859870922. input_tokens=159, output_tokens=27
21:22:54,972 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4394760599825531. input_tokens=139, output_tokens=15
21:22:56,174 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4481477359950077. input_tokens=160, output_tokens=29
21:22:57,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5614363870117813. input_tokens=190, output_tokens=45
21:22:58,579 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.44145597401075065. input_tokens=148, output_tokens=23
21:23:00,796 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:00,798 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0164111859921832. input_tokens=177, output_tokens=42
21:23:02,459 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:03,687 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:04,858 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:06,298 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:07,354 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:08,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.460015327000292. input_tokens=162, output_tokens=29
21:23:09,243 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4791039109986741. input_tokens=144, output_tokens=14
21:23:10,445 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4413868180126883. input_tokens=150, output_tokens=15
21:23:11,648 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6735816230066121. input_tokens=142, output_tokens=11
21:23:12,851 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5224037769949064. input_tokens=142, output_tokens=24
21:23:14,486 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:15,754 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:16,908 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:18,170 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:19,752 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:20,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4341236689942889. input_tokens=138, output_tokens=8
21:23:21,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4951919729937799. input_tokens=149, output_tokens=24
21:23:22,495 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4408266640093643. input_tokens=137, output_tokens=16
21:23:23,697 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.49588235598639585. input_tokens=141, output_tokens=12
21:23:24,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8696896620094776. input_tokens=387, output_tokens=163
21:23:27,291 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:27,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1909145410172641. input_tokens=241, output_tokens=94
21:23:29,171 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:30,320 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:31,695 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:32,848 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:33,819 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:34,534 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6761694500164595. input_tokens=257, output_tokens=80
21:23:35,736 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6188959910068661. input_tokens=227, output_tokens=79
21:23:36,938 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.78528694898705. input_tokens=324, output_tokens=149
21:23:38,140 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7304657179920468. input_tokens=310, output_tokens=113
21:23:39,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4942878699803259. input_tokens=165, output_tokens=27
21:23:41,450 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:42,440 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:43,469 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:44,612 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:45,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9070467540004756. input_tokens=306, output_tokens=143
21:23:46,807 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:47,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6898984909930732. input_tokens=181, output_tokens=63
21:23:48,667 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5133242190058809. input_tokens=168, output_tokens=30
21:23:49,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4485541219764855. input_tokens=145, output_tokens=17
21:23:51,540 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:52,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5494633700000122. input_tokens=148, output_tokens=23
21:23:53,939 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:55,126 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:56,369 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:57,107 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.46995042098569684. input_tokens=144, output_tokens=11
21:23:58,786 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:23:59,517 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.45838562201242894. input_tokens=142, output_tokens=14
21:24:00,719 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.43664662798983045. input_tokens=146, output_tokens=12
21:24:01,922 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.47156995499972254. input_tokens=147, output_tokens=19
21:24:03,708 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:04,332 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4783141770167276. input_tokens=149, output_tokens=23
21:24:06,20 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:07,256 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:08,437 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:09,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5863756170147099. input_tokens=150, output_tokens=21
21:24:11,17 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:11,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48815457298769616. input_tokens=144, output_tokens=15
21:24:12,764 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5170997510140296. input_tokens=153, output_tokens=22
21:24:13,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.49566309800138697. input_tokens=150, output_tokens=24
21:24:15,995 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:16,375 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6661131579894572. input_tokens=151, output_tokens=26
21:24:18,57 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:19,381 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:20,535 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:21,721 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:22,409 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.828639549028594. input_tokens=238, output_tokens=111
21:24:23,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48120037201442756. input_tokens=161, output_tokens=33
21:24:24,813 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5977686189871747. input_tokens=166, output_tokens=46
21:24:26,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5436316620034631. input_tokens=164, output_tokens=41
21:24:27,217 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5221566010150127. input_tokens=168, output_tokens=43
21:24:29,408 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:30,521 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:31,581 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:32,564 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:33,909 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:34,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.989071347983554. input_tokens=349, output_tokens=133
21:24:35,663 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8945487890159711. input_tokens=299, output_tokens=169
21:24:36,866 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7467812079994474. input_tokens=234, output_tokens=102
21:24:38,68 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5221743930014782. input_tokens=169, output_tokens=47
21:24:39,271 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.658683868998196. input_tokens=217, output_tokens=83
21:24:41,3 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:42,229 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:43,364 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:44,597 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:45,794 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:46,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5308010980079416. input_tokens=147, output_tokens=37
21:24:47,716 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5486989810015075. input_tokens=149, output_tokens=26
21:24:48,919 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.47587093399488367. input_tokens=157, output_tokens=26
21:24:50,121 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5019044409855269. input_tokens=153, output_tokens=22
21:24:51,324 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4905054770060815. input_tokens=152, output_tokens=25
21:24:53,511 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:53,513 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.9867953259963542. input_tokens=151, output_tokens=19
21:24:55,369 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:56,362 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:57,675 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:58,949 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:24:59,978 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:00,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6555331590061542. input_tokens=227, output_tokens=79
21:25:01,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.44127709002350457. input_tokens=149, output_tokens=21
21:25:03,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5452741360059008. input_tokens=141, output_tokens=25
21:25:04,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6123266440117732. input_tokens=145, output_tokens=30
21:25:05,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4332379939733073. input_tokens=142, output_tokens=12
21:25:07,600 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:08,656 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:09,890 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:11,106 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:12,627 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:12,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8343298999825493. input_tokens=150, output_tokens=15
21:25:14,8 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6826107079978101. input_tokens=190, output_tokens=69
21:25:15,210 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7089212550199591. input_tokens=229, output_tokens=74
21:25:16,413 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.7175631930003874. input_tokens=187, output_tokens=65
21:25:17,616 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.031214173999615. input_tokens=167, output_tokens=54
21:25:19,345 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:20,656 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:21,739 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:22,901 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:24,245 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:24,859 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5278067809995264. input_tokens=178, output_tokens=37
21:25:26,61 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6308669320133049. input_tokens=158, output_tokens=45
21:25:27,263 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5037885749770794. input_tokens=169, output_tokens=36
21:25:28,465 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.45949892498902045. input_tokens=165, output_tokens=26
21:25:29,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5966001669876277. input_tokens=167, output_tokens=44
21:25:31,411 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:32,619 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:33,937 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:35,319 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:36,601 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:36,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5411660649988335. input_tokens=168, output_tokens=22
21:25:38,112 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5409687520004809. input_tokens=174, output_tokens=47
21:25:39,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6512614559906069. input_tokens=175, output_tokens=59
21:25:40,517 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8256539209978655. input_tokens=202, output_tokens=85
21:25:41,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.8992913929978386. input_tokens=209, output_tokens=89
21:25:43,982 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:43,984 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0616593029990327. input_tokens=168, output_tokens=32
21:25:45,631 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:47,79 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:48,130 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:49,451 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:50,635 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:51,225 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.44545531101175584. input_tokens=161, output_tokens=25
21:25:52,429 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.685535111988429. input_tokens=211, output_tokens=57
21:25:53,632 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5290489320177585. input_tokens=200, output_tokens=48
21:25:54,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.643620072019985. input_tokens=185, output_tokens=53
21:25:56,38 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6197293250006624. input_tokens=164, output_tokens=46
21:25:58,367 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:25:58,369 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.128449306008406. input_tokens=158, output_tokens=28
21:26:00,82 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:01,210 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:02,523 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:03,718 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:04,919 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:04,921 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.516149481991306. input_tokens=178, output_tokens=0
21:26:05,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5121854050084949. input_tokens=159, output_tokens=31
21:26:06,813 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4317493570270017. input_tokens=153, output_tokens=12
21:26:08,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5355611720005982. input_tokens=163, output_tokens=40
21:26:09,217 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.519066570996074. input_tokens=167, output_tokens=37
21:26:11,593 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:11,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.1751076530199498. input_tokens=151, output_tokens=37
21:26:13,809 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:14,468 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:15,850 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:16,960 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:18,134 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:18,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0145764229819179. input_tokens=167, output_tokens=37
21:26:20,31 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.46532707099686377. input_tokens=155, output_tokens=24
21:26:21,233 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.640077644988196. input_tokens=137, output_tokens=29
21:26:22,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5424078289943282. input_tokens=137, output_tokens=26
21:26:23,640 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5098485260095913. input_tokens=176, output_tokens=31
21:26:25,915 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:25,917 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0730077259941027. input_tokens=136, output_tokens=23
21:26:27,636 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:28,945 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:30,120 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:31,230 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:32,424 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:33,152 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5181018799776211. input_tokens=138, output_tokens=30
21:26:34,354 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.6196166669833474. input_tokens=137, output_tokens=37
21:26:35,556 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5874528000131249. input_tokens=136, output_tokens=38
21:26:36,758 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4944760960061103. input_tokens=162, output_tokens=31
21:26:37,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48112175698042847. input_tokens=168, output_tokens=37
21:26:40,170 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:40,895 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:42,93 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:43,267 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:44,479 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:26:45,202 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.0083267570007592. input_tokens=161, output_tokens=30
21:26:46,405 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5261923180078156. input_tokens=151, output_tokens=29
21:26:47,607 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.5165219589835033. input_tokens=172, output_tokens=27
21:26:48,810 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.4816307989822235. input_tokens=163, output_tokens=21
21:26:50,12 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 0.48718437398201786. input_tokens=167, output_tokens=24
21:26:50,126 root INFO Starting preprocessing of transition probabilities on graph with 338 nodes and 534 edges
21:26:50,126 root INFO Starting at time 1729279610.126738
21:26:50,126 root INFO Beginning preprocessing of transition probabilities for 338 vertices
21:26:50,126 root INFO Completed 1 / 338 vertices
21:26:50,127 root INFO Completed 34 / 338 vertices
21:26:50,128 root INFO Completed 67 / 338 vertices
21:26:50,129 root INFO Completed 100 / 338 vertices
21:26:50,130 root INFO Completed 133 / 338 vertices
21:26:50,130 root INFO Completed 166 / 338 vertices
21:26:50,131 root INFO Completed 199 / 338 vertices
21:26:50,132 root INFO Completed 232 / 338 vertices
21:26:50,133 root INFO Completed 265 / 338 vertices
21:26:50,134 root INFO Completed 298 / 338 vertices
21:26:50,135 root INFO Completed 331 / 338 vertices
21:26:50,136 root INFO Completed preprocessing of transition probabilities for vertices
21:26:50,137 root INFO Beginning preprocessing of transition probabilities for 534 edges
21:26:50,137 root INFO Completed 1 / 534 edges
21:26:50,139 root INFO Completed 54 / 534 edges
21:26:50,140 root INFO Completed 107 / 534 edges
21:26:50,144 root INFO Completed 160 / 534 edges
21:26:50,149 root INFO Completed 213 / 534 edges
21:26:50,151 root INFO Completed 266 / 534 edges
21:26:50,151 root INFO Completed 319 / 534 edges
21:26:50,152 root INFO Completed 372 / 534 edges
21:26:50,153 root INFO Completed 425 / 534 edges
21:26:50,153 root INFO Completed 478 / 534 edges
21:26:50,154 root INFO Completed 531 / 534 edges
21:26:50,154 root INFO Completed preprocessing of transition probabilities for edges
21:26:50,155 root INFO Simulating walks on graph at time 1729279610.1558306
21:26:50,156 root INFO Walk iteration: 1/10
21:26:50,167 root INFO Walk iteration: 2/10
21:26:50,178 root INFO Walk iteration: 3/10
21:26:50,188 root INFO Walk iteration: 4/10
21:26:50,198 root INFO Walk iteration: 5/10
21:26:50,209 root INFO Walk iteration: 6/10
21:26:50,219 root INFO Walk iteration: 7/10
21:26:50,229 root INFO Walk iteration: 8/10
21:26:50,239 root INFO Walk iteration: 9/10
21:26:50,249 root INFO Walk iteration: 10/10
21:26:50,259 root INFO Learning embeddings at time 1729279610.2590714
21:26:50,260 gensim.models.word2vec INFO collecting all words and their counts
21:26:50,260 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
21:26:50,262 gensim.models.word2vec INFO collected 338 word types from a corpus of 65800 raw words and 3380 sentences
21:26:50,262 gensim.models.word2vec INFO Creating a fresh vocabulary
21:26:50,263 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 338 unique words (100.00% of original 338, drops 0)', 'datetime': '2024-10-18T21:26:50.263309', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,263 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 65800 word corpus (100.00% of original 65800, drops 0)', 'datetime': '2024-10-18T21:26:50.263923', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,264 gensim.models.word2vec INFO deleting the raw counts dictionary of 338 items
21:26:50,264 gensim.models.word2vec INFO sample=0.001 downsamples 93 most-common words
21:26:50,264 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 40976.56144064161 word corpus (62.3%% of prior 65800)', 'datetime': '2024-10-18T21:26:50.264705', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,265 gensim.models.word2vec INFO estimated required memory for 338 words and 1536 dimensions: 4322344 bytes
21:26:50,265 gensim.models.word2vec INFO resetting layer weights
21:26:50,266 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-18T21:26:50.266900', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'build_vocab'}
21:26:50,266 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 338 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-10-18T21:26:50.266937', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:50,329 gensim.models.word2vec INFO EPOCH 0: training on 65800 raw words (40883 effective words) took 0.1s, 684189 effective words/s
21:26:50,393 gensim.models.word2vec INFO EPOCH 1: training on 65800 raw words (40953 effective words) took 0.1s, 654895 effective words/s
21:26:50,456 gensim.models.word2vec INFO EPOCH 2: training on 65800 raw words (40870 effective words) took 0.1s, 682708 effective words/s
21:26:50,456 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 197400 raw words (122706 effective words) took 0.2s, 648300 effective words/s', 'datetime': '2024-10-18T21:26:50.456241', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:50,456 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=338, vector_size=1536, alpha=0.025>', 'datetime': '2024-10-18T21:26:50.456297', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'created'}
21:26:50,456 root INFO Completed. Ending time is 1729279610.456473 Elapsed time is -0.32973504066467285
21:26:50,488 root INFO Starting preprocessing of transition probabilities on graph with 338 nodes and 534 edges
21:26:50,488 root INFO Starting at time 1729279610.4885886
21:26:50,488 root INFO Beginning preprocessing of transition probabilities for 338 vertices
21:26:50,488 root INFO Completed 1 / 338 vertices
21:26:50,488 root INFO Completed 34 / 338 vertices
21:26:50,490 root INFO Completed 67 / 338 vertices
21:26:50,490 root INFO Completed 100 / 338 vertices
21:26:50,491 root INFO Completed 133 / 338 vertices
21:26:50,492 root INFO Completed 166 / 338 vertices
21:26:50,493 root INFO Completed 199 / 338 vertices
21:26:50,494 root INFO Completed 232 / 338 vertices
21:26:50,495 root INFO Completed 265 / 338 vertices
21:26:50,496 root INFO Completed 298 / 338 vertices
21:26:50,497 root INFO Completed 331 / 338 vertices
21:26:50,498 root INFO Completed preprocessing of transition probabilities for vertices
21:26:50,499 root INFO Beginning preprocessing of transition probabilities for 534 edges
21:26:50,499 root INFO Completed 1 / 534 edges
21:26:50,502 root INFO Completed 54 / 534 edges
21:26:50,503 root INFO Completed 107 / 534 edges
21:26:50,509 root INFO Completed 160 / 534 edges
21:26:50,514 root INFO Completed 213 / 534 edges
21:26:50,516 root INFO Completed 266 / 534 edges
21:26:50,517 root INFO Completed 319 / 534 edges
21:26:50,518 root INFO Completed 372 / 534 edges
21:26:50,519 root INFO Completed 425 / 534 edges
21:26:50,520 root INFO Completed 478 / 534 edges
21:26:50,520 root INFO Completed 531 / 534 edges
21:26:50,521 root INFO Completed preprocessing of transition probabilities for edges
21:26:50,521 root INFO Simulating walks on graph at time 1729279610.521327
21:26:50,521 root INFO Walk iteration: 1/10
21:26:50,532 root INFO Walk iteration: 2/10
21:26:50,542 root INFO Walk iteration: 3/10
21:26:50,553 root INFO Walk iteration: 4/10
21:26:50,563 root INFO Walk iteration: 5/10
21:26:50,573 root INFO Walk iteration: 6/10
21:26:50,583 root INFO Walk iteration: 7/10
21:26:50,594 root INFO Walk iteration: 8/10
21:26:50,604 root INFO Walk iteration: 9/10
21:26:50,614 root INFO Walk iteration: 10/10
21:26:50,624 root INFO Learning embeddings at time 1729279610.6244905
21:26:50,626 gensim.models.word2vec INFO collecting all words and their counts
21:26:50,626 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
21:26:50,628 gensim.models.word2vec INFO collected 338 word types from a corpus of 65800 raw words and 3380 sentences
21:26:50,629 gensim.models.word2vec INFO Creating a fresh vocabulary
21:26:50,629 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 338 unique words (100.00% of original 338, drops 0)', 'datetime': '2024-10-18T21:26:50.629314', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,630 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 65800 word corpus (100.00% of original 65800, drops 0)', 'datetime': '2024-10-18T21:26:50.630129', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,631 gensim.models.word2vec INFO deleting the raw counts dictionary of 338 items
21:26:50,632 gensim.models.word2vec INFO sample=0.001 downsamples 93 most-common words
21:26:50,633 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 40976.56144064161 word corpus (62.3%% of prior 65800)', 'datetime': '2024-10-18T21:26:50.633263', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:50,634 gensim.models.word2vec INFO estimated required memory for 338 words and 1536 dimensions: 4322344 bytes
21:26:50,634 gensim.models.word2vec INFO resetting layer weights
21:26:50,635 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-18T21:26:50.635910', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'build_vocab'}
21:26:50,635 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 338 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-10-18T21:26:50.635950', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:50,699 gensim.models.word2vec INFO EPOCH 0: training on 65800 raw words (40917 effective words) took 0.1s, 669359 effective words/s
21:26:50,764 gensim.models.word2vec INFO EPOCH 1: training on 65800 raw words (41084 effective words) took 0.1s, 651223 effective words/s
21:26:50,826 gensim.models.word2vec INFO EPOCH 2: training on 65800 raw words (40866 effective words) took 0.1s, 675222 effective words/s
21:26:50,827 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 197400 raw words (122867 effective words) took 0.2s, 643163 effective words/s', 'datetime': '2024-10-18T21:26:50.827017', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:50,827 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=338, vector_size=1536, alpha=0.025>', 'datetime': '2024-10-18T21:26:50.827051', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'created'}
21:26:50,827 root INFO Completed. Ending time is 1729279610.827145 Elapsed time is -0.33855652809143066
21:26:50,976 root INFO Starting preprocessing of transition probabilities on graph with 338 nodes and 534 edges
21:26:50,976 root INFO Starting at time 1729279610.9764457
21:26:50,976 root INFO Beginning preprocessing of transition probabilities for 338 vertices
21:26:50,976 root INFO Completed 1 / 338 vertices
21:26:50,976 root INFO Completed 34 / 338 vertices
21:26:50,977 root INFO Completed 67 / 338 vertices
21:26:50,978 root INFO Completed 100 / 338 vertices
21:26:50,979 root INFO Completed 133 / 338 vertices
21:26:50,981 root INFO Completed 166 / 338 vertices
21:26:50,982 root INFO Completed 199 / 338 vertices
21:26:50,983 root INFO Completed 232 / 338 vertices
21:26:50,984 root INFO Completed 265 / 338 vertices
21:26:50,985 root INFO Completed 298 / 338 vertices
21:26:50,985 root INFO Completed 331 / 338 vertices
21:26:50,985 root INFO Completed preprocessing of transition probabilities for vertices
21:26:50,986 root INFO Beginning preprocessing of transition probabilities for 534 edges
21:26:50,986 root INFO Completed 1 / 534 edges
21:26:50,988 root INFO Completed 54 / 534 edges
21:26:50,989 root INFO Completed 107 / 534 edges
21:26:50,993 root INFO Completed 160 / 534 edges
21:26:50,998 root INFO Completed 213 / 534 edges
21:26:51,0 root INFO Completed 266 / 534 edges
21:26:51,0 root INFO Completed 319 / 534 edges
21:26:51,2 root INFO Completed 372 / 534 edges
21:26:51,2 root INFO Completed 425 / 534 edges
21:26:51,3 root INFO Completed 478 / 534 edges
21:26:51,4 root INFO Completed 531 / 534 edges
21:26:51,4 root INFO Completed preprocessing of transition probabilities for edges
21:26:51,5 root INFO Simulating walks on graph at time 1729279611.0057025
21:26:51,6 root INFO Walk iteration: 1/10
21:26:51,17 root INFO Walk iteration: 2/10
21:26:51,27 root INFO Walk iteration: 3/10
21:26:51,38 root INFO Walk iteration: 4/10
21:26:51,48 root INFO Walk iteration: 5/10
21:26:51,58 root INFO Walk iteration: 6/10
21:26:51,68 root INFO Walk iteration: 7/10
21:26:51,78 root INFO Walk iteration: 8/10
21:26:51,88 root INFO Walk iteration: 9/10
21:26:51,97 root INFO Walk iteration: 10/10
21:26:51,107 root INFO Learning embeddings at time 1729279611.1078298
21:26:51,109 gensim.models.word2vec INFO collecting all words and their counts
21:26:51,109 gensim.models.word2vec INFO PROGRESS: at sentence #0, processed 0 words, keeping 0 word types
21:26:51,111 gensim.models.word2vec INFO collected 338 word types from a corpus of 65800 raw words and 3380 sentences
21:26:51,111 gensim.models.word2vec INFO Creating a fresh vocabulary
21:26:51,112 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 retains 338 unique words (100.00% of original 338, drops 0)', 'datetime': '2024-10-18T21:26:51.112113', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:51,113 gensim.utils INFO Word2Vec lifecycle event {'msg': 'effective_min_count=0 leaves 65800 word corpus (100.00% of original 65800, drops 0)', 'datetime': '2024-10-18T21:26:51.113066', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:51,114 gensim.models.word2vec INFO deleting the raw counts dictionary of 338 items
21:26:51,114 gensim.models.word2vec INFO sample=0.001 downsamples 93 most-common words
21:26:51,114 gensim.utils INFO Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 40976.56144064161 word corpus (62.3%% of prior 65800)', 'datetime': '2024-10-18T21:26:51.114979', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'prepare_vocab'}
21:26:51,115 gensim.models.word2vec INFO estimated required memory for 338 words and 1536 dimensions: 4322344 bytes
21:26:51,115 gensim.models.word2vec INFO resetting layer weights
21:26:51,116 gensim.utils INFO Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-10-18T21:26:51.116846', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'build_vocab'}
21:26:51,116 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training model with 8 workers on 338 vocabulary and 1536 features, using sg=1 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-10-18T21:26:51.116883', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:51,181 gensim.models.word2vec INFO EPOCH 0: training on 65800 raw words (40942 effective words) took 0.1s, 662942 effective words/s
21:26:51,244 gensim.models.word2vec INFO EPOCH 1: training on 65800 raw words (41125 effective words) took 0.1s, 675452 effective words/s
21:26:51,308 gensim.models.word2vec INFO EPOCH 2: training on 65800 raw words (41113 effective words) took 0.1s, 670337 effective words/s
21:26:51,308 gensim.utils INFO Word2Vec lifecycle event {'msg': 'training on 197400 raw words (123180 effective words) took 0.2s, 644338 effective words/s', 'datetime': '2024-10-18T21:26:51.308075', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'train'}
21:26:51,308 gensim.utils INFO Word2Vec lifecycle event {'params': 'Word2Vec<vocab=338, vector_size=1536, alpha=0.025>', 'datetime': '2024-10-18T21:26:51.308110', 'gensim': '4.3.3', 'python': '3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0]', 'platform': 'Linux-6.1.112-1-cip-amd64-x86_64-with-glibc2.36', 'event': 'created'}
21:26:51,308 root INFO Completed. Ending time is 1729279611.3082185 Elapsed time is -0.3317728042602539
21:26:51,497 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
21:26:51,953 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
21:26:51,954 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
21:26:52,138 datashaper.workflow.workflow INFO executing verb create_final_entities
21:26:52,189 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:8080
21:26:52,226 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for text: TPM=350000, RPM=10
21:26:52,226 graphrag.index.llm.load_llm INFO create concurrency limiter for text: 25
21:26:52,247 graphrag.index.operations.embed_text.strategies.openai INFO embedding 689 inputs via 675 snippets using 43 batches. max_batch_size=16, max_tokens=8191
21:26:53,399 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:53,429 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.177909877995262. input_tokens=413, output_tokens=0
21:26:53,787 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:53,811 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5599721870094072. input_tokens=549, output_tokens=0
21:26:53,813 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:53,813 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:53,838 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.5896147520106751. input_tokens=969, output_tokens=0
21:26:53,863 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6133143570041284. input_tokens=937, output_tokens=0
21:26:53,872 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:53,896 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.6460957390081603. input_tokens=1212, output_tokens=0
21:26:54,560 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:54,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1324403870094102. input_tokens=398, output_tokens=0
21:26:55,226 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:55,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3478082989749964. input_tokens=336, output_tokens=0
21:26:55,251 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:55,282 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.3812977279885672. input_tokens=697, output_tokens=0
21:26:55,306 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:55,330 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4610576030099764. input_tokens=396, output_tokens=0
21:26:55,332 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:26:55,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.4512967959744856. input_tokens=790, output_tokens=0
21:27:01,352 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:01,375 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7746056159958243. input_tokens=1685, output_tokens=0
21:27:07,778 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:07,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1919385099899955. input_tokens=1794, output_tokens=0
21:27:13,768 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:13,792 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1730129870120436. input_tokens=782, output_tokens=0
21:27:19,351 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:19,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.745539171010023. input_tokens=989, output_tokens=0
21:27:25,263 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:25,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6488804249966051. input_tokens=460, output_tokens=0
21:27:31,880 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:31,906 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.258855700987624. input_tokens=525, output_tokens=0
21:27:37,793 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:37,823 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1705737829906866. input_tokens=493, output_tokens=0
21:27:43,795 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:43,817 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1563958399929106. input_tokens=375, output_tokens=0
21:27:49,379 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:49,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7330058230145369. input_tokens=322, output_tokens=0
21:27:55,823 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:27:55,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1684398929937743. input_tokens=427, output_tokens=0
21:28:01,920 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:01,944 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.257074305001879. input_tokens=378, output_tokens=0
21:28:07,322 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:07,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6487951079907361. input_tokens=568, output_tokens=0
21:28:13,882 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:13,905 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2002041829982772. input_tokens=1562, output_tokens=0
21:28:19,432 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:19,460 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7464738360140473. input_tokens=653, output_tokens=0
21:28:25,968 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:25,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2694613019993994. input_tokens=328, output_tokens=0
21:28:31,869 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:31,894 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1617596980067901. input_tokens=739, output_tokens=0
21:28:37,355 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:37,378 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.6380614319932647. input_tokens=753, output_tokens=0
21:28:43,491 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:43,514 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7679274500114843. input_tokens=1685, output_tokens=0
21:28:49,904 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:49,927 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1726306519994978. input_tokens=891, output_tokens=0
21:28:55,888 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:28:55,911 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1487635940138716. input_tokens=461, output_tokens=0
21:29:02,10 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:02,34 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.265240807988448. input_tokens=236, output_tokens=0
21:29:07,498 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:07,525 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.7488355030072853. input_tokens=249, output_tokens=0
21:29:14,23 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:14,47 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2619453360093758. input_tokens=344, output_tokens=0
21:29:19,931 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:19,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.16489618801279. input_tokens=306, output_tokens=0
21:29:25,940 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:25,964 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1609406390052754. input_tokens=378, output_tokens=0
21:29:31,954 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:31,979 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1678189529920928. input_tokens=355, output_tokens=0
21:29:38,54 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:38,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2581379339972045. input_tokens=249, output_tokens=0
21:29:43,961 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:43,985 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1571809900051448. input_tokens=201, output_tokens=0
21:29:49,975 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:49,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1620764010003768. input_tokens=248, output_tokens=0
21:29:56,67 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:29:56,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.2471409979916643. input_tokens=277, output_tokens=0
21:30:01,990 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:30:02,14 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1616157770040445. input_tokens=364, output_tokens=0
21:30:07,986 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:30:08,10 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 1.1484142190020066. input_tokens=1123, output_tokens=0
21:30:13,806 httpx INFO HTTP Request: POST http://localhost:8080/embeddings "HTTP/1.1 200 OK"
21:30:13,815 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.9437820950115565. input_tokens=205, output_tokens=0
21:30:13,828 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
21:30:14,106 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['create_base_entity_graph']
21:30:14,107 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
21:30:14,144 datashaper.workflow.workflow INFO executing verb create_final_nodes
21:30:17,996 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
21:30:18,322 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['create_base_entity_graph']
21:30:18,323 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
21:30:18,363 datashaper.workflow.workflow INFO executing verb create_final_communities
21:30:18,482 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
21:30:18,624 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
21:30:18,624 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
21:30:18,768 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
21:30:18,807 datashaper.workflow.workflow INFO executing verb create_final_relationships
21:30:18,856 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
21:30:19,7 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['create_final_relationships', 'create_final_entities', 'create_base_text_units']
21:30:19,7 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
21:30:19,13 graphrag.utils.storage INFO read table from storage: create_final_entities.parquet
21:30:19,109 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
21:30:19,122 datashaper.workflow.workflow INFO executing verb create_final_text_units
21:30:19,137 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
21:30:19,285 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
21:30:19,286 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
21:30:19,314 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
21:30:19,325 datashaper.workflow.workflow INFO executing verb create_final_community_reports
21:30:19,357 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=2 => 478
21:30:19,394 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=1 => 846
21:30:19,473 graphrag.index.operations.summarize_communities.prepare_community_reports INFO Number of nodes at level=0 => 905
21:30:22,521 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:22,524 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.8744117470050696. input_tokens=2141, output_tokens=403
21:30:22,896 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:22,899 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.2555875389953144. input_tokens=2556, output_tokens=453
21:30:22,913 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:22,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.2662010960048065. input_tokens=2737, output_tokens=527
21:30:23,607 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:23,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.9678798009990714. input_tokens=6321, output_tokens=676
21:30:24,989 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:24,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.345657716999995. input_tokens=2463, output_tokens=971
21:30:25,323 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:25,326 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.408320129994536. input_tokens=2437, output_tokens=452
21:30:25,618 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:25,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.9874906960176304. input_tokens=2203, output_tokens=412
21:30:26,699 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:26,703 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.7760203359939624. input_tokens=4854, output_tokens=747
21:30:26,825 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:26,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.278979748982238. input_tokens=2931, output_tokens=879
21:30:27,758 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:27,761 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.412001313001383. input_tokens=2418, output_tokens=464
21:30:28,571 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:28,573 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.8475804640038405. input_tokens=2049, output_tokens=319
21:30:28,593 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:28,595 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.9511181470006704. input_tokens=2627, output_tokens=567
21:30:28,928 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:28,931 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.9150374550081324. input_tokens=2927, output_tokens=744
21:30:29,571 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:29,574 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.7264984979992732. input_tokens=2750, output_tokens=528
21:30:29,717 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:29,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.9373587069858331. input_tokens=2049, output_tokens=327
21:30:32,266 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:32,269 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.513130904000718. input_tokens=2079, output_tokens=424
21:30:32,872 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:32,875 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.1168936569883954. input_tokens=2324, output_tokens=566
21:30:33,445 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:33,448 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.6936130720132496. input_tokens=3108, output_tokens=723
21:30:34,115 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:34,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.8267716410045978. input_tokens=2051, output_tokens=292
21:30:34,584 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:34,588 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.837400047981646. input_tokens=8616, output_tokens=938
21:30:34,874 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:34,877 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.9800574730033986. input_tokens=2039, output_tokens=316
21:30:35,306 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:35,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.557130973000312. input_tokens=3360, output_tokens=1307
21:30:35,733 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:35,736 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.5831599300145172. input_tokens=2055, output_tokens=257
21:30:36,131 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:36,134 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.6626884160214104. input_tokens=2312, output_tokens=484
21:30:36,292 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:36,294 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.6795072969980538. input_tokens=2039, output_tokens=272
21:30:36,744 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:36,746 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.4140944560058415. input_tokens=2032, output_tokens=224
21:30:36,940 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:36,943 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.0505079999857116. input_tokens=2277, output_tokens=364
21:30:38,313 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:38,316 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.5581312910071574. input_tokens=2289, output_tokens=490
21:30:38,571 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:38,571 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:40,33 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:40,33 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:40,388 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:40,392 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.072701944009168. input_tokens=3545, output_tokens=798
21:30:40,425 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:40,426 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:40,435 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:30:40,436 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.2641891759994905. input_tokens=3717, output_tokens=821
21:30:40,440 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:40,440 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:40,447 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:40,447 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:40,606 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:40,607 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 1/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:41,726 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:41,727 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:41,728 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:41,729 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:42,583 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:42,584 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:43,792 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:43,793 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 2/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:44,992 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:44,992 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:46,208 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:46,209 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:47,418 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:47,419 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:48,625 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:48,626 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:49,834 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:49,835 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 3/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:51,44 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:51,45 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:52,243 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:52,243 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:53,459 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:53,460 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:54,668 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:54,669 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:30:55,877 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:30:55,878 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 4/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:00,62 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:00,63 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:00,789 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:00,789 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:02,186 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:02,186 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:03,367 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:03,367 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:04,4 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:04,5 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 5/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:10,97 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:10,98 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:10,807 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:10,807 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:12,209 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:12,209 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:13,394 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:13,395 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:14,31 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:14,32 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 6/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:20,116 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:20,116 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:21,659 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:21,659 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:22,236 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:22,237 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:23,422 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:23,423 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:24,58 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:24,59 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 7/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:30,150 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:30,151 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:31,686 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:31,687 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:32,263 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:32,264 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:33,450 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:33,451 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:34,84 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 429 Too Many Requests"
21:31:34,85 graphrag.llm.base.rate_limiting_llm WARNING create_community_report failed to invoke LLM 8/10 attempts. Cause: rate limit exceeded, will retry. Recommended sleep for 0 seconds. Follow recommendation? True
21:31:42,461 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:42,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 8 retries took 2.3043655380024575. input_tokens=2084, output_tokens=320
21:31:44,174 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:44,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 8 retries took 1.906905469018966. input_tokens=2094, output_tokens=320
21:31:45,910 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:45,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 8 retries took 2.458079534000717. input_tokens=2047, output_tokens=323
21:31:45,995 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:45,996 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.508558298985008. input_tokens=5376, output_tokens=639
21:31:46,180 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:46,184 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 8 retries took 4.492290510010207. input_tokens=5508, output_tokens=867
21:31:46,755 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:46,756 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 8 retries took 2.668878369993763. input_tokens=2108, output_tokens=353
21:31:47,783 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:47,786 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.8503816179872956. input_tokens=2097, output_tokens=304
21:31:47,905 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:47,908 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.709449557994958. input_tokens=3683, output_tokens=715
21:31:48,380 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:48,383 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.3812936620088294. input_tokens=2555, output_tokens=422
21:31:50,465 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:50,468 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.5399815869750455. input_tokens=2147, output_tokens=497
21:31:50,976 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:50,980 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.759497754013864. input_tokens=3670, output_tokens=1048
21:31:51,378 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:51,497 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:52,66 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:52,70 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 5.296917600004235. input_tokens=4196, output_tokens=1021
21:31:53,521 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:54,482 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.9743694759963546. input_tokens=2175, output_tokens=538
21:31:55,686 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.6891790660156403. input_tokens=3934, output_tokens=744
21:31:57,674 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:31:58,97 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.033859343995573. input_tokens=2451, output_tokens=531
21:32:00,105 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:01,716 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.403202483983478. input_tokens=2773, output_tokens=882
21:32:02,540 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:03,91 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:04,127 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.217751862015575. input_tokens=2166, output_tokens=592
21:32:06,185 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:06,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.2423750040179584. input_tokens=2806, output_tokens=638
21:32:07,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.5848526249756105. input_tokens=2282, output_tokens=472
21:32:08,317 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:10,152 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.266406309994636. input_tokens=3036, output_tokens=620
21:32:11,811 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:13,772 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.989463032979984. input_tokens=2666, output_tokens=608
21:32:14,640 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:14,919 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:14,923 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.5660541669931263. input_tokens=2647, output_tokens=662
21:32:17,333 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.868778817006387. input_tokens=3230, output_tokens=558
21:32:18,379 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:19,742 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.0784329539746977. input_tokens=2077, output_tokens=318
21:32:22,722 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:23,359 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.2561724279948976. input_tokens=2525, output_tokens=410
21:32:23,424 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:25,263 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:25,769 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.188255988992751. input_tokens=2579, output_tokens=767
21:32:25,815 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:28,179 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.481129599007545. input_tokens=2066, output_tokens=405
21:32:29,382 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.113579455995932. input_tokens=2225, output_tokens=435
21:32:29,518 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:30,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 1.2553959439974278. input_tokens=2037, output_tokens=171
21:32:31,788 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.5488236349774525. input_tokens=2192, output_tokens=449
21:32:36,737 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:37,139 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:39,84 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.6956268929934595. input_tokens=9065, output_tokens=665
21:32:39,746 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:39,778 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:40,287 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.8898315519909374. input_tokens=2895, output_tokens=588
21:32:41,945 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:42,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.288333503995091. input_tokens=3183, output_tokens=706
21:32:43,900 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.1106187450059224. input_tokens=3233, output_tokens=507
21:32:45,904 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:46,310 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.069714516022941. input_tokens=7337, output_tokens=683
21:32:48,777 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:49,933 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.416436311992584. input_tokens=8012, output_tokens=738
21:32:50,33 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:52,344 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.6755204770015553. input_tokens=3665, output_tokens=742
21:32:53,158 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:54,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.5209171639871784. input_tokens=2250, output_tokens=479
21:32:54,804 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:56,318 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:32:57,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 4.436985376989469. input_tokens=3327, output_tokens=793
21:32:59,571 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.669924405985512. input_tokens=4953, output_tokens=599
21:32:59,699 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:33:00,775 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 2.774676521017682. input_tokens=2273, output_tokens=522
21:33:01,978 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.7480359739856794. input_tokens=2424, output_tokens=684
21:33:02,53 httpx INFO HTTP Request: POST http://localhost:8080/chat/completions "HTTP/1.1 200 OK"
21:33:03,258 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 3.6895332470012363. input_tokens=7151, output_tokens=943
21:33:03,271 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
21:33:03,429 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_final_text_units']
21:33:03,433 graphrag.utils.storage INFO read table from storage: create_final_text_units.parquet
21:33:03,442 datashaper.workflow.workflow INFO executing verb create_final_documents
21:33:03,449 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
21:33:03,472 graphrag.index.cli INFO All workflows completed successfully.

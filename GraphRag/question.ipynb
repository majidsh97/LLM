{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'embeddings', 'metadatas', 'documents', 'uris', 'data', 'included'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3180"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "#https://github.com/chroma-core/chroma/blob/main/chromadb/experimental/density_relevance.ipynb\n",
    "\n",
    "client =  chromadb.PersistentClient('./chroma_docs')\n",
    "col_raw = client.get_collection('documents_raw')\n",
    "#col_raw = client.get_collection('documents_summary')\n",
    "\n",
    "data = col_raw.get()\n",
    "\n",
    "print(data.keys())\n",
    "len(data['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'distances', 'metadatas', 'embeddings', 'documents', 'uris', 'data', 'included'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['9.4 GraphRAG in Industry\\n\\nIn this section, we mainly focus on industrial GraphRAG systems. These systems are characterized by their reliance on industrial graph database systems or their focus on large-scale graph data, details of which are as follows.\\n\\n• GraphRAG (by Microsoft)10: The system uses LLMs to construct entity-based knowledge graphs and pre-generate community summaries of related entity groups, which enables the capture of both local and global relationships within a document collection, thereby enhancing Query-Focused Summarization (QFS) task [32]. The project can also utilize open-source RAG toolkits for rapid implementation, such as LlamaIndex11, LangChain12, etc.\\n\\n• GraphRAG (by NebulaGraph)13: The project is the first industrial GraphRAG system, which is developed by NebulaGraph Corporation. The project integrates LLMs into the NebulaGraph database, which aims to deliver more intelligent and precise search results.\\n\\n• GraphRAG (by Antgroup)14: The framework is developed on the foundation of several AI engineering frameworks such as DB-GPT, knowledge graph engine OpenSPG, and graph database TuGraph. Specifically, the system begins by extracting triples from documents using LLMs, which are then stored in the graph database. During the retrieval phase, it identifies keywords from the query, locates corresponding nodes in the graph database, and traverses the subgraph using BFS\\n\\n10https://github.com/microsoft/graphrag\\n\\n11https://docs.llamaindex.ai/en/stable/ examples/index structs/knowledge graph/KnowledgeGraphDemo.html\\n\\n12https://python.langchain.com/docs/use_cases/graph\\n\\n13https://www.nebula-graph.io/posts/graph-RAG\\n\\n14https://github.com/eosphoros-ai/DB-GPT\\n\\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.\\n\\nPeng et al.\\n\\nGraph Retrieval-Augmented Generation: A Survey\\n\\nor DFS. In the generation phase, the retrieved subgraph data is formatted into text and submitted along with the context and query for processing by LLMs.\\n\\n• NallM (by Neo4j)15: The NaLLM (Neo4j and Large Language Models) framework integrates Neo4j graph database technology with LLMs. It aims to explore and demonstrate the synergy between Neo4j and LLMs, focusing on three primary use cases: Natural Language Interface to a Knowledge Graph, Creating a Knowledge Graph from Unstructured Data, and Generate Reports Using Both Static Data and LLM Data.\\n\\n• LLM Graph Builder (by Neo4j)16: It is a project developed by Neo4j for automatically construct- ing knowledge graphs, suitable for the GraphRAG’s Graph Database Construction and Indexing phase. The project primarily utilizes LLMs to extract nodes, relationships, and their properties from unstructured data, and utilizes the LangChain framework to create structured knowledge graphs.',\n",
       "  '3 Preliminaries\\n\\nIn this section, we introduce background knowledge of GraphRAG for easier comprehension of our survey. First, we introduce Text-Attributed Graphs which is a universal and general format of\\n\\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.\\n\\n111:5\\n\\n111:6\\n\\nPeng et al.\\n\\ngraph data used in GraphRAG. Then, we provide formal definitions for two types of models that can be used in the retrieval and generation stages: Graph Neural Networks and Language Models.\\n\\n3.1 Text-Attributed Graphs\\n\\nThe graph data used in Graph RAG can be represented uniformly as Text-Attributed Graphs (TAGs), where nodes and edges possess textual attributes. Formally, a text-attributed graph can be denoted as G = (V, E, A, {x𝑣 }𝑣 ∈ V, {e𝑖,𝑗 }𝑖,𝑗 ∈ E), where V is the set of nodes, E ⊆ V × V is the set of edges, A ∈ {0, 1} | V | × | V | is the adjacent matrix. Additionally, {x𝑣 }𝑣 ∈ V and {e𝑖,𝑗 }𝑖,𝑗 ∈ E are textual attributes of nodes and edges, respectively. One typical kind of TAGs is Knowledge Graphs (KGs), where nodes are entities, edges are relations among entities, and text attributes are the names of entities and relations.\\n\\n3.2 Graph Neural Networks\\n\\nGraph Neural Networks (GNNs) are a kind of deep learning framework to model the graph data. Classical GNNs, e.g., GCN [83], GAT [162], GraphSAGE [52], adopt a message-passing manner to obtain node representations. Formally, each node representation h(𝑙 −1) in the 𝑙-th layer is updated 𝑖 by aggregating the information from neighboring nodes and edges:\\n\\nh(𝑙 ) 𝑖 = UPD(h(𝑙 −1) 𝑖 , AGG𝑗 ∈ N (𝑖 ) MSG(h(𝑙 −1) 𝑖 , h(𝑙 −1) 𝑗 , e(𝑙 −1) 𝑖,𝑗 )), (1)\\n\\nwhere N(𝑖 ) represents the neighbors of node 𝑖. MSG denotes the message function, which computes the message based on the node, its neighbor, and the edge between them. AGG refers to the aggregation function that combines the received messages using a permutation-invariant method, such as mean, sum, or max. UPD represents the update function, which updates each node’s attributes with the aggregated messages.\\n\\nSubsequently, a readout function, e.g., mean, sum, or max pooling, can be applied to obtain the global-level representation:\\n\\nh𝐺 = READOUT𝑖 ∈ V𝐺 (h(𝐿) 𝑖 ). (2)\\n\\nIn GraphRAG, GNNs can be utilized to obtain representations of graph data for the retrieval phase, as well as to model the retrieved graph structures.',\n",
       "  '2 Comparison with Related Techniques and Surveys\\n\\nIn this section, we compare Graph Retrieval-Augmented Generation (GraphRAG) with related techniques and corresponding surveys, including RAG, LLMs on graphs, and Knowledge Base Question Answering (KBQA).\\n\\n2.1 RAG\\n\\nRAG combines external knowledge with LLMs for improved task performance, integrating domain- specific information to ensure factuality and credibility. In the past two years, researchers have written many comprehensive surveys about RAG [34, 45, 59, 62, 178, 195, 202]. For example, et al. [34] and Gao et al. [45] categorize RAG methods from the perspectives of retrieval, gen- eration, and augmentation. Zhao et al. [202] review RAG methods for databases with different modalities. Yu et al. [195] systematically summarize the evaluation of RAG methods. These works Fan\\n\\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.\\n\\nPeng et al.\\n\\nPeng et al.\\n\\nGraph Retrieval-Augmented Generation: A Survey\\n\\nprovide a structured synthesis of current RAG methodologies, fostering a deeper understanding and suggesting future directions of the area.\\n\\nFrom a broad perspective, GraphRAG can be seen as a branch of RAG, which retrieves relevant relational knowledge from graph databases instead of text corpus. However, compared to text- based RAG, GraphRAG takes into account the relationships between texts and incorporates the structural information as additional knowledge beyond text. Furthermore, during the construction of graph data, raw text data may undergo filtering and summarization processes, enhancing the refinement of information within the graph data. Although previous surveys on RAG have touched upon GraphRAG, they predominantly center on textual data integration. This paper diverges by placing a primary emphasis on the indexing, retrieval, and utilization of structured graph data, which represents a substantial departure from handling purely textual information and spurs the emergence of many new techniques.',\n",
       "  '6 Conclusion\\n\\nWe have presented a global approach to Graph RAG, combining knowledge graph generation, retrieval-augmented generation (RAG), and query-focused summarization (QFS) to support human sensemaking over entire text corpora. Initial evaluations show substantial improvements over a na¨ıve RAG baseline for both the comprehensiveness and diversity of answers, as well as favorable comparisons to a global but graph-free approach using map-reduce source text summarization. For situations requiring many global queries over the same dataset, summaries of root-level communi- ties in the entity-based graph index provide a data index that is both superior to na¨ıve RAG and achieves competitive performance to other global methods at a fraction of the token cost.\\n\\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n11\\n\\nAcknowledgements\\n\\nWe would also like to thank the following people who contributed to the work: Alonso Guevara Fern´andez, Amber Hoak, Andr´es Morales Esquivel, Ben Cutler, Billie Rinaldi, Chris Sanchez, Chris Trevino, Christine Caggiano, David Tittsworth, Dayenne de Souza, Douglas Orbaker, Ed Clark, Gabriel Nieves-Ponce, Gaudy Blanco Meneses, Kate Lytvynets, Katy Smith, M´onica Carva- jal, Nathan Evans, Richard Ortega, Rodrigo Racanicci, Sarah Smith, and Shane Solomon.',\n",
       "  '• We discuss the core technologies underpinning existing GraphRAG systems, including G- Indexing, G-Retrieval, and G-Generation. For each component, we analyze the spectrum of model selection, methodological design, and enhancement strategies currently being explored. Additionally, we contrast the diverse training methodologies employed across these modules.\\n\\n• We delineate the downstream tasks, benchmarks, application domains, evaluation metrics, current challenges, and future research directions pertinent to GraphRAG, discussing both\\n\\nJ. ACM, Vol. 37, No. 4, Article 111. Publication date: September 2024.\\n\\n111:3\\n\\n111:3\\n\\n111:4\\n\\n1114\\n\\nInput Query How did the artistic movements of the 19th century impact the development of modern art in the 20th century? G-Retrieval Retrieval Graph Format G-Generation Output Results __ Response $ ‘Adjacency/Edge Table Pre-Generation ge: 3 Nodes => Generator —> £ % - E Enhancements o=Es @ g&e c Natural Language ese Triplets = ges Query Knowledge Kk SSS Enh nt Enhancements SPARED . 285 Mhancements Covetke Forms, Mid-Generation Goce sag {y Paths £R Enhancements gos . @ Graph Database & G-Indexing ‘Syntax Tree 8 £8 Soa : subs Se EEE ES REESE Post-Generation ES? 0 _ Enhancements Generator —> = 5 = Open Knowledge Self-Constructed s&s Graphs Graph Data Hybrid Graph Embedding Ses\\n\\n. Graph Database & G-Indexing : ES 0 Open Knowledge Self-Constructed Graphs Graph Data\\n\\nFig. 2. The overview of the GraphRAG framework for question answering task. In this survey, we divide GraphRAG into three stages: G-Indexing, G-Retrieval, and G-Generation. We categorize the retrieval sources into open-source knowledge graphs and self-constructed graph data. Various enhancing techniques like query enhancement and knowledge enhancement may be adopted to boost the relevance of the results. Unlike RAG, which uses retrieved text directly for generation, GraphRAG requires converting the retrieved graph information into patterns acceptable to generators to enhance the task performance.\\n\\nthe progress and prospects of this field. Furthermore, we compile an inventory of existing industry GraphRAG systems, providing insights into the translation of academic research into real-world industry solutions.\\n\\nOrganization. The rest of the survey is organized as follows: Section 2 compares related tech- niques, while Section 3 outlines the general process of GraphRAG. Sections 5 to 7 categorize the techniques associated with GraphRAG’s three stages: G-Indexing, G-Retrieval, and G-Generation. Section 8 introduces the training strategies of retrievers and generators. Section 9 summarizes GraphRAG’s downstream tasks, corresponding benchmarks, application domains, evaluation met- rics, and industrial GraphRAG systems. Section 10 provides an outlook on future directions. Finally, Section 11 concludes the content of this survey.']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = col_raw.query(query_texts=\"what is graph rag?\",n_results=5)\n",
    "print(results.keys())\n",
    "results['documents']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

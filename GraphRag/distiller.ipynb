{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb?ref=blog.langchain.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2304.12244v2.pdf',\n",
       " '2402.05930v1.pdf',\n",
       " '2405.16506v1.pdf',\n",
       " '2102.00151.pdf',\n",
       " '2310.06825v1.pdf',\n",
       " '2112.07916v2.pdf',\n",
       " '2401.13919v4.pdf',\n",
       " '2312.12423.pdf',\n",
       " '2305.10601v2.pdf',\n",
       " '2406.05085v1.pdf',\n",
       " '2409.00149v1.pdf',\n",
       " '2212.10423v1.pdf',\n",
       " '2311.07587v2.pdf',\n",
       " '2409.04109v1.pdf',\n",
       " '2310.12931v2.pdf',\n",
       " '2309.14521.pdf',\n",
       " '2408.06292v3.pdf',\n",
       " '2402.15301v2.pdf',\n",
       " '2108.10447v1.pdf',\n",
       " '2406.12430v1.pdf',\n",
       " '2311.18751v2.pdf',\n",
       " '2402.03146v1.pdf',\n",
       " '2312.10997v5.pdf',\n",
       " '2404.00610v1.pdf',\n",
       " '2203.05794v1.pdf',\n",
       " '2303.18223v13.pdf',\n",
       " '2409.03284v1.pdf',\n",
       " '2308.02357v1.pdf',\n",
       " '2209.11755v1.pdf',\n",
       " '2309.15698v1.pdf',\n",
       " '2408.06292v1.pdf',\n",
       " '2305.05084v6.pdf',\n",
       " '2405.10292v2.pdf',\n",
       " '2402.18041v1.pdf',\n",
       " '2310.08184v1.pdf',\n",
       " '2312.10029v2.pdf',\n",
       " '2305.13453v2.pdf',\n",
       " '2310.11511v1.pdf',\n",
       " '2406.14550v1.pdf',\n",
       " 'P10-1031.pdf',\n",
       " '2409.04004v2.pdf',\n",
       " '2109.05679v2.pdf',\n",
       " '2102.01187.pdf',\n",
       " '2312.15713v1.pdf',\n",
       " '2408.03010v1.pdf',\n",
       " '2305.17888v1.pdf',\n",
       " '2303.11366v4.pdf',\n",
       " '2307.03109v9.pdf',\n",
       " '2408.08921v2.pdf',\n",
       " '2106.14807v1.pdf',\n",
       " '2304.12210.pdf',\n",
       " '2307.12856v4.pdf',\n",
       " '2404.16130.pdf',\n",
       " '2409.00786v1.pdf',\n",
       " '2403.08345v1.pdf',\n",
       " '2312.14238.pdf',\n",
       " '2402.03216v4.pdf',\n",
       " '2403.14403v2.pdf',\n",
       " '2209.11000v1.pdf',\n",
       " '2307.08621v4.pdf',\n",
       " '2406.11736v1.pdf',\n",
       " '2206.08896v1.pdf',\n",
       " '2210.03945v2.pdf',\n",
       " '2210.11416v5.pdf',\n",
       " '2112.08778v1.pdf']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "path = 'documents/'\n",
    "files = os.listdir(path)\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "# Get elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Element(BaseModel):\n",
    "        type: str\n",
    "        text: Any\n",
    "def get_text_and_table(filename):\n",
    "    raw_pdf_elements = partition_pdf(\n",
    "    filename=path + filename,\n",
    "    # Using pdf format to find embedded image blocks\n",
    "    extract_images_in_pdf=False,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    "    chunking_strategy=\"by_title\",\n",
    "    # Chunking params to aggregate text blocks\n",
    "    # Attempt to create a new chunk 3800 chars\n",
    "    # Attempt to keep chunks > 2000 chars\n",
    "    # Hard max on chunks\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,\n",
    "    )\n",
    "    # Create a dictionary to store counts of each type\n",
    "    category_counts = {}\n",
    "\n",
    "    for element in raw_pdf_elements:\n",
    "        category = str(type(element))\n",
    "        if category in category_counts:\n",
    "            category_counts[category] += 1\n",
    "        else:\n",
    "            category_counts[category] = 1\n",
    "\n",
    "    # Unique_categories will have unique elements\n",
    "    unique_categories = set(category_counts.keys())\n",
    "    category_counts\n",
    "\n",
    "\n",
    "\n",
    "    # Categorize by type\n",
    "    categorized_elements = []\n",
    "    for element in raw_pdf_elements:\n",
    "        if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "            categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "        elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "            categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "\n",
    "    # Tables\n",
    "    table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
    "    print(len(table_elements))\n",
    "\n",
    "    # Text\n",
    "    text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
    "    print(len(text_elements))\n",
    "    \n",
    "    return text_elements,table_elements\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ['OPENAI_API_KEY']='any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "base_url = \"http://localhost:8080/\"\n",
    "# Summary chain\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o\",base_url=base_url)\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def batch_sleep(batch,sleep=2):\n",
    "    new_list = []\n",
    "    for t in batch:\n",
    "        s = summarize_chain.invoke(t)\n",
    "        new_list.append(s)\n",
    "        time.sleep(sleep)\n",
    "    \n",
    "    return new_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2305.13453v2.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insert of existing embedding ID: 2305.13453v2.pdf_0\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_1\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_2\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_3\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_4\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_5\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_6\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_7\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_8\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_9\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_10\n",
      "Insert of existing embedding ID: 2305.13453v2.pdf_11\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_0\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_1\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_2\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_3\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_4\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_5\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_6\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_7\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_8\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_9\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_10\n",
      "Add of existing embedding ID: 2305.13453v2.pdf_11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "12\n",
      "2078\n",
      "1 2310.11511v1.pdf\n",
      "7\n",
      "39\n",
      "2124\n",
      "2 2406.14550v1.pdf\n",
      "8\n",
      "32\n",
      "2164\n",
      "3 P10-1031.pdf\n",
      "2\n",
      "17\n",
      "2183\n",
      "4 2409.04004v2.pdf\n",
      "14\n",
      "39\n",
      "2236\n",
      "5 2109.05679v2.pdf\n",
      "1\n",
      "29\n",
      "2266\n",
      "6 2102.01187.pdf\n",
      "4\n",
      "17\n",
      "2287\n",
      "7 2312.15713v1.pdf\n",
      "8\n",
      "31\n",
      "2326\n",
      "8 2408.03010v1.pdf\n",
      "3\n",
      "13\n",
      "2342\n",
      "9 2305.17888v1.pdf\n",
      "12\n",
      "21\n",
      "2375\n",
      "10 2303.11366v4.pdf\n",
      "7\n",
      "26\n",
      "2408\n",
      "11 2307.03109v9.pdf\n",
      "13\n",
      "69\n",
      "2490\n",
      "12 2408.08921v2.pdf\n",
      "1\n",
      "59\n",
      "2550\n",
      "13 2106.14807v1.pdf\n",
      "2\n",
      "9\n",
      "2561\n",
      "14 2304.12210.pdf\n",
      "6\n",
      "68\n",
      "2635\n",
      "15 2307.12856v4.pdf\n",
      "11\n",
      "35\n",
      "2681\n",
      "16 2404.16130.pdf\n",
      "4\n",
      "20\n",
      "2705\n",
      "17 2409.00786v1.pdf\n",
      "12\n",
      "34\n",
      "2751\n",
      "18 2403.08345v1.pdf\n",
      "1\n",
      "11\n",
      "2763\n",
      "19 2312.14238.pdf\n",
      "38\n",
      "54\n",
      "2855\n",
      "20 2402.03216v4.pdf\n",
      "15\n",
      "31\n",
      "2901\n",
      "21 2403.14403v2.pdf\n",
      "7\n",
      "26\n",
      "2934\n",
      "22 2209.11000v1.pdf\n",
      "6\n",
      "19\n",
      "2959\n",
      "23 2307.08621v4.pdf\n",
      "8\n",
      "21\n",
      "2988\n",
      "24 2406.11736v1.pdf\n",
      "9\n",
      "22\n",
      "3019\n",
      "25 2206.08896v1.pdf\n",
      "2\n",
      "46\n",
      "3067\n",
      "26 2210.03945v2.pdf\n",
      "10\n",
      "24\n",
      "3101\n",
      "27 2210.11416v5.pdf\n",
      "46\n",
      "64\n",
      "3211\n",
      "28 2112.08778v1.pdf\n",
      "5\n",
      "15\n",
      "3231\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient('./chroma_docs')\n",
    "collection = client.get_or_create_collection('documents_summary')\n",
    "collection_raw= client.get_or_create_collection('documents_raw')\n",
    "#collection_table = client.get_or_create_collection('table_summary')\n",
    "\n",
    "for i,filename in enumerate(files[36:]):\n",
    "    \n",
    "    print(i,filename)\n",
    "    text_elements,table_elements = get_text_and_table(filename)\n",
    "    # Apply to text\n",
    "    texts = [i.text for i in text_elements]\n",
    "    tables = [i.text for i in table_elements]\n",
    "    \n",
    "    ids = [filename+'_'+ str(i) for i in range(len(texts))]\n",
    "    ids_tables = [filename+'_table_'+ str(i) for i in range(len(tables))]\n",
    "    \n",
    "    if len(ids)>0:\n",
    "        collection_raw.add(ids=ids,documents=texts)\n",
    "        text_summaries = batch_sleep(texts)\n",
    "        collection.add(ids=ids,documents=text_summaries)\n",
    "    \n",
    "    if len(ids_tables)>0:\n",
    "        collection_raw.add(ids=ids_tables,documents=tables)\n",
    "        \n",
    "        table_summaries = batch_sleep(tables)\n",
    "        collection.add(ids=ids_tables,documents=table_summaries)\n",
    "        \n",
    "    print(collection.count())\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

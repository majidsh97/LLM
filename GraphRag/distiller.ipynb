{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2304.12244v2.pdf',\n",
       " '2402.05930v1.pdf',\n",
       " '2405.16506v1.pdf',\n",
       " '2102.00151.pdf',\n",
       " '2310.06825v1.pdf',\n",
       " '2112.07916v2.pdf',\n",
       " '2401.13919v4.pdf',\n",
       " '2312.12423.pdf',\n",
       " '2305.10601v2.pdf',\n",
       " '2406.05085v1.pdf',\n",
       " '2409.00149v1.pdf',\n",
       " '2212.10423v1.pdf',\n",
       " '2311.07587v2.pdf',\n",
       " '2409.04109v1.pdf',\n",
       " '2310.12931v2.pdf',\n",
       " '2309.14521.pdf',\n",
       " '2408.06292v3.pdf',\n",
       " '2402.15301v2.pdf',\n",
       " '2108.10447v1.pdf',\n",
       " '2406.12430v1.pdf',\n",
       " '2311.18751v2.pdf',\n",
       " '2402.03146v1.pdf',\n",
       " '2312.10997v5.pdf',\n",
       " '2404.00610v1.pdf',\n",
       " '2203.05794v1.pdf',\n",
       " '2303.18223v13.pdf',\n",
       " '2409.03284v1.pdf',\n",
       " '2308.02357v1.pdf',\n",
       " '2209.11755v1.pdf',\n",
       " '2309.15698v1.pdf',\n",
       " '2408.06292v1.pdf',\n",
       " '2305.05084v6.pdf',\n",
       " '2405.10292v2.pdf',\n",
       " '2402.18041v1.pdf',\n",
       " '2310.08184v1.pdf',\n",
       " '2312.10029v2.pdf',\n",
       " '2305.13453v2.pdf',\n",
       " '2310.11511v1.pdf',\n",
       " '2406.14550v1.pdf',\n",
       " 'P10-1031.pdf',\n",
       " '2409.04004v2.pdf',\n",
       " '2109.05679v2.pdf',\n",
       " '2102.01187.pdf',\n",
       " '2312.15713v1.pdf',\n",
       " '2408.03010v1.pdf',\n",
       " '2305.17888v1.pdf',\n",
       " '2303.11366v4.pdf',\n",
       " '2307.03109v9.pdf',\n",
       " '2408.08921v2.pdf',\n",
       " '2106.14807v1.pdf',\n",
       " '2304.12210.pdf',\n",
       " '2307.12856v4.pdf',\n",
       " '2404.16130.pdf',\n",
       " '2409.00786v1.pdf',\n",
       " '2403.08345v1.pdf',\n",
       " '2312.14238.pdf',\n",
       " '2402.03216v4.pdf',\n",
       " '2403.14403v2.pdf',\n",
       " '2209.11000v1.pdf',\n",
       " '2307.08621v4.pdf',\n",
       " '2406.11736v1.pdf',\n",
       " '2206.08896v1.pdf',\n",
       " '2210.03945v2.pdf',\n",
       " '2210.11416v5.pdf',\n",
       " '2112.08778v1.pdf']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "path = 'documents/'\n",
    "files = os.listdir(path)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "# Get elements\n",
    "raw_pdf_elements = partition_pdf(\n",
    "    filename=path + files[0],\n",
    "    # Using pdf format to find embedded image blocks\n",
    "    extract_images_in_pdf=True,\n",
    "    # Use layout model (YOLOX) to get bounding boxes (for tables) and find titles\n",
    "    # Titles are any sub-section of the document\n",
    "    infer_table_structure=True,\n",
    "    # Post processing to aggregate text once we have the title\n",
    "    chunking_strategy=\"by_title\",\n",
    "    # Chunking params to aggregate text blocks\n",
    "    # Attempt to create a new chunk 3800 chars\n",
    "    # Attempt to keep chunks > 2000 chars\n",
    "    # Hard max on chunks\n",
    "    max_characters=4000,\n",
    "    new_after_n_chars=3800,\n",
    "    combine_text_under_n_chars=2000,\n",
    "    image_output_dir_path=path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"<class 'unstructured.documents.elements.CompositeElement'>\": 41,\n",
       " \"<class 'unstructured.documents.elements.Table'>\": 6}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to store counts of each type\n",
    "category_counts = {}\n",
    "\n",
    "for element in raw_pdf_elements:\n",
    "    category = str(type(element))\n",
    "    if category in category_counts:\n",
    "        category_counts[category] += 1\n",
    "    else:\n",
    "        category_counts[category] = 1\n",
    "\n",
    "# Unique_categories will have unique elements\n",
    "unique_categories = set(category_counts.keys())\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "class Element(BaseModel):\n",
    "    type: str\n",
    "    text: Any\n",
    "\n",
    "\n",
    "# Categorize by type\n",
    "categorized_elements = []\n",
    "for element in raw_pdf_elements:\n",
    "    if \"unstructured.documents.elements.Table\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"table\", text=str(element)))\n",
    "    elif \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        categorized_elements.append(Element(type=\"text\", text=str(element)))\n",
    "\n",
    "# Tables\n",
    "table_elements = [e for e in categorized_elements if e.type == \"table\"]\n",
    "print(len(table_elements))\n",
    "\n",
    "# Text\n",
    "text_elements = [e for e in categorized_elements if e.type == \"text\"]\n",
    "print(len(text_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "os.environ['OPENAI_API_KEY']='any'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "prompt_text = \"\"\"You are an assistant tasked with summarizing tables and text. \\\n",
    "Give a concise summary of the table or text. Table or text chunk: {element} \"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_text)\n",
    "base_url = \"http://localhost:8080/\"\n",
    "# Summary chain\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o\",base_url=base_url)\n",
    "summarize_chain = {\"element\": lambda x: x} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2777\n"
     ]
    }
   ],
   "source": [
    "# Apply to text\n",
    "texts = [i.text for i in text_elements]\n",
    "text_summaries = summarize_chain.batch(texts, {\"max_concurrency\": 1},)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summaries = []\n",
    "for e in text_elements:\n",
    "    t = e.text\n",
    "    s = summarize_chain.invoke(t)\n",
    "    text_summaries.append(s)\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import chromadb\n",
    "client = chromadb.PersistentClient('./chroma_docs')\n",
    "collection = client.get_or_create_collection('documents_summary')\n",
    "#collection_table = client.get_or_create_collection('table_summary')\n",
    "\n",
    "\n",
    "ids = [files[0]+'_'+ str(i) for i in range(len(text_summaries))]\n",
    "collection.upsert(ids=ids,documents=text_summaries)\n",
    "collection.count()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to tables\n",
    "tables = [i.text for i in table_elements]\n",
    "table_summaries = summarize_chain.batch(tables, {\"max_concurrency\": 1})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 2304.12244v2.pdf_table_0\n",
      "Add of existing embedding ID: 2304.12244v2.pdf_table_1\n",
      "Add of existing embedding ID: 2304.12244v2.pdf_table_2\n",
      "Add of existing embedding ID: 2304.12244v2.pdf_table_3\n",
      "Add of existing embedding ID: 2304.12244v2.pdf_table_4\n",
      "Add of existing embedding ID: 2304.12244v2.pdf_table_5\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_0\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_1\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_2\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_3\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_4\n",
      "Insert of existing embedding ID: 2304.12244v2.pdf_table_5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [files[0]+'_table_'+ str(i) for i in range(len(table_elements))]\n",
    "collection.add(ids=ids,documents=table_summaries)\n",
    "collection.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

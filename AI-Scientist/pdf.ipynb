{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypdf\n",
    "\n",
    "mlts = pypdf.PdfReader('./mlts.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ''\n",
    "texts =[]\n",
    "for i,p in enumerate(mlts.pages):\n",
    "    t +=f'\\nPage {i+1}\\n'+ p.extract_text()\n",
    "    if i%10==9:\n",
    "        texts.append(t)\n",
    "        t=''\n",
    "        \n",
    "texts.append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Page 1\n",
      "MachineLearning forTime Series (MLTS orMLTS-Deluxe Lectures)Dr. Dario ZancaMachine Learning and Data Analytics (MaD) LabFriedrich-Alexander-Universit√§t Erlangen-N√ºrnberg18.10.2022\n",
      "Page 2\n",
      "Organisational InformationMachine Learning for time series‚Ä¢5 ECTS‚Ä¢Lectures + ExercisesMachine Learning for Time Series (Deluxe)‚Ä¢7.5 ECTS‚Ä¢Lectures + Exercises + Project\n",
      "Page 3\n",
      "Topics overview‚Ä¢Time series fundamentals and definitions (2 lectures) √ü ‚Ä¢Bayesian Inference (1 lecture) ‚Ä¢Gaussian processes (2 lectures)‚Ä¢State space models (2 lectures) ‚Ä¢Autoregressive models (1 lecture)‚Ä¢Data mining on time series (1 lecture)‚Ä¢Deep learning on time series (4 lectures)‚Ä¢Domain adaptation (1 lecture)\n",
      "Page 4\n",
      "Course timesLectures (online)A new lecture recording is generally released every Thursday on FAU.TVConsultation hours by appointment, write to dario.zanca@fau.de Exercises (online)Live Zoom Session starting on November 3rd Recordings from previous editions are available at https://www.fau.tv/course/id/3178StudOn2023-2024:https://www.studon.fau.de/crs5276833.html\n",
      "Page 5\n",
      "Exams and evaluationWritten Exam (5 ECTS)‚Ä¢ 70% from lectures, 30% from exercises‚Ä¢On-campus \n",
      "Page 6\n",
      "Course organizersLecturersMachine Learning and Data Analytics (MaD) Lab‚Ä¢Dr. Dario Zanca, dario.zanca@fau.de*‚Ä¢Prof. Dr. Bj√∂rn Eskofier, bjoern.eskofier@fau.de\n",
      "* Please, address all your correspondence about the course to Dr. Dario Zanca\n",
      "Page 7\n",
      "Course organizersTeaching assistantsExercises, responsibles:‚Ä¢Richard Dirauf(M.Sc.), richard.dirauf@fau.de‚Ä¢PhilippSchlieper(M.Sc.), philipp.schlieper@fau.de\n",
      "Page 8\n",
      "ReferencesMachine learning: A Probabilistic Perspective,by Kevin Murphy (2012)The Elements of Statistical Learning: Data Mining, Inference, and Predictionby Trevor Hastie, Robert Tibshirani, and Jerome Friedman (2009)Deep Learningby Ian Goodfellow, YoshuaBengio, and Aaron Courville (2016)\n",
      "\n",
      "Page 9\n",
      "\n",
      "Page 10\n",
      "Time series fundamentalsMotivations\n"
     ]
    }
   ],
   "source": [
    "slides = texts[0]\n",
    "print(slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from utils import extract_json_between_markers\n",
    "import pandas as pd\n",
    "\n",
    "genai.configure(api_key='AIzaSyDcsi9U5RgrnT3BG34Q0SMbbIvBc5kyFG0')\n",
    "safe = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "]\n",
    "system = \"\"\"You are an examiner who creates various types of questions from course slides for a university exam.\n",
    "The type of questions can be fill_blank, mathematical formula, reasoning, conceptual, definition, calculation, etc.\n",
    "Provide your response in the following JSON format:\n",
    "'''json\n",
    "\"Type\": Type of the Question.\n",
    "\"Difficulty\": The hardness level of the Question ranges from 1 to 10.\n",
    "\"Page\": The page number that the answer is there.\n",
    "\"Hash_Tag\": one-word #hash_tag for the Question.\n",
    "\"Question\": This Question MUST be from the provided slides.\n",
    "\"Answer\": This is the Answer to the Question from the slides.\n",
    "'''\n",
    "\"\"\",\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\",\n",
    "                              system_instruction=system,\n",
    "                              safety_settings=safe,\n",
    "                              )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"Type\": \"definition\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 51,\n",
      "    \"Hash_Tag\": \"#CLT\",\n",
      "    \"Question\": \"Explain the Central Limit Theorem (CLT) in the context of time series. What are the precise conditions required for the CLT to hold in a time series context?\",\n",
      "    \"Answer\": \"The Central Limit Theorem (CLT) states that the sum of independent and identically distributed (i.i.d.) random variables converges to a normal distribution as the number of variables increases. For stationary time series with a finite mean (ùúá) and long-run variance (ùúé^2), the CLT holds, meaning the distribution of the sample mean approaches a normal distribution with mean ùúá and variance ùúé^2/n, where n is the number of observations.  The CLT applies to time series as long as the series is stationary and the observations are independent.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 9,\n",
      "    \"Page\": 52,\n",
      "    \"Hash_Tag\": \"#CLT_Importance\",\n",
      "    \"Question\": \"Explain how the CLT's applicability to a time series allows us to utilize a broader range of statistical methods. Why is it especially beneficial for statistical inference?\",\n",
      "    \"Answer\": \"The CLT's applicability to time series enables us to use statistical methods that rely on the assumption of normality. This is because the CLT allows us to approximate the distribution of the sample mean as normal, even when the individual observations in the time series are not normally distributed.  This is crucial for statistical inference because it allows us to generalize results from a sample to the population. For example, we can use hypothesis testing and confidence interval estimation, which are based on the assumption of normality, to draw conclusions about the population based on a sample from a time series.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"conceptual\",\n",
      "    \"Difficulty\": 7,\n",
      "    \"Page\": 52,\n",
      "    \"Hash_Tag\": \"#CLT_Limitations\",\n",
      "    \"Question\": \"Why might the CLT not be directly applicable to many real-world time series? What are some common issues encountered, and how can these be addressed?\",\n",
      "    \"Answer\": \"Real-world time series often violate the assumptions of the CLT, particularly the assumption of independence. Time series data often exhibits dependence, where values at one point in time are correlated with values at previous time points. This violates the independence assumption. Furthermore, real-world time series are not always stationary; their statistical properties can change over time. This is another violation of the CLT assumptions. To address these issues, we can try to transform the time series to make it stationary, using techniques such as differencing or other transformations. Additionally, we can explore alternative versions of the CLT that accommodate dependence, such as the CLT for M-dependent random variables.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"fill_blank\",\n",
      "    \"Difficulty\": 6,\n",
      "    \"Page\": 54,\n",
      "    \"Hash_Tag\": \"#M-dependent\",\n",
      "    \"Question\": \"A stochastic process {ùëã_t} is said to be **_____** if ùëã_t and ùëã_{t-k} are independent for k > **_____**.\",\n",
      "    \"Answer\": \"M-dependent, M\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"mathematical_formula\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 54,\n",
      "    \"Hash_Tag\": \"#M-dependent_CLT\",\n",
      "    \"Question\": \"State the CLT for an M-dependent stationary process {ùëã_t} with mean ùúá, covariance ùõæ_k, and variance of the mean of n observations denoted as V_n. Express V_n in terms of ùõæ_k.\",\n",
      "    \"Answer\": \"If V_n > 0, then ‚àön(ùëã_nÃÖ - ùúá) converges in distribution to N(0, V_n), where V_n = Œ£_{k=-(n-1)}^{n-1} (1 - |k|/n) ùõæ_k.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"conceptual\",\n",
      "    \"Difficulty\": 6,\n",
      "    \"Page\": 57,\n",
      "    \"Hash_Tag\": \"#TimeSeriesImportance\",\n",
      "    \"Question\": \"Explain how the advent of digitalization has enhanced the importance of time series analysis in modern times.\",\n",
      "    \"Answer\": \"Digitalization has led to a massive increase in the collection and availability of time series data.  This data comes from various sources, including sensors, social media, financial markets, and more. Analyzing this data is crucial for understanding trends, making predictions, and optimizing processes in numerous fields. Therefore, the importance of time series analysis has grown significantly with the rise of digitalization.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 7,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#TimeSeriesProperties\",\n",
      "    \"Question\": \"Discuss the relevance of the \"Regularly vs Irregularly Sampled\" property of a time series in the context of its analysis. How does this property influence the choice of methods or the interpretation of results?\",\n",
      "    \"Answer\": \"Whether a time series is regularly or irregularly sampled affects the methods we can employ for analysis. Regularly sampled data allows for consistent time intervals between observations, making it easier to apply standard time series methods. Irregularly sampled data requires more sophisticated methods that can handle the non-uniform time intervals. Additionally, interpreting the results from an irregularly sampled time series requires careful consideration of the non-uniform nature of the data, as it can introduce bias or affect the estimation of trends and seasonalities.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 59,\n",
      "    \"Hash_Tag\": \"#Stationarity_CLT\",\n",
      "    \"Question\": \"Explain why the Central Limit Theorem (CLT) is only applicable to stationary time series. Why is it important to ensure stationarity before applying the CLT, and what are the implications if the data is not stationary?\",\n",
      "    \"Answer\": \"The CLT requires the time series to be stationary because it relies on the assumption that the mean and variance of the time series remain constant over time. Non-stationary time series exhibit changing statistical properties, making it difficult to apply the CLT and make accurate inferences. If the data is not stationary, we need to use methods to transform the series into a stationary process, such as differencing. This is crucial because the CLT provides a foundation for statistical inference, and applying it to non-stationary data can lead to misleading results and conclusions.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"conceptual\",\n",
      "    \"Difficulty\": 9,\n",
      "    \"Page\": 59,\n",
      "    \"Hash_Tag\": \"#TimeSeriesDependencies\",\n",
      "    \"Question\": \"Discuss the importance of understanding and analyzing the dependences present in time series data. How do these dependencies affect the applicability of standard methods, and what are some approaches for dealing with them?\",\n",
      "    \"Answer\": \"Understanding and analyzing the dependences in time series data is crucial for accurate modeling and forecasting. These dependencies, also known as autocorrelations, reflect the relationships between observations at different time points. Standard methods for time series analysis often assume independence or a specific form of dependence, which can be violated in real-world data. Ignoring these dependencies can lead to inaccurate models and predictions.  To handle dependencies, we can explore methods like autoregressive (AR) models, moving average (MA) models, or ARMA/ARIMA models, which explicitly account for the temporal relationships present in the data.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 7,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#TimeSeriesTypes\",\n",
      "    \"Question\": \"Explain the distinction between \"deterministic\" and \"non-deterministic\" time series. How does this distinction impact the choice of analysis techniques?\",\n",
      "    \"Answer\": \"Deterministic time series are fully predictable based on past values. They can be represented by a mathematical function, and their future values can be precisely calculated. In contrast, non-deterministic time series contain a random component and cannot be fully predicted based on past values alone. They typically exhibit randomness or noise. This distinction impacts the choice of analysis techniques, as deterministic time series can be modeled using deterministic methods like regression analysis, while non-deterministic time series require methods that account for the stochastic component, such as ARMA or ARIMA models.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#Ergodicity\",\n",
      "    \"Question\": \"Explain the concept of \"ergodicity\" in the context of time series analysis. Why is ergodicity important for making inferences about a time series from a single realization?\",\n",
      "    \"Answer\": \"Ergodicity in time series implies that the time average of a single realization of the process converges to the ensemble average over a large number of realizations. This means that the statistical properties of the time series can be inferred from a single realization, assuming it is ergodic. Ergodicity is crucial because it allows us to use a single time series to estimate the properties of the entire process, which is often more practical than obtaining multiple realizations of the process.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"definition\",\n",
      "    \"Difficulty\": 6,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#Univariate\",\n",
      "    \"Question\": \"Define \"Univariate\" time series and give an example.\",\n",
      "    \"Answer\": \"A univariate time series is a sequence of observations of a single variable over time. For example, the daily closing price of a particular stock is a univariate time series.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"definition\",\n",
      "    \"Difficulty\": 6,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#Multivariate\",\n",
      "    \"Question\": \"Define \"Multivariate\" time series and give an example.\",\n",
      "    \"Answer\": \"A multivariate time series consists of observations of multiple variables over time. For example, tracking the daily temperature and humidity levels in a city would represent a multivariate time series.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"definition\",\n",
      "    \"Difficulty\": 6,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#Periodic\",\n",
      "    \"Question\": \"Define \"Periodic\" time series and give an example.\",\n",
      "    \"Answer\": \"A periodic time series exhibits a pattern that repeats at regular intervals. For example, daily sales of a particular product might follow a weekly pattern, peaking on weekends and decreasing during weekdays.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"calculation\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 54,\n",
      "    \"Hash_Tag\": \"#M-dependent_Variance\",\n",
      "    \"Question\": \"Assume an M-dependent stationary process {ùëã_t} with mean ùúá and autocovariance function ùõæ_k = 0.5^|k|. Calculate the variance of the mean of 100 observations (V_100) for this process.\"\n",
      "    \"Answer\": \"V_100 = Œ£_{k=-99}^{99} (1 - |k|/100) 0.5^|k|. Calculate this sum to obtain the variance.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"conceptual\",\n",
      "    \"Difficulty\": 9,\n",
      "    \"Page\": 59,\n",
      "    \"Hash_Tag\": \"#NonStationarity\",\n",
      "    \"Question\": \"Describe the challenges associated with analyzing non-stationary time series data, and outline common techniques used to address these challenges. How do these techniques help make the data amenable to statistical inference?\",\n",
      "    \"Answer\": \"Non-stationary time series pose several challenges: (1) The CLT doesn't directly apply, so we can't assume normality for statistical inference. (2) Standard time series models that rely on stationarity may provide inaccurate predictions. To address these challenges, we use techniques like differencing, which removes the trend and makes the data stationary. Other techniques include detrending and seasonal adjustment. These techniques help make the data amenable to statistical inference by transforming the non-stationary time series into a stationary one, allowing us to apply the CLT and utilize standard time series models effectively.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"conceptual\",\n",
      "    \"Difficulty\": 8,\n",
      "    \"Page\": 52,\n",
      "    \"Hash_Tag\": \"#CLT_Regression\",\n",
      "    \"Question\": \"Explain how the CLT justifies the assumption of normality for the error terms in linear regression models used to analyze time series data. Why is this assumption important for the validity of the regression model?\",\n",
      "    \"Answer\": \"The CLT justifies the assumption of normality for the error terms in linear regression because it suggests that the sum of a large number of independent random variables (errors in this case) converges to a normal distribution. This assumption is crucial for the validity of the regression model because it allows us to use standard statistical inference techniques, such as hypothesis testing and confidence interval estimation, which are based on the assumption of normality. It enables us to make reliable conclusions about the relationship between variables and to estimate the model parameters accurately.\"\n",
      "  },\n",
      "  {\n",
      "    \"Type\": \"reasoning\",\n",
      "    \"Difficulty\": 7,\n",
      "    \"Page\": 58,\n",
      "    \"Hash_Tag\": \"#Discrete_Continuous\",\n",
      "    \"Question\": \"Describe the difference between \"Discrete\" and \"Continuous\" time series. Provide examples of each and discuss how this difference might influence the choice of analysis methods.\",\n",
      "    \"Answer\": \"Discrete time series have observations taken at specific, discrete points in time. For example, daily stock prices or monthly sales figures are discrete time series. Continuous time series have observations measured continuously over time, such as temperature readings from a sensor. The difference influences the choice of analysis methods because discrete time series can be modeled using discrete-time methods, while continuous time series require continuous-time methods, which may involve differential equations or other techniques that handle continuous data.\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "slides = texts[5]\n",
    "\n",
    "prompt = \"\"\"\n",
    "From the following slides create 20 difficult questions for 'machine learning for time series' exam. \n",
    "''' SlIDES:\n",
    "{slides}\n",
    "'''\n",
    "The slides may contain unimportant and unrelated information to the machine learning in time series. Do not use that information in your questions.\n",
    "You have to create ALL type of questions.\n",
    "\"\"\"\n",
    "noq =4\n",
    "prompt= prompt.format(slides=slides,noq = noq)\n",
    "res = model.generate_content(prompt).text\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "js = extract_json_between_markers(res)\n",
    "df = pd.DataFrame(js)\n",
    "print(js)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = rows.drop_duplicates(['query','label'])\n",
    "import time\n",
    "for i,x in rows.iterrows():\n",
    "    print(i)\n",
    "    print(x['query'])\n",
    "    print(x['element'])\n",
    "    time.sleep(1)\n",
    "    qe.loc[i,'label']=input()\n",
    "\n",
    "qe = pd.read_excel('query_element_4.xlsx')\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 5)\n",
    "\n",
    "#qe['label'].value_counts()\n",
    "c1 =qe['label'].notna()\n",
    "#c2 = qe['auto_label']=='password' \n",
    "rows = qe[c1].drop_duplicates(['query'])\n",
    "\n",
    "rows\n",
    "#qe[qe['auto_label']=='email']\n",
    "\n",
    "#qe[qe['auto_label'].notna()]\n",
    "\n",
    "\n",
    "qe.loc[348,'label']='picture'\n",
    "qe.loc[349,'label']='recommender'\n",
    "qe.loc[350,'label']='major'\n",
    "\n",
    "qe.loc[4,'label']='subscribe'\n",
    "qe.loc[15,'label']='search'\n",
    "qe.loc[44,'label']='address'\n",
    "qe.loc[58,'label']='cover letter'\n",
    "qe.loc[366,'label']='cover letter'\n",
    "qe.loc[410,'label']='cover letter'\n",
    "qe.loc[412,'label']='cover letter'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qe.loc[65,'label']=pd.NA\n",
    "qe.loc[309,'label']='cover letter'\n",
    "qe.loc[319,'label']='show password'\n",
    "qe.loc[749:753,'label']='transcript'\n",
    "qe.loc[789,'label']='university'\n",
    "qe.loc[790,'label']='university'\n",
    "\n",
    "qe.loc[1587,'label']='ethnicity'\n",
    "\n",
    "qe.loc[426,'label']='career level'\n",
    "qe.loc[433,'label']='career level'\n",
    "qe.loc[1305,'label']='career level'\n",
    "qe.loc[1481,'label']='career level'\n",
    "\n",
    "qe.loc[154,'label']='newsletter'\n",
    "qe.loc[1480,'label']='newsletter'\n",
    "qe.loc[1196,'label']='newsletter'\n",
    "qe.loc[1530,'label']='sex'\n",
    "\n",
    "\n",
    "\n",
    "qe.loc[1286,'label']='register'\n",
    "qe.loc[320,'label']='login'\n",
    "\n",
    "qe.loc[150,'label']='company'\n",
    "qe.loc[1171,'label']='company'\n",
    "\n",
    "qe.loc[320,'label']='login'\n",
    "qe.loc[60,'label']='captcha'\n",
    "qe.loc[63,'label']='captcha'\n",
    "qe.loc[698,'label']='captcha'\n",
    "qe.loc[734,'label']='captcha'\n",
    "\n",
    "\n",
    "\n",
    "qe.loc[320,'label']='login'\n",
    "\n",
    "\n",
    "qe.loc[1586,'label']='ethnicity'\n",
    "qe.loc[81,'label']='skill'\n",
    "qe.loc[1586,'label']='ethnicity'\n",
    "qe.loc[1504,'label']='find us'\n",
    "qe.loc[689,'label']='find us'\n",
    "qe.loc[1532,'label']='sex'\n",
    "qe.loc[1548,'label']='sex'\n",
    "\n",
    "qe.loc[1291:1298,'label']='distance'\n",
    "qe.loc[93,'label']='submit'\n",
    "qe.loc[189,'label']='cancel'\n",
    "\n",
    "\n",
    "qe.loc[500,'label']= pd.NA\n",
    "qe.loc[501,'label']= pd.NA\n",
    "qe.loc[146,'label']= pd.NA\n",
    "qe.loc[295,'label']= pd.NA\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sentence_transformers.similarity_functions import cos_sim \n",
    "from IPython.display import clear_output\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,x in rows.iterrows():\n",
    "        _q = embeding_model.encode(x['query'].lower())\n",
    "        _l = embeding_model.encode(x['label'])\n",
    "        sim = cos_sim(_q,_l)\n",
    "        c = sim<0.4\n",
    "        if c==True:\n",
    "            print(i)\n",
    "            print(sim)\n",
    "            print(x['query'])\n",
    "            print(x['element'])\n",
    "            print(x['label'])\n",
    "            print('--------------------------------------------------')\n",
    "            #input()\n",
    "            #clear_output(True)\n",
    "\n",
    "        #break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qe.loc[32,'label']='cookie'\n",
    "qe.loc[267,'label']='longitude'\n",
    "qe.loc[1038,'label']='privacy'\n",
    "qe.loc[1008,'label']='forgot password'\n",
    "qe.loc[1452,'label']='forgot password'\n",
    "qe.loc[1437,'label']='forgot password'\n",
    "qe.loc[1321,'label']='forgot password'\n",
    "qe.loc[98,'label']='forgot password'\n",
    "qe.loc[1319,'label']='username'\n",
    "\n",
    "\n",
    "qe.loc[929,'label']='recommender'\n",
    "qe.loc[464,'label']='captcha'\n",
    "qe.loc[369,'label']='captcha'\n",
    "\n",
    "qe.loc[873,'label']='username'\n",
    "qe.loc[250,'label']='last name'\n",
    "qe.loc[155,'label']='pronoun'\n",
    "qe.loc[141,'label']='pronoun'\n",
    "\n",
    "qe.loc[123,'label']='job title'\n",
    "qe.loc[763,'label']='job title'\n",
    "qe.loc[273,'label']='job title'\n",
    "qe.loc[229,'label']='job title'\n",
    "\n",
    "\n",
    "qe.loc[102,'label']='sex'\n",
    "qe.loc[101,'label']='sex'\n",
    "\n",
    "qe.loc[125,'label']='available from'\n",
    "qe.loc[1329,'label']='available from'\n",
    "\n",
    "qe.loc[135,'label']='graduation year'\n",
    "qe.loc[812,'label']='graduation year'\n",
    "\n",
    "qe.loc[533,'label']='years of experience'\n",
    "qe.loc[1274,'label']='salary'\n",
    "qe.loc[1325,'label']='salary'\n",
    "qe.loc[1330,'label']='salary'\n",
    "qe.loc[551,'label']='salary'\n",
    "\n",
    "qe.loc[1178,'label']='cover letter'\n",
    "qe.loc[1132,'label']='cover letter'\n",
    "qe.loc[1057,'label']='cover letter'\n",
    "qe.loc[1032,'label']='cover letter'\n",
    "qe.loc[1030,'label']='cover letter'\n",
    "qe.loc[1032,'label']='cover letter'\n",
    "qe.loc[1032,'label']='cover letter'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qe.loc[1494,'label']='major'\n",
    "qe.loc[1490,'label']='major'\n",
    "\n",
    "qe.loc[810,'label']='major'\n",
    "\n",
    "qe.loc[1577,'label']='zip'\n",
    "qe.loc[889,'label']='zip'\n",
    "\n",
    "qe.loc[544,'label']='house number'\n",
    "qe.loc[426,'label']='career level'\n",
    "qe.loc[101,'label']='sex'\n",
    "qe.loc[1277,'label']='picture'\n",
    "qe.loc[1124,'label']='cancel'\n",
    "qe.loc[101,'label']='sex'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_dataset = pd.read_excel(\"train_forms.xlsx\")[[\"input_text\", \"label\"]]\n",
    "\n",
    "train_dataset.drop_duplicates([\"input_text\"]).reset_index(drop=True)\n",
    "c = train_dataset[\"label\"] == \"other\"\n",
    "train_dataset.loc[c, \"label\"] = pd.NA\n",
    "c = train_dataset[\"label\"] == \"eligible\"\n",
    "train_dataset.loc[c, \"label\"] = pd.NA\n",
    "c = train_dataset[\"label\"] == \"birthdate\"\n",
    "train_dataset.loc[c, \"label\"] = \"birth\"\n",
    "c = train_dataset[\"label\"] == \"resident country\"\n",
    "train_dataset.loc[c, \"label\"] = \"country\"\n",
    "c = train_dataset[\"label\"] == \"residentcountry\"\n",
    "train_dataset.loc[c, \"label\"] = \"country\"\n",
    "c = train_dataset[\"label\"] == \"citizen country\"\n",
    "train_dataset.loc[c, \"label\"] = \"country\"\n",
    "c = train_dataset[\"label\"] == \"recommendation\"\n",
    "train_dataset.loc[c, \"label\"] = \"recommender\"\n",
    "c = train_dataset[\"label\"] == \"german language level\"\n",
    "train_dataset.loc[c, \"label\"] = \"German language level\"\n",
    "c = train_dataset[\"label\"] == \"english language level\"\n",
    "train_dataset.loc[c, \"label\"] = \"English language level\"\n",
    "\n",
    "\n",
    "\n",
    "train_dataset[\"label\"].unique()\n",
    "train_dataset = train_dataset.dropna().reset_index(drop=True)\n",
    "\n",
    "# c = train_dataset['labels']=='privacy'\n",
    "# train_dataset.loc[c,:]\n",
    "\n",
    "lll = []\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./html/1.html','r',encoding='utf-8') as f:\n",
    "    html = f.read()\n",
    "\n",
    "\n",
    "html = BeautifulSoup(html,'html.parser')\n",
    "import os\n",
    "from bs4 import BeautifulSoup,PageElement,Comment\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess_form(form):\n",
    "    if isinstance(form,str):\n",
    "        form = BeautifulSoup(form,'html.parser')\n",
    "        \n",
    "    form:PageElement\n",
    "    comments=form.find_all(string=lambda text: isinstance(text, Comment))\n",
    "    for comment in comments:\n",
    "        comment.extract()\n",
    "    all_tags = form.find_all()\n",
    "\n",
    "    # Remove all tags except for 'link', 'input', and 'select' tags\n",
    "    i=0\n",
    "    for element in all_tags:\n",
    "        element:PageElement\n",
    "        for k in ['style','class','bounding_box_rect','is_clickable']:\n",
    "            if k in element.attrs:\n",
    "                    del element[k]\n",
    "                    pass\n",
    "           \n",
    "        if 'type' in element.attrs and element.attrs['type']=='hidden':\n",
    "            element.unwrap()\n",
    "            pass\n",
    "            \n",
    "        \n",
    "        #if element.name  in ['div','text']: \n",
    "        if element.name not in ['a', 'input', 'select','radio','button','textarea','checkbox','option']:\n",
    "            \n",
    "            element.unwrap()\n",
    "            #print(element)\n",
    "            pass\n",
    "        else:\n",
    "            #element['backend_node_id']=i\n",
    "            pass\n",
    "\n",
    "            \n",
    "                \n",
    "            i+=1\n",
    "            \n",
    "    #print(form.prettify() )\n",
    "    return form\n",
    "    \n",
    "import re\n",
    "\n",
    "def get_query_element(f):\n",
    "    query_element=[]\n",
    "    mytext  = ''\n",
    "    texts = []\n",
    "    \n",
    "    for element in f:\n",
    "        # Get the text before the element\n",
    "        #print('-----------------------------')\n",
    "        if element.name == None:\n",
    "            t = element.text.replace('\\n','').replace('\\t','').strip()\n",
    "            if t!='' and len(t)>2:\n",
    "                #mytext+=t+'\\n '\n",
    "                texts.append(t)\n",
    "        else:\n",
    "            \n",
    "            \n",
    "            mytext = ''.join(texts[-1:]) +' '+ element.text.strip()\n",
    "            element : PageElement\n",
    "            \n",
    "            query_element.append({'query':mytext,'element': str(element).replace('\\n','').replace('  ','').strip()})\n",
    "            mytext =''\n",
    "            texts=[]\n",
    "        \n",
    "    return query_element\n",
    "\n",
    "\n",
    "def get_query_html(f):\n",
    "    f:PageElement\n",
    "    childs = f.find_all(string=True,recursive=False)\n",
    "    for c in childs:\n",
    "        print('---------------------')\n",
    "        print(c)\n",
    "    pass\n",
    "    \n",
    "    \n",
    "    \n",
    "def tag_equal(d,tag):\n",
    "    d:PageElement\n",
    "    if tag=='text' and d.name=='input' and  d['type']==None:\n",
    "        return True\n",
    "    if d.name==tag or (d.name=='input' and d['type']==tag):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    \n",
    "def process_query_element(qe_list):\n",
    "    for d in qe_list:\n",
    "        q = d['query']\n",
    "        e = d['element']\n",
    "        d = BeautifulSoup(d,'html.parser').find()\n",
    "        d:PageElement\n",
    "        if tag_equal(d,'checkbox'):\n",
    "            pass\n",
    "    pass\n",
    "            \n",
    "        \n",
    "\n",
    "with open('./html/1.html','r',encoding='utf-8') as f:\n",
    "    html = f.read()\n",
    "    \n",
    "soup = BeautifulSoup(html,'html.parser')\n",
    "forms = soup.find_all('form')\n",
    "for f in forms:\n",
    "    f = preprocess_form(f)\n",
    "    d = get_query_element(f)\n",
    "    print(d)\n",
    "    \n",
    "    \n",
    "forms=pd.read_excel('forms copy.xlsx',index_col=0).reset_index(drop=True)\n",
    "\n",
    "for _ ,f in forms.iterrows():\n",
    "    print(_)\n",
    "    #print(f['form'])\n",
    "    f = str(f['form'])\n",
    "    #print(f)\n",
    "    #f = BeautifulSoup(str(f),'html.parser')\n",
    "    f = preprocess_form(f)\n",
    "    #f = f.find_all()\n",
    "    #print(f)\n",
    "    d = get_query_element(f)\n",
    "    d = pd.DataFrame(d)\n",
    "    #print(d)\n",
    "    for i,x in d.iterrows():\n",
    "        print(x['query'])\n",
    "        print(x['element'])\n",
    "        print('--------------------------------------------------')\n",
    "\n",
    "\n",
    "    print('***************************************************')\n",
    "    input()\n",
    "    \n",
    "model.eval()\n",
    "toks = tokenizer.apply_chat_template([ [#{\"role\":\"system\",\"content\":\"\"}\n",
    "                                {\"role\":\"user\", \"content\":\"\"\"Your answer has to be in json format like {\"answer\":\"\"}. Use this content in your answer:\\n\"\"\"+to_str(person)}\n",
    "                               ,{\"role\":\"user\", \"content\":\"What is this HTML element about?\\n\"+str(x['query'])+x['element'] }\n",
    "                               #,{\"role\":\"assistant\",\"content\":\"\"}\n",
    "                               ] for i,x in qe.iterrows()] ,truncation=True,max_length=512)  # ,return_tensors='pt')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from ast import keyword\n",
    "import json\n",
    "with torch.no_grad():\n",
    "  for i in range(0,len(toks)):\n",
    "      t = toks[i]\n",
    "      t = torch.tensor([t]).cuda()\n",
    "\n",
    "      o = model.generate(input_ids=t,max_new_tokens=20,do_sample=False,)\n",
    "      decoded = tokenizer.decode(o[0][t.shape[1]:])\n",
    "      #print(decoded)\n",
    "\n",
    "      try:\n",
    "                _s = decoded.find('{')\n",
    "                _e = decoded.find('}',_s)+1\n",
    "                #print(decoded[_s:])\n",
    "                #print(decoded[_s:_e])\n",
    "                answer = json.loads(decoded[_s:_e])['answer']\n",
    "                print(i,answer)\n",
    "\n",
    "                for k,v in person.items():\n",
    "                    if v==answer:\n",
    "\n",
    "                      qe.loc[i,'label'] = k\n",
    "                    else:\n",
    "                      qe.loc[i,'label'] = pd.NA\n",
    "\n",
    "                qe.loc[i,'answer']=answer\n",
    "\n",
    "\n",
    "                pass\n",
    "      except Exception as e:\n",
    "                print(\"ERROR: \",decoded)\n",
    "                print(\"---------------------------------\")\n",
    "\n",
    "                print(e)\n",
    "\n",
    "                pass\n",
    "            \n",
    "            \n",
    "def auto_label(x):\n",
    "    element = BeautifulSoup(x['element'],'html.parser').find()\n",
    "    #print(element)\n",
    "    type = element.attrs.get('type')\n",
    "    print(type)\n",
    "    if type=='email':\n",
    "        return 'email'\n",
    "    elif type=='search':\n",
    "        return 'search'\n",
    "    elif type=='password':\n",
    "        return 'password'\n",
    "    elif type=='tel':\n",
    "        return 'phone number'\n",
    "    return pd.NA\n",
    "    \n",
    "    \n",
    "value_to_key = {}\n",
    "for k,v in person.items():\n",
    "    value_to_key[v]=k\n",
    "    \n",
    "\"\"\"\n",
    "for i,x in rows.iterrows():\n",
    "    #l  = auto_label(x)\n",
    "    try:\n",
    "        #l = value_to_key[x['answer']]\n",
    "        #qe.loc[i,'label'] = l\n",
    "        #print(l)\n",
    "        pass\n",
    "    except:\n",
    "        #qe.loc[i,'label'] = pd.NA\n",
    "        pass\n",
    "    #print(label)\n",
    "    \n",
    "\"\"\"\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

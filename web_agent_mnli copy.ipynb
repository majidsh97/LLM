{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification,AutoTokenizer,AutoModelForMaskedLM , Trainer,TrainingArguments,BitsAndBytesConfig,pipeline,default_data_collator\n",
    "from peft import get_peft_model,LoraConfig\n",
    "import datasets\n",
    "import torchmetrics\n",
    "import torch\n",
    "from hqq.engine.hf import HQQModelForCausalLM\n",
    "from hqq.models.hf.base import AutoHQQHFModel\n",
    "from huggingface_hub import snapshot_download\n",
    "#import deepspeed\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from var_dump import var_dump\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "cache_dir='/proj/ciptmp/ix05ogym/.cache/'\n",
    "output_dir = cache_dir+'outputs/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS={\n",
    "        #----------------------form--------------------------------------\n",
    "       'firstname':['firstname','first_name','forename','first','first-name'],\n",
    "       'lastname':['lastname','last_name','surename','last','last-name'] ,\n",
    "       'email':['email','e-mail','username','user_name','user-name','type=\"email\"'], \n",
    "       'password':['password'], \n",
    "       'cv':['cv','resume','curriculum','vitae'],\n",
    "       'birthdate':['birthdate','birth','dateofbirth','date-of-birth','birth-date'],\n",
    "       'phonenumber':['phonenumber','phone','telephone','tel'],\n",
    "       'housenumber':['hausnummer'],\n",
    "       'residentcountry':['resident','country'],\n",
    "       'citizencountry':['citizen','citizenship','city'],\n",
    "       'transcript':['transcript'],\n",
    "       'coverletter':['coverletter','cover', 'letter'], \n",
    "       'picture':['picture'], \n",
    "       'address':['address','location'],\n",
    "       'linkedin':['linkedin'],\n",
    "       'github':['github'],\n",
    "       'xing':['xing'],\n",
    "       'twitter':['twitter'],\n",
    "       'website':['website'],\n",
    "       'postalcode':['postalcode','zip','zip-code','postal'],\n",
    "       'city':['city'],\n",
    "       'housenumber':['housenumber'], \n",
    "       'salary':['salary'],\n",
    "       'sex':['sex','gender'], \n",
    "       'availablefrom':['noticeprieod'],\n",
    "       'file':['type=\"file\"'],\n",
    "       'captcha':['captcha'],\n",
    "       'submit':['apply','type=\"submit\"'],\n",
    "       'cancel':['cancel'],\n",
    "       'fake':['fake'],\n",
    "       'question':['question'],\n",
    "       'agree':['agree'],\n",
    "       'other':['other'],\n",
    "       'apply':['apply'],\n",
    "       'recommendation':['recommendation'],\n",
    "       'workherebefore':['workherebefore'],\n",
    "       'findus':['find'],\n",
    "       'dropbox':['dropbox'],\n",
    "       'googledrive':['google drive'],\n",
    "       'workhours':['workhours'],\n",
    "       'workduration':[''],\n",
    "       'visa':['visa'],\n",
    "       'eligible':['eligible'],\n",
    "       'germanlevel':['germanlevel'],\n",
    "       'company':[''],#current company\n",
    "       'relocate':[''],\n",
    "       'universityenrollment':[],#are a student?\n",
    "       'englishlevel':[],\n",
    "       #important about job\n",
    "       #important about jobplace?\n",
    "              \n",
    "       #-------------------------------------------------------------------\n",
    "       #-----------------------------------btns ---------------------------\n",
    "       'login':['login','sign'],\n",
    "       'username':['username'],\n",
    "       'register':['register','sign'],\n",
    "       'cookie':['cookie'],\n",
    "       'next':['apply now','next'],\n",
    "       'search':[],\n",
    "       #-------------------------------------------------------------------\n",
    "       \n",
    "       \n",
    "       \n",
    "       \n",
    "       }\n",
    "\n",
    "\n",
    "LABEL_INDEX_TO_KEY = list(KEYWORDS.keys()) #self.personal_data.columns\n",
    "i =0\n",
    "LABEL_KEY_TO_INDEX = {}\n",
    "for key in KEYWORDS:\n",
    "            LABEL_KEY_TO_INDEX[key] =i\n",
    "            i+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = pd.read_pickle('input_text.pkl')\n",
    "#mydata.reset_index(inplace=True)\n",
    "mydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata['labels'].value_counts().plot(figsize=(10,10), kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata[mydata['labels']=='residentcounty']#='residentcountry'\n",
    "mydata.loc[45,'labels'] = 'residentcountry'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"index = (inp['input_ids']== toknizer.mask_token_id).int().argmax().item()\n",
    "print(index ,o.logits.shape)\n",
    "token_id = o.logits[0,index,:].argsort(descending=True)\n",
    "r = toknizer.convert_ids_to_tokens(token_id[:5])\n",
    "MASK = toknizer.convert_tokens_to_string(r[0:1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large-mnli\" , cache_dir=cache_dir)\n",
    "model  = AutoModelForSequenceClassification.from_pretrained(\"FacebookAI/roberta-large-mnli\",\n",
    "                          #quantization_config=GPTQConfig(bits=4, disable_exllama=False),\n",
    "                          #load_in_8bit=True,\n",
    "                          cache_dir=cache_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/480 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 480/480 [00:00<00:00, 1772.47 examples/s]\n",
      "Map: 100%|██████████| 121/121 [00:00<00:00, 2055.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 480\n",
       "})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = datasets.Dataset.from_pandas(mydata)\n",
    "data = data.train_test_split(0.2)\n",
    "train_dataset = data['train']\n",
    "test_dataset = data['test']\n",
    "\n",
    "\n",
    "def preprocess(example):\n",
    "    #print(example['element'])\n",
    "    h = [f\"this text is about {i} .\" for i in example['text']]\n",
    "    t= tokenizer(example['element'],h,return_tensors='pt' , padding=True,truncation=True ,max_length=512).to('cuda')\n",
    "    t['labels'] = [1 for i in example['labels']]\n",
    "    return t\n",
    "    pass\n",
    "\n",
    "train_dataset_tokenized =  train_dataset.map(preprocess,batch_size=32,batched=True,drop_last_batch=False,remove_columns=['text', 'element', 'label', 'input_text'])\n",
    "test_dataset_tokenized =  test_dataset.map(preprocess,batch_size=32,batched=True,drop_last_batch=False,remove_columns=['text', 'element', 'label', 'input_text'])\n",
    "\n",
    "train_dataset_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 41552,\n",
       " 46797,\n",
       " 1907,\n",
       " 40635,\n",
       " 29015,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 179,\n",
       " 42679,\n",
       " 40635,\n",
       " 22303,\n",
       " 113,\n",
       " 13561,\n",
       " 40635,\n",
       " 29015,\n",
       " 12,\n",
       " 46797,\n",
       " 12,\n",
       " 8569,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 33480,\n",
       " 40635,\n",
       " 14869,\n",
       " 35,\n",
       " 50,\n",
       " 90,\n",
       " 6,\n",
       " 37035,\n",
       " 293,\n",
       " 1245,\n",
       " 1021,\n",
       " 3624,\n",
       " 618,\n",
       " 459,\n",
       " 4494,\n",
       " 9791,\n",
       " 113,\n",
       " 766,\n",
       " 40635,\n",
       " 462,\n",
       " 113,\n",
       " 7241,\n",
       " 43779,\n",
       " 43651,\n",
       " 40635,\n",
       " 1529,\n",
       " 113,\n",
       " 45729,\n",
       " 40635,\n",
       " 2723,\n",
       " 6,\n",
       " 37035,\n",
       " 293,\n",
       " 1245,\n",
       " 1021,\n",
       " 3624,\n",
       " 2968,\n",
       " 329,\n",
       " 113,\n",
       " 923,\n",
       " 40635,\n",
       " 254,\n",
       " 32373,\n",
       " 225,\n",
       " 113,\n",
       " 1380,\n",
       " 40635,\n",
       " 48408,\n",
       " 12,\n",
       " 1409,\n",
       " 922,\n",
       " 298,\n",
       " 506,\n",
       " 364,\n",
       " 134,\n",
       " 267,\n",
       " 45328,\n",
       " 288,\n",
       " 118,\n",
       " 246,\n",
       " 46479,\n",
       " 2,\n",
       " 2,\n",
       " 9226,\n",
       " 2788,\n",
       " 16,\n",
       " 59,\n",
       " 21,\n",
       " 41552,\n",
       " 46797,\n",
       " 1907,\n",
       " 40635,\n",
       " 29015,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 179,\n",
       " 42679,\n",
       " 40635,\n",
       " 22303,\n",
       " 113,\n",
       " 13561,\n",
       " 40635,\n",
       " 29015,\n",
       " 12,\n",
       " 46797,\n",
       " 12,\n",
       " 12196,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 33480,\n",
       " 40635,\n",
       " 7325,\n",
       " 35,\n",
       " 633,\n",
       " 90,\n",
       " 405,\n",
       " 523,\n",
       " 6,\n",
       " 1690,\n",
       " 1725,\n",
       " 605,\n",
       " 2723,\n",
       " 242,\n",
       " 1021,\n",
       " 3624,\n",
       " 542,\n",
       " 1334,\n",
       " 858,\n",
       " 298,\n",
       " 2262,\n",
       " 113,\n",
       " 766,\n",
       " 40635,\n",
       " 1343,\n",
       " 113,\n",
       " 7241,\n",
       " 43779,\n",
       " 43651,\n",
       " 40635,\n",
       " 1529,\n",
       " 113,\n",
       " 45729,\n",
       " 40635,\n",
       " 30056,\n",
       " 90,\n",
       " 405,\n",
       " 523,\n",
       " 1021,\n",
       " 3624,\n",
       " 542,\n",
       " 1334,\n",
       " 858,\n",
       " 298,\n",
       " 2262,\n",
       " 113,\n",
       " 923,\n",
       " 48893,\n",
       " 1380,\n",
       " 40635,\n",
       " 48408,\n",
       " 12,\n",
       " 3103,\n",
       " 1630,\n",
       " 876,\n",
       " 364,\n",
       " 134,\n",
       " 267,\n",
       " 45328,\n",
       " 288,\n",
       " 118,\n",
       " 246,\n",
       " 46479,\n",
       " 14869,\n",
       " 41552,\n",
       " 46797,\n",
       " 1907,\n",
       " 40635,\n",
       " 29015,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 179,\n",
       " 42679,\n",
       " 40635,\n",
       " 22303,\n",
       " 113,\n",
       " 13561,\n",
       " 40635,\n",
       " 29015,\n",
       " 12,\n",
       " 46797,\n",
       " 12,\n",
       " 8569,\n",
       " 113,\n",
       " 10,\n",
       " 6374,\n",
       " 12,\n",
       " 33480,\n",
       " 40635,\n",
       " 14869,\n",
       " 35,\n",
       " 50,\n",
       " 90,\n",
       " 6,\n",
       " 37035,\n",
       " 293,\n",
       " 1245,\n",
       " 1021,\n",
       " 3624,\n",
       " 618,\n",
       " 459,\n",
       " 4494,\n",
       " 9791,\n",
       " 113,\n",
       " 766,\n",
       " 40635,\n",
       " 462,\n",
       " 113,\n",
       " 7241,\n",
       " 43779,\n",
       " 43651,\n",
       " 40635,\n",
       " 1529,\n",
       " 113,\n",
       " 45729,\n",
       " 40635,\n",
       " 2723,\n",
       " 6,\n",
       " 37035,\n",
       " 293,\n",
       " 1245,\n",
       " 1021,\n",
       " 3624,\n",
       " 2968,\n",
       " 329,\n",
       " 113,\n",
       " 923,\n",
       " 40635,\n",
       " 254,\n",
       " 32373,\n",
       " 225,\n",
       " 113,\n",
       " 1380,\n",
       " 40635,\n",
       " 48408,\n",
       " 12,\n",
       " 1409,\n",
       " 922,\n",
       " 298,\n",
       " 506,\n",
       " 364,\n",
       " 134,\n",
       " 267,\n",
       " 45328,\n",
       " 288,\n",
       " 118,\n",
       " 246,\n",
       " 46479,\n",
       " 41207,\n",
       " 465,\n",
       " 225,\n",
       " 41552,\n",
       " 32135,\n",
       " 1907,\n",
       " 40635,\n",
       " 45533,\n",
       " 113,\n",
       " 1380,\n",
       " 40635,\n",
       " 48408,\n",
       " 12,\n",
       " 1180,\n",
       " 246,\n",
       " 19581,\n",
       " 1343,\n",
       " 364,\n",
       " 398,\n",
       " 7488,\n",
       " 288,\n",
       " 1178,\n",
       " 4708,\n",
       " 46479,\n",
       " 41207,\n",
       " 465,\n",
       " 225,\n",
       " 49138,\n",
       " 32135,\n",
       " 15698,\n",
       " 479,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_tokenized[0]['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'is_floating_point'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 27\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m metric(p_label , label_ids )\n\u001b[1;32m     11\u001b[0m trainer \u001b[38;5;241m=\u001b[39m  Trainer(\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset_tokenized,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 27\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/transformers/trainer.py:3572\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3569\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3571\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3572\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3573\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3574\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3575\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3576\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3577\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3579\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3580\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3582\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/transformers/trainer.py:3854\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3850\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3851\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3852\u001b[0m         )\n\u001b[1;32m   3853\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3854\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3856\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[0;32mIn[97], line 9\u001b[0m, in \u001b[0;36mcompute_metric\u001b[0;34m(inp)\u001b[0m\n\u001b[1;32m      6\u001b[0m p_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(preds,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m metric \u001b[38;5;241m=\u001b[39m torchmetrics\u001b[38;5;241m.\u001b[39mAccuracy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m'\u001b[39m,num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp_label\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torchmetrics/metric.py:311\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torchmetrics/metric.py:380\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torchmetrics/metric.py:482\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    484\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torchmetrics/classification/stat_scores.py:339\u001b[0m, in \u001b[0;36mMulticlassStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 339\u001b[0m     \u001b[43m_multiclass_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k)\n\u001b[1;32m    343\u001b[0m tp, fp, tn, fn \u001b[38;5;241m=\u001b[39m _multiclass_stat_scores_update(\n\u001b[1;32m    344\u001b[0m     preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtop_k, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maverage, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultidim_average, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index\n\u001b[1;32m    345\u001b[0m )\n",
      "File \u001b[0;32m/proj/ciptmp/ix05ogym/myenv/lib/python3.11/site-packages/torchmetrics/functional/classification/stat_scores.py:316\u001b[0m, in \u001b[0;36m_multiclass_stat_scores_tensor_validation\u001b[0;34m(preds, target, num_classes, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEither `preds` and `target` both should have the (same) shape (N, ...), or `target` should be (N, ...)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and `preds` should be (N, C, ...).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     )\n\u001b[1;32m    315\u001b[0m check_value \u001b[38;5;241m=\u001b[39m num_classes \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m num_classes \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, name \u001b[38;5;129;01min\u001b[39;00m ((target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;241m+\u001b[39m ((preds, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreds\u001b[39m\u001b[38;5;124m\"\u001b[39m),) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m() \u001b[38;5;28;01melse\u001b[39;00m ():  \u001b[38;5;66;03m# noqa: RUF005\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     num_unique_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(torch\u001b[38;5;241m.\u001b[39munique(t))\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_unique_values \u001b[38;5;241m>\u001b[39m check_value:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'is_floating_point'"
     ]
    }
   ],
   "source": [
    "import torchmetrics\n",
    "import numpy as np\n",
    "from var_dump import var_dump\n",
    "def compute_metric(inp):\n",
    "    preds , label_ids  = inp\n",
    "    p_label = np.argmax(preds,1)\n",
    "    \n",
    "    metric = torchmetrics.Accuracy('multiclass',num_classes=3)\n",
    "    return metric(p_label , label_ids )\n",
    "\n",
    "trainer =  Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=test_dataset_tokenized,\n",
    "    compute_metrics=compute_metric,\n",
    "    \n",
    "    args= TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=1\n",
    "        \n",
    "        \n",
    "        \n",
    "    )\n",
    "    \n",
    ")\n",
    "\n",
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"bid = json.loads(d['actions'][1]['pos_candidates'][0]['attributes'])['backend_node_id']\n",
    "print(d['actions'][1]['pos_candidates'])\n",
    "soup = BeautifulSoup(lll['html'][1])#d['actions'][1]['raw_html'])\n",
    "#soup = BeautifulSoup(d['actions'][3]['raw_html'])\n",
    "#s = soup.find( '*' )\n",
    "# Find all 'div' tags\n",
    "soup = soup.find('form')\n",
    "all_tags = soup.find_all()\n",
    "\n",
    "# Remove all tags except for 'link', 'input', and 'select' tags\n",
    "i=0\n",
    "for element in all_tags:\n",
    "    if element.name  in ['div','text']: \n",
    "    #if element.name not in ['a','link', 'input', 'select','radio','button']:\n",
    "        \n",
    "        element.unwrap()\n",
    "    else:\n",
    "        element['backend_node_id']=i\n",
    "        \n",
    "        if 'class' in element.attrs:\n",
    "            del element['class']\n",
    "            pass\n",
    "        if 'bounding_box_rect' in element.attrs:\n",
    "            del element['bounding_box_rect']\n",
    "            pass\n",
    "        if 'is_clickable' in element.attrs:\n",
    "            del element['is_clickable']\n",
    "            pass\n",
    "        \n",
    "            \n",
    "        i+=1\n",
    "\n",
    "     \n",
    "\n",
    "s = soup.prettify()\n",
    "#b = s.split(\"/>\")\n",
    "x = toknizer(s,return_tensors='pt')\n",
    "print(x['input_ids'].shape[1],x['input_ids'].shape[1]/16348)\n",
    "\n",
    "\n",
    "print(s)\n",
    "if False:\n",
    "    for i in b:\n",
    "        print(i)\n",
    "        print('---------------------')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata.iloc[1,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
